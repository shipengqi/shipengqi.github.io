[{"categories":["Others"],"content":"正则表达式的三种功能：校验数据、查找文本、对文本进行切割和替换等操作。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:0:0","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"元字符 元字符就是指那些在正则表达式中具有特殊意义的专用字符，正则就是由一系列的元字符组成的。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:1:0","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"特殊单字符 字符 说明 . 任意字符（除换行以外） \\d 任意数字 \\D 任意非数字 \\w 任意字母，数字，下划线 \\W 任意非字母，数字，下划线的字符 \\s 任意空白符 \\S 任意非空白符 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:1:1","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"空白符 空白符包括空格，换行符 \\n， TAB 制表符 \\t 等。不同的操作系统换行符也有区别，例如 Windows 中换行是 \\r\\n，Linux 和 MaxOS 中是 \\n。 字符 说明 \\r 回车符 \\n 换行符 \\f 换页符 \\t 制表符 \\v 垂直制表符 \\s 任意空白符 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:1:2","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"量词 量词的元字符用来表示字符出现的次数。 字符 说明 * 0 到多次，等价于 {0,} + 1 到多次，等价于 {1,} ? 0 到 1 次，等价于 {0,1} {m} m 次 {m,} 至少 m 次 {m,n} m 到 n 次 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:1:3","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"范围 使用量词去匹配手机号 \\d{11}，但是范围比较大，会匹配到非手机号的数字，例如 11 个 0，所以需要在一定范围里找到符合要求的数字。 字符 说明 [...] 多选一，括号中的任意单个字符 [a-z] a 到 z 之间的任意单个字符 [^...] 取反，不能是括号中的任意单个字符 |：或，例如 ab|bc 表示 ab 或者 bc ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:1:4","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"贪婪与非贪婪模式 使用正则 a+ 在 aaabb 中查找，只有一个输出结果 aaa。但是使用 a* 的话会有 4 个匹配结果，分别是 [\"aaa\", \"\", \"\", \"\"]。 为什么会匹配到空字符串？因为 * 表示 0 到多次，匹配 0 次就是空字符串。aaa 部分应该也有空字符串，为什么没匹配上？ ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:2:0","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"贪婪匹配（Greedy） 在正则中，表示次数的量词默认是贪婪的，在贪婪模式下，会尝试尽可能最大长度去匹配。 aaabb 中使用正则 a* 的匹配过程： 匹配次数 开始 结束 说明 匹配结果 第 1 次 0 3 到第一个字母 b 发现不满足，输出 aaa aaa 第 2 次 3 4 匹配剩下的 bb 发现不满足，输出空字符串 空字符串 第 3 次 4 4 匹配剩下的 b 发现不满足，输出空字符串 空字符串 第 4 次 5 5 匹配剩下的空字符串，输出空字符串 空字符串 a* 在匹配开头的 a 时，会尝试尽量匹配更多的 a，直到第一个字母 b 不满足要求为止，匹配上三个 a，后面每次匹配时都得到了空字符串。 如果想尽可能最短匹配，那就要用到非贪婪匹配模式了。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:2:1","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"非贪婪匹配（Lazy） 非贪婪模式只需要在量词后面加上 ?，比如 a*?，在用这个正则去匹配 aaabb，得到的结果就是 [\"\", \"a\", \"\", \"a\", \"\", \"a\", \"\", \"\", \"\"]。 这次匹配到的结果都是单个的 a，就连每个 a 左边的空字符串也匹配上了。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:2:2","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"独占模式（Possessive） 不管是贪婪模式，还是非贪婪模式，都需要发生回溯才能完成相应的功能。但是在一些场景下，我们不需要回溯，匹配不上返回失败就好了，因此正则中还有另外一种模式，独占模式，它类似贪婪匹配，但匹配过程不会发生回溯，因此在一些场合下性能会更好。 什么是回溯？ 用正则 xy{1,3}z 匹配文本 xyyz。y{1,3} 会尽可能长地去匹配，当匹配完 xyy 后，由于 y 要尽可能匹配最长，即三个，但字符串中后面是个 z 就会导致匹配不上，这时候正则就会向前回溯，吐出当前字符 z，接着用正则中的 z 去匹配。 把这个正则改成非贪婪模式 xy{1,3}?z，y{1,3}? 尽可能少地匹配。匹配上一个 y 之后，文本中的 xy 后，正则会使用 xy 后面的 y 和正则中的 z 比较，发现正则 z 和 y 不匹配，这时正则就会向前回溯，重新查看 y 匹配两个的情况，匹配上正则中的 xyy，然后再用 z 去文本 中的 z，匹配成功。 独占模式就是在量词后面加上 +。 把正则改成独占模式 xy{1,3}+z，y{1,3}+ 尽可能长的匹配了两个 y，不回溯导致正则的 z 和前面的 y 匹配不上。 Go 不支持独占模式。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:2:3","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"分组与编号 () 在正则中可以用于分组，被括号括起来的部分“子表达式”会被保存成一个子组。分组和编号的规则，用一句话来说就是，第几个括号就是第几个分组。 假设时间格式是 2020-05-10 20:23:05，使用正则 ((\\d{4})-(\\d{2})-(\\d{2})) ((\\d{2}):(\\d{2}):(\\d{2})) 来匹配。 2020 - 05 - 10 20 : 23 : 05\r((\\d{4})-(\\d{2})-(\\d{2})) ((\\d{2}):(\\d{2}):(\\d{2}))\r12 3 4 56 7 8 // 分组编号对应着左括号的位置 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:3:0","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"分组引用 知道了分组的编号可以通过 \\\u003cnumber\u003e 的方式来引用，如 \\2。在 JavaScript 中是通过 $\u003cnumber\u003e 来引用，如 $2。Go 不支持。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:3:1","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"不保存子组 默认情况下，在括号里面的会保存成子组，如果不需要保存子组可以在括号里面使用 ?:，如 \\d{15}(?:\\d{3})?。 不保存子组可以理解成，括号只用于归组，把某个部分当成“单个元素”，不分配编号，后面不会再进行这部分的引用。可以提高正则的性能。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:3:2","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"4 中匹配模式 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:4:0","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"不区分大小写 不区分大小写的模式修饰符是 (?i)，使用时放在整个正则前面时，就表示整个正则表达式都是不区分大小写的，如 (?i)cat，等价于 [Cc][Aa][Tt]。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:4:1","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"点号通配模式 . 可以匹配上任何符号，除了换行。要匹配真正的“任意”符号的时候，可以使用 [\\s\\S] 或 [\\d\\D] 或 [\\w\\W] 等。也可以使用点号通配模式。有很多地方把它称作单行匹配模式。但这么说容易造成误解，毕竟它与多行匹配模式没有关系。 点号通配模式修饰符是 (?s)，如 (?s).+ JavaScript 不支持，可以使用 [\\s\\S] 等方式替代。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:4:2","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"多行匹配模式 通常情况下，^ 匹配整个字符串的开头，$ 匹配整个字符串的结尾。多行匹配模式改变的就是 ^ 和 $ 的匹配行为。 例如 ^the|cat$ 匹配下面的文本： the little cat\rthe small cat 只能匹配到第一个 the 和最后一个 cat。 多行模式的作用在于，使 ^ 和 $ 能匹配上每行的开头或结尾，我们可以使用模式修饰符号 (?m) 来指定，如 (?m)^the|cat$。 正则中还有 \\A 和 \\z（Python 中是 \\Z） 这两个元字符容易混淆，\\A 仅匹配整个字符串的开始，\\z 仅匹配整个字符串的结束，在多行匹配模式下，它们 的匹配行为不会改变，如果只想匹配整个字符串，而不是匹配每一行，用这个更严谨一些。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:4:3","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"注释模式 正则中支持添加注释，修饰符 (?#)，如 (\\w+)(?#word) \\1(?#word repeat again)。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:4:4","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"断言 断言是指对匹配到的文本位置有要求。 例如 \\d{11} 能匹配上 11 位数字，但这 11 位数字可能是 18 位身份证号中的一部分。查找 tom 这个单词，但其它的单词，比如 tomorrow 中也包含了tom。 正则中提供了一些结构，只用于匹配位置，而不是文本内容本身，这种结构就是断言。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:5:0","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"单词边界 例如 tom asked me if I would go fishing with him tomorrow.，要把 tom 换成 jim，文本中除了 tom，tomorrow 也是以 tom 开头的。 单词的组成一般可以用元字符 \\w+ 来表示，只要找出单词的边界，也就是当出现了 \\w 表示的范围以外的字符，比如引号、空格、标点、换行等这些符号，我们就可以在正则中使用 \\b （Boundary）来表示单词的边界。 正则应该是 \\btom\\b。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:5:1","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"行的开始或结束 如果要求匹配的内容要出现在一行文本开头或结尾，就可以使用 ^ 和 $ 来进行位置界定。在多行模式下，^ 和 $ 符号可以匹配每一行的开头或结尾。更严谨的做法是，使用 \\A 和 \\z 来匹配整个文本的开头或结尾。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:5:2","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"环视 邮政编码的规则是由 6 位数字组成。现在要求提取文本中的邮政编码。根据规则，很容易就可以写出邮编的组成 \\d{6}。但是 7 位数的前 6 位也能匹配上，12 位数可以匹配上两次。 也就是说，除了文本本身组成符合这 6 位数的规则外，这 6 位数左边或右边都不能是数字。正则是通过环视来解决这个问题的。 正则 名称 含义 示例 (?\u003c=Y) 肯定逆序环视 左边是 Y (?\u003c=\\d)th th 的左边是数字，可以匹配文本 9th (?\u003c!Y) 否定逆序环视 左边不是 Y (?\u003c!\\d)th th 的左边不是数字，可以匹配文本 health (?=Y) 肯定顺序环视 右边是 Y th(?=\\d) th 的右边是数字，可以匹配文本 th9 (?!Y) 否定顺序环视 右边不是 Y th(?!\\d) th 的右边不是数字，可以匹配文本 the 左尖括号代表看左边，没有尖括号是看右边，感叹号是非的意思。 针对邮编的正则可以改成 (?\u003c!\\d)\\d{6}(?!\\d)。 表示单词边界的 \\b 也可以用环视的方式来写。例如 the little cat is in the hat，单词可以用 \\w+ 来表示，单词的边界其实就是那些不能组成单词的字符，即左边和右边都不能是组成单词的字符。 (?\u003c!\\w) 表示左边不能是单词组成字符，(?!\\w) 右边不能是单词组成字符，即 \\b\\w+\\b 也可以写成 (?\u003c!\\w)\\w+(?!\\w)。可以写成 (?\u003c=\\W)\\w+(?=\\W)。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:5:3","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"转义 转义在工作中是比较常见的，如 str = \"How do you spell the word \\\"regex\\\"?\"，但是正则中什么时候需要转义，什么时候不用转义？ ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:6:0","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"转义字符 转义字符自身和后面的字符看成一个整体，用来表示某种含义。最常见的例子是，C 语言中用反斜线字符 \\ 作为转义字符，来表示那些不可打印的 ASCII 控制符。另外，在 URI 协议中，请求串中的一些符号有特殊含义，也需要转义，转义字符用的是百分号 %。 之所以称为转义字符，是因为它后面的字符，不是原来的意思了。例如文件名中有 * 号，我们就需要转义： rm access_log* # 删除当前目录下 access_log 开头的文件 rm access_log\\* # 删除当前目录下名字叫 access_log* 的文件 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:6:1","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"字符串转义和正则转义 正则中也是使用 \\ 进行转义的。 一般来说，正则中 \\d 代表的是单个数字，但如果我们想表示成 反斜杠和字母 d，这时候就需要进行转义，写成 \\\\d。 在程序中表示普通字符串的时候，我们如果要表示反斜杠，通常需要写成两个反斜杠，因为只写一个会被理解成“转义符号”，而不是反斜杠本身。 在程序使用过程中，从输入的字符串到正则表达式，其实有两步转换过程，分别是字符串转义和正则转义。 在正则中正确表示“反斜杠”具体的过程是这样子：我们输入的字符串，四个\\\\\\\\，经过第一步字符串转义，它代表的含义是两个 \\\\；这两个反斜杠再经过第二步正则转义，它就可以代表单个 \\ 了。 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:6:2","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"元字符的转义 如果现在要查找比如*、+、? 本身，而不是元字符的功能，这时候就需要对其进行转义，直接在前面加上反斜杠就可以了。 正则中方括号 [] 和 花括号 {} 只需转义开括号，但圆括号 () 两个都要转义。 \u003e\u003e\u003e import re \u003e\u003e\u003e re.findall('\\(\\)\\[]\\{}', '()[]{}') ['()[]{}'] \u003e\u003e\u003e re.findall('\\(\\)\\[\\]\\{\\}', '()[]{}') # 方括号和花括号都转义也可以 ['()[]{}'] 在正则中，圆括号通常用于分组，或者将某个部分看成一个整体，如果只转义开括号或闭括号，正则会认为少了另外一半，所以会报错。 字符组中的转义 字符组中需要转义的有三种情况： 脱字符在中括号中，且在第一个位置需要转义： \u003e\u003e\u003e import re \u003e\u003e\u003e re.findall(r'[^ab]', '^ab') # 转义前代表\"非\" ['^'] \u003e\u003e\u003e re.findall(r'[\\^ab]', '^ab') # 转义后代表普通字符 ['^', 'a', 'b'] 中划线在中括号中，且不在首尾位置： \u003e\u003e\u003e import re \u003e\u003e\u003e re.findall(r'[a-c]', 'abc-') # 中划线在中间，代表\"范围\" ['a', 'b', 'c'] \u003e\u003e\u003e re.findall(r'[a\\-c]', 'abc-') # 中划线在中间，转义后的 ['a', 'c', '-'] \u003e\u003e\u003e re.findall(r'[-ac]', 'abc-') # 在开头，不需要转义 ['a', 'c', '-'] \u003e\u003e\u003e re.findall(r'[ac-]', 'abc-') # 在结尾，不需要转义 ['a', 'c', '-'] 右括号在中括号中，且不在首位： \u003e\u003e\u003e import re \u003e\u003e\u003e re.findall(r'[]ab]', ']ab') # 右括号不转义，在首位 [']', 'a', 'b'] \u003e\u003e\u003e re.findall(r'[a]b]', ']ab') # 右括号不转义，不在首位 [] # 匹配不上，因为含义是 a后面跟上b] \u003e\u003e\u003e re.findall(r'[a\\]b]', ']ab') # 转义后代表普通字符 [']', 'a', 'b'] ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:6:3","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"参考链接 正则表达式入门课 ","date":"2022-05-02","objectID":"/posts/2020-05-20-regex/:7:0","tags":null,"title":"Regex","uri":"/posts/2020-05-20-regex/"},{"categories":["Others"],"content":"OAuth 2.0 是一种授权协议。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:0:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"OAuth 2.0 有什么用？ OAuth 2.0 就是保证第三方（软件）只有在获得授权之后，才能进一步访问授权者的数据。 OAuth 2.0 的体系里面有 4 种角色，分别是： 资源拥有者 客户端 授权服务 受保护资源 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:1:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"OAuth 2.0 的 4 种授权类型 授权码许可（Authorization Code），通过授权码 code 获取 access_Token 客户端凭据许可（Client Credentials），通过第三方 client 的 app_id 和 app_secret 获取 access_Token 资源拥有者凭据许可（Password），通过用户的 username 和 password 获取 access_Token 隐式许可（Implicit），通过嵌入在浏览器的第三方 client 的 app_id 获取 access_Token ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:2:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"授权码许可类型 下图就是授权码许可的流程： 上面的流程第 4 步，授权服务生成了授权码 code，然后重定向到了 client。经历了两次重定向，为什么不直接返回 access_token？ 原因是如果直接返回 access_token，就不能使用重定向的方式，access_token 在 URL 中会把 access_token 暴露在浏览器上，有被窃取的安全风险。 下面是没有授权码的流程： 由于少了一次重定向，浏览器停在了授权页面上，无法回到小兔软件的页面。 这就是授权码这个间接凭证的作用。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:2:1","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"授权服务 授权服务就是负责颁发访问令牌的的服务。OAuth 2.0 的核心就是授权服务，授权服务的核心是令牌。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:3:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"授权服务要做些什么 例如小兔软件要让小明去京东商家开放平台那里给它授权数据，那这里总不能你要，京东开放平台就给你。需要小兔先去平台上注册，注册完以后，平台会给小兔软件 app_id 和 app_secret 等信息，方便之后的授权验证。 同时，注册的时候，还要配置受保护资源的可访问范围。比如小兔软件能否获取小明店铺的订单信息，能否获取订单的所有字段信息等，这个权限范围就是 scope。 注册完之后，授权服务的授权码许可流程： ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:3:1","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"授权码许可流程 包含两部分：准备工作和生成授权码 code。 准备工作： 验证基本信息包括对第三方软件合法性和回调地址合法性的校验。 在浏览器环境下，颁发 code 的请求过程都是在浏览器前段完成的，意味着有被冒充的风险。因为授权服务 必须对第三方软件的存在性做判断。 回调地址也是可以被伪造的。因此也需要校验是否是已经注册的回调地址。 校验权限范围，比如使用微信登录第三方软件时，微信授权页面会提示第三方软件会获得你的昵称，头像，地理位置等信息。如果不想让第三方获取，可以不选择 某一项。这就是说需要对小兔软件传过来的 scope 参数，与小兔软件在平台注册时申请的 scope 对比校验。 生成授权页面，用户点击 approve 之后叫（这之前还会有登录操作），才会生成授权码 code 和 access_token。 生成授权码 code： 第二次校验权限范围，使用用户授权之后的权限 scope 和注册时的 scope 做比对。因为用户点击 approve 之前可以选择权限范围。 处理请求，生成授权码 code。校验 response_type，有两种类型的值 code 和 token，授权码流程的 response_type 的值就是 code。 授权服务将 code 与 app_id 和 user 进行关系映射，由于授权码 code 是临时的，所以还需要设置有效期（一般不会超过 5 分钟），并且一个授权码 code 只能被使用一次。 将授权码 code 和 scope 绑定存储，后续颁发 access_token 时通过 code 获取 scope，并与 access_token 绑定。 重定向到第三方软件，code 在重定向 URL 种。 颁发访问令牌： 小兔软件拿着 code 来请求，这个过程在后端完成，校验 grant_type 是否为 authorization_code，校验 app_id 和 app_secret。 校验授权码 code 是否合法，取出之前存储的 code，code 值对应的 key 是 app_id 和 user 的组合值。确认 code 有效后，从存储中删除。 生成 access_token，有三个原则：唯一性，不连续性，不可猜性。存储 access_token ，并与 app_id 和 user 进行关系映射。还需要和 scope 绑定，设置过期时间 expires_in。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:3:2","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"refresh_token 颁发 refresh_token 和 access_token 是一起生成的。第三方软件会得到两个 token。 refresh_token 有什么用？ 在 access_token 失效的情况 下，为了不让用户频繁手动授权，通过 refresh_token 向系统重新请求生成一个新的 access_token。 在 OAuth 2.0 规范中，refresh_token 是一种特殊的授权许可类型，是嵌入在授权码许可类型下的一种特殊许可类型。 refresh_token 流程主要包括如下两大步骤： grant_type 值为 refresh_token，验证第三方软件是否存在，验证 refresh_token。验证 refresh_token 是否属于该第三方软件。 重新生成 access_token 和 refresh_token。 一个 refresh_token 被使用以后，授权服务需要将其废弃，并重新颁发一个 refresh_token。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:3:3","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"JWT JSON Web Token（JWT）是一个开放标准，就是用一种结构化封装的方式生成 token 的技术。 结构化后，token 本身就可以包含一些有用的信息，可以分为三部分： Header，typ 表示 token 的类型，alg 表示使用的签名算法 Payload，JWT 的数据体。sub 一般为资源拥有者的唯一标识，exp token 的过期时间，iat token 的颁发时间。还可以自定义声明。 Signature，JWT 信息的签名。防止信息被篡改。 三部分通过 . 分隔，Header.Payload.Signature。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:4:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"令牌内检 令牌内检的意思就是，受保护资源服务要验证授权服务颁发的令牌，受保护资源服务调用授权服务的接口来检验令牌。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:4:1","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"JWT 如何使用 授权服务颁发 JWT token 给第三方软件，第三方软件拿着 token 来请求受保护资源。JWT 在公网上传输，用 base64 进行编码，同时还需要进行签名及加密处理。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:4:2","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"JWT 的优缺点 优点： JWT 的核心思想就是用计算替代存储，就是时间换空间。 加密。 JWT token，有助于增强系统的可用性和可伸缩性。为什么这么说，因为 JWT token 本身包含了验证身份需要的信息，不需要服务端额外的存储，每次请求都是 无状态的。 缺点： JWT token 不会在服务端存储，所以无法改变 token 的状态。这就意味着，只要 token 没有过期，就可以一直使用。 为了解决这个问题，通 常会有两种做法： 将每次生成 JWT 令牌时的秘钥粒度缩小到用户级别，也就是一个用户一个秘钥。这样，当用户取消授权或者修改密码后，就可以让这个密钥一起修改。一般情况下，这 种方案需要配套一个单独的密钥管理服务。 在不提供用户主动取消授权的环境里面，如果只考虑到修改密码的情况，那么就可以把用户密码作为 JWT 的密钥。当然，这也是用户粒度级别的。这样一来，用户 修改密码也就相当于修改了密钥。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:4:3","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"Token 生命周期 无论是JWT 结构化令牌还是普通的令牌。它们都有有效期，只不过，JWT 令牌可以把有效期的信息存储在本身的结构体中。 OAuth 2.0 的令牌生命周期，通常会有三种情况： 自然过期，这是最常见的情况。这个过程是，从授权服务创建 一个令牌开始，到第三方软件使用令牌，再到受保护资源服务验证令牌，最后再到令牌失 效。同时，这个过程也不排除主动销毁令牌的事情发生，比如令牌被泄露，授权服务可以 做主让令牌失效。 访问令牌失效之后可以使用刷新令牌请求 新的访问令牌来代替失效的访问令牌，以提升用户使用第三方软件的体验。 就是让第三方软件比如小兔，主动发起令牌失效的请求，然后授 权服务收到请求之后让令牌立即失效。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:4:4","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"第三方软件 如何构建第三方软件， 包括 4 部分，分别是：注册信息、引导授权、使用访问令牌、使用刷新令牌。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:5:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"注册信息 小兔软件只有先有了身份，才可以参与到 OAuth 2.0 的流程中去。也就是说，小兔软件需要先拥有自己的 app_id 和 app_serect 等信息，同时还要填写 自己的回调地址 redirect_uri、申请权限等信息。这也叫做静态注册， ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:5:1","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"引导授权 当用户需要使用第三方软件，来操作其在受保护资源上的数据，就需要第三方软件来引导 授权。小兔软件需要小明的授权，只有授权服务才能允许小明这样做。所以呢，小兔软 件需要“配合”小明做的第一件事儿，就是将小明引导至授权服务。让用户为第三方软件授权，得到了授权之后，第三方软件才可以 代表用户去访问数据。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:5:2","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"使用 access_token 拿到令牌后去使用令牌，才是第三方软件的最终目的。 目前 OAuth 2.0 的令牌只支持一种类型，那就是 bearer 令牌，可以是任意字符串格式的令牌。使用 access_token请求的方式，有三种： URI Query Parameter： GET /resource?access_token=b1a64d5c-5e0c-4a70-9711-7af6568a61fb HTTP/1.1 POST 表单： POST /resource HTTP/1.1\rHost: server.example.com\rContent-Type: application/x-www-form-urlencoded\raccess_token=b1a64d5c-5e0c-4a70-9711-7af6568a61fb Authorization Request Header： GET /resource HTTP/1.1\rHost: server.example.com\rAuthorization: Bearer b1a64d5c-5e0c-4a70-9711-7af6568a61fb 建议是采用 Authorization 的方式来传递令牌。 使用 refresh_token 的方式跟使用 access_token 是一样的。 refresh_token的使用，最需要关心的是，什么时候使用 refresh_token？ 例如，在小兔打单软件收到 access_token 的同时，也会收到 access_token 的过期时间 expires_in。一个设 计良好的第三方应用，应该将 expires_in 值保存下来并定时检测；如果发现 expires_in即将过期，则需要利用 refresh_token 去重新请求授权服务，以便获取新的、有效的访问 令牌。 这种定时检测的方法可以提前发现 access_token 是否即将过期。此外，还有一种方法是“现场”发现。也就是说，比如小兔软件访问小明店铺订单的时候， 突然收到一个 access_token 失 效的响应，此时小兔软件立即使用 refresh_token 来请求一个 access_token，以便继续代表小 明使用他的数据。 refresh_token 是一次性的，使用之后就会失效，但是它的有效期会比 access_token 要长。但是如果 refresh_token 也过期了怎么办？ 在这种情况下，就需要重新授权了。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:5:3","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"资源拥有者凭据许可（Password） 资源拥有者的凭据，就是用户名和密码。这是最糟糕的一种方式。为什么 OAuth 2.0 还支持这种许可类型？ 例如，小兔此时就是京东官方出品的一款软件，小明也是京东的用户，那么小明其实是可以使用用户名和密码来直接使用小兔这款软件的。原因很简单，那就是这里不再 有“第三方”的概念了。 小兔软件只需要使用一次用户名和密码数据来换回一个 token，进而通过 token 来访问小明店铺的数据，以后就不会再使用用户名和密码了。 注意第 2 步中的 grant_type 的值为 password，告诉授权服务使用资源拥有者凭据许可凭据的方式去请求访问。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:6:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"客户端凭据许可（Client Credentials） 如果小兔软件访问了一个不需要用户小明授权的数据，比如获取京东 LOGO 的图片地址，这个 LOGO 信息不属于任何一个第三方用户。在授权流程中，就不再需要 资源拥有者这个角色了。也可以理解为“第三方软件就是资源拥有者”。 这种场景下的授权，便是客户端凭据许可，第三方软件可以直接使用注册时的 app_id 和 app_secret 来换回访问令牌 token。 第 1 步：第三方软件小兔通过后端服务向授权服务发送请求，这里 grant_type 的值为 client_credentials ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:7:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"隐式许可（Implicit） 如果小明使用的小兔打单软件应用没有后端服务，就是在浏览器里面执行的，比如纯粹的 JavaScript 应用，应该如何使用 OAuth 2.0？ 在这种情况下，小兔软件对于浏览器就没有任何保密的数据可以隐藏了，不需要 app_secret 的值，也不用再通过授权码 code。因为使用授权码的目的之一， 就是把浏览器和第三方软件的信息做一个隔离，确保浏览器看不到 access_token。 隐式许可授权流程的安全性会降低很多。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:8:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"OIDC OIDC 是一种用户身份认证的开放标准。OIDC 是基于 OAuth 2.0 构建的身份认证框架协议。OAuth 2.0 是一种授权协议，而不是身份认证协议。 OIDC = 授权协议 + 身份认证，是 OAuth 2.0 的超集。 OIDC 和 OAuth 2.0 的角色对应关系： OIDC 标准框架中的三个角色： EU（End User），终端用户 RP（Relying Party），认证服务的依赖方，就是 OAuth 2.0 中的第三方软件。 OP（OpenID Provider），身份认证服务提供方 OIDC 的通信流程： OIDC 的授权码流程和 OAuth 2.0 授权码流程几乎一样，唯一的区别就是多了一个 ID_TOKEN。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:9:0","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"ID_TOKEN OIDC 对 OAuth 2.0 最主要的扩展就是提供了 id_token。 id_token 和 access_token 是一起返回的。但是 access_token 是不需要被第三方软件解析的。而 id_token 需要被第三方软件解析，从而获取 id_token 中的信息。 id_token 能够标识用户，失效时间等属性来达到身份认证的目的。id_token 才是身份认证得关键。 ID_TOKEN 中有什么信息？ id_token 也是 JWT token（由一组 Cliams 构成以及其他辅助的 Cliams），一定包含下面 5 个参数： iss，token 的颁发者，它的值就是 OP 的 URL。 sub，token 的主题，值是一个代表 EU 的全局唯一的标识符。 aud，token 的目标受众，值是 RP 的 app_id。 exp，token 的过期时间。 iat，token 的颁发时间。 在第三方软件（RP）拿到这些信息之后，就获得了身份信息（如 sub，EU 的全局唯一的标识符），然后对身份信息进行验证 至此，可以说用户身份认证就可以完成了， 后续可以根据 UserInfo EndPoint 获取更完整的信息。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:9:1","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Others"],"content":"OIDC 流程 id_token -\u003e 创建 UserInfo EndPoint -\u003e 解析 id_token -\u003e 记录登录状态 -\u003e 获取 UserInfo。 ","date":"2020-11-03","objectID":"/posts/2020-11-03-oauth2-getting-started/:9:2","tags":null,"title":"OAuth 2.0 Getting Started","uri":"/posts/2020-11-03-oauth2-getting-started/"},{"categories":["Go"],"content":"Delve 安装 $ go get github.com/go-delve/delve/cmd/dlv # or $ git clone https://github.com/go-delve/delve.git $GOPATH/src/github.com/go-delve/delve $ cd $GOPATH/src/github.com/go-delve/delve $ make install # check $ dlv version 如果找不到 dlv，检查环境变量 PATH 和 GOPATH。 如果使用的是 Go Modules，执行上面的命令时，不要在你的项目目录里面。 ","date":"2020-04-09","objectID":"/posts/2020-04-09-go-remote-debug/:1:0","tags":null,"title":"Golang Remote Debug with Delve","uri":"/posts/2020-04-09-go-remote-debug/"},{"categories":["Go"],"content":"编译源码并开启调试模式 # compile CGO_ENABLED=0 go build -gcflags \"all=-N -l\" -a -o ./main ./main.go # start dlv --listen=:2345 \\ --headless \\ --api-version=2 \\ --accept-multiclient \\ --check-go-version=false \\ exec ./main --check-go-version 的默认值是 true，检查 golang 的版本。在有些环境下可以设置为 false，比如我是将二进制文件运行在容器环境中，而我的容器 中并没有 golang。 golang 的版本要大于 1.14。 如果 ./main 后面需要参数，使用 -- 分隔，例如： $ dlv --listen=:2345 --headless=true --api-version=2 --accept-multiclient --check-go-version=false exec ./main -- -f ./conf/debug.ini 相当于： $ ./main -f ./conf/debug.ini 启动服务之后，输出： $ dlv --listen=:2345 --headless=true --api-version=2 --accept-multiclient --check-go-version=false exec ./main API server listening at: [::]:2345 进程会 pending 在这里，等待 remote debug 的连接。 如果不需要被阻塞，可以使用 --continue 参数： $ dlv --listen=:2345 --headless=true --api-version=2 --accept-multiclient --check-go-version=false exec --continue ./main API server listening at: [::]:2345 [GIN-debug] [WARNING] Running in \"debug\" mode. Switch to \"release\" mode in production. - using env: export GIN_MODE=release - using code: gin.SetMode(gin.ReleaseMode) ... ","date":"2020-04-09","objectID":"/posts/2020-04-09-go-remote-debug/:2:0","tags":null,"title":"Golang Remote Debug with Delve","uri":"/posts/2020-04-09-go-remote-debug/"},{"categories":["Go"],"content":"IDE 配置 示例使用的 IDE 是 IDEA，在 Add Configuration 中配置 Go Remote： 配置好后，点击 debug 按钮： 连接成功之后，server 端会输出： $ dlv --listen=:2345 --headless=true --api-version=2 --accept-multiclient --check-go-version=false exec ./main API server listening at: [::]:2345 [GIN-debug] [WARNING] Running in \"debug\" mode. Switch to \"release\" mode in production. - using env: export GIN_MODE=release - using code: gin.SetMode(gin.ReleaseMode) [GIN-debug] GET / --\u003e suite-installer-backend/app/http.loadRouter.func2 (6 handlers) [GIN-debug] GET /healthz --\u003e suite-installer-backend/app/http.healthCheck (6 handlers) [GIN-debug] GET /urest/v1.2/deployment/:deploymentUuid/components --\u003e suite-installer-backend/app/http.getComponents (7 handlers) [GIN-debug] POST /urest/v1.2/deployment/:deploymentUuid/deployer --\u003e suite-installer-backend/app/http.startDeployer (7 handlers) [GIN-debug] POST /urest/v1.2/deployment/:deploymentUuid/logs --\u003e suite-installer-backend/app/http.saveLogs (7 handlers) 之后就可以断点调试了。 ","date":"2020-04-09","objectID":"/posts/2020-04-09-go-remote-debug/:3:0","tags":null,"title":"Golang Remote Debug with Delve","uri":"/posts/2020-04-09-go-remote-debug/"},{"categories":["Go"],"content":"问题 ","date":"2020-04-09","objectID":"/posts/2020-04-09-go-remote-debug/:4:0","tags":null,"title":"Golang Remote Debug with Delve","uri":"/posts/2020-04-09-go-remote-debug/"},{"categories":["Go"],"content":"operation not permitted 在 docker container 中运行，如果输出下面的错误： could not launch process: fork/exec ./main: operation not permitted 可以设置 --security-opt=seccomp:unconfined 参数。关闭容器的 seccomp（linux 内核的一种安全机制） 限制。 docker 是使用命名空间进行用户隔离，使用 cgroups 来限制容器使用的资源。使用 apparmor 限制容器对资源的访问以及使用 seccomp 限制容器的系统调用等。 $ docker run -p 2345:2345 --security-opt=seccomp:unconfined test:latest # 或者 $ docker run -p 2345:2345 --security-opt=apparmor:unconfined --cap-add=SYS_PTRACE test:latest --cap-add 用来添加 Linux capabilities。SYS_PTRACE 表示使用 ptrace(2) 追踪任意进程。 参考： docker run reference operation not permitted issue。 Delve debug in docker。 container debug。 ","date":"2020-04-09","objectID":"/posts/2020-04-09-go-remote-debug/:4:1","tags":null,"title":"Golang Remote Debug with Delve","uri":"/posts/2020-04-09-go-remote-debug/"},{"categories":["Go"],"content":"closed network connection 如果使用了 --continue 参数，碰到了如下错误： 2021-03-10T07:10:48Z error layer=rpc writing response:write tcp 127.0.0.1:2345-\u003e127.0.0.1:39402: use of closed network connection 可能是在你的 main goroutine 中有无限循环导致，例如： func main() { for { // Necessary code here } }() 可以改成： func main() { go func() { for { // Necessary code here } } }() 如果要实现在 main goroutine 中阻塞，可以利用 chan 来实现。 参考 closed network connection issue。 ","date":"2020-04-09","objectID":"/posts/2020-04-09-go-remote-debug/:4:2","tags":null,"title":"Golang Remote Debug with Delve","uri":"/posts/2020-04-09-go-remote-debug/"},{"categories":["Go"],"content":"permission denied 如果在 kubernetes 中，pod 启动时碰到下面的错误： Could not create config directory: mkdir .config: permission denied. 可能是因为设置了 securityContext 的问题，可以查看是否配置了 runAsUser，runAsGroup 等。 另外 pod 也需要配置容器的 --security-opt 等参数： spec: containers: - args: - --security-opt=seccomp:unconfined - --security-opt=apparmor:unconfined - --cap-add=SYS_PTRACE # or capabilities in container.securityContext securityContext: capabilities: add: - SYS_PTRACE ","date":"2020-04-09","objectID":"/posts/2020-04-09-go-remote-debug/:4:3","tags":null,"title":"Golang Remote Debug with Delve","uri":"/posts/2020-04-09-go-remote-debug/"},{"categories":["Go"],"content":"Kubernetes 中的 Pod 状态 Pending 或者 1/2 Running 在 Kubernetes 中调试时，如果 pod 配置了 readinessProbe，但是没有使用 --continue 参数，那么容器进程阻塞，会导致 pod 的 readinessProbe 总是失败，导致 Pod 的状态一直是 Pending 或者 1/2 Running。 ","date":"2020-04-09","objectID":"/posts/2020-04-09-go-remote-debug/:4:4","tags":null,"title":"Golang Remote Debug with Delve","uri":"/posts/2020-04-09-go-remote-debug/"},{"categories":["Go"],"content":"本页收集了在 review go 代码时常见的评论。这只是一份常见错误的清单，并不是一个全面的风格指南。全面的风格指南可以参 考 The Uber Go Style Guide 。 可以看做是对 Effective Go 的补充。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:0:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Gofmt 所有代码在发布前均使用 gofmt 进行修正。 另一种方法是使用 goimports ，这是 gofmt 的一个超集，可以根据需要添加（和删除）导入行。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:1:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Comment Sentences commentary 注释应该是完整的句子，即使这似乎有点多余。这样做，能使注释在转化成 godoc 时有一个不错的格式。注释应该以要描述的对象开头，句号结尾。 // Request represents a request to run a command. type Request struct { ... // Encode writes the JSON encoding of req to w. func Encode(w io.Writer, req *Request) { ... ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:2:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Contexts context.Context 类型的值（可以是安全凭证、跟踪信息、截止日期和取消信号）可以跨越 API 和进程边界。Go 程序在整个函数调用链中显 式地将 Contexts 从传入的 RPC 和 HTTP 请求传递到传出的请求。 Context 所多数作为函数的第一个参数: func F(ctx context.Context, /* other arguments */) {} 不特定于请求的函数可能会使用 context.background()，即使你认为不需要这样做，也最好传递一个上下文。默认的情况是传递一 个 Context；当有充分的理由可以替代的情况下，才会直接使用 context.Background()。 不要在结构类型中添加 Context 成员，而是在该类型上的每个需要传递的方法中添加一个 ctx 参数。唯一的例外方法，就是签名必须与标准库或第三 方库中的接口相匹配时。 不要创建自定义的 Context 类型，或者在函数签名中使用 Context 以外的接口。 如果需要传递应用数据，就把它放在参数中，在接收器中，globals 的，或者，如果它真的属于那里，就放在 Context 的值中。 Contexts 是不可更改的，所以将 ctx 传递给多个调用可以共享相同的 deadline, cancellation signal, credentials, parent trace 等。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:3:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Crypto Rand 不要使用 math/rand 包来生成密钥，即使是一次性密钥。应该使用 crypto/rand： import ( \"crypto/rand\" // \"encoding/base64\" // \"encoding/hex\" \"fmt\" ) func Key() string { buf := make([]byte, 16) _, err := rand.Read(buf) if err != nil { panic(err) // out of randomness, should never happen } return fmt.Sprintf(\"%x\", buf) // or hex.EncodeToString(buf) // or base64.StdEncoding.EncodeToString(buf) } ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:4:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Declaring Empty Slices 声明空的 slice，最好使用 var t []string 不要使用： t := []string{} 前者声明了一个值为 nil 的 slice，有些时候，而后者声明了一个长度为 0 的 non-nil slice。两者使用 len 和 cap 得到的都是零，但是 应该优先使用前者。因为可能你从没向这个 slice append 元素，使用前者，可以避免内存分配。 注意，在有些情况下，non-nil slice 是首选的，比如对 JSON 对象进行编码时（nil slice 编码为 null，而 []string{} 编码为 JSON 数 组 []）。 在设计接口时，要避免区分 nil slice 和 non-nil slice、“零长度” 切片，因为这可能会导致微妙的编程错误。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:5:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Doc Comments 所有顶级的、导出的名称都应该有 doc 注释，不重要的未导出的 type 或 func 声明也应该有 doc 注释。 有关注释的更多信息，可以参考 commentary Go 提供两种注释风格，C 的块注释风格 /**/，C++ 的行注释风格 //。块注释主要作为包的注释，但在表达式中或禁用大段代码时也很有用。 每一个包都应该有包注释，位于文件的顶部，在包名出现之前。如果一个包有多个文件，包注释只需要出现在一个文件的顶部即可。 包注释应该介绍包，并提供与整个包相关的信息。它将首先出现在 godoc 页面上，并应设置下面的详细文档。 包注释建议使用块注释风格，如果这个包特别简单，需要的注释很少，也可以选择使用行注释。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:6:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Don’t Panic errors 尽量不要使用 panic 处理一般的错误。函数应该设计成多返回值，其中包括 要返回的 error 类型。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:7:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Error Strings 错误字符串不应该大写（除非以专有名词或缩略语开头），也不应该以标点符号结尾，因为它们通常是在其他上下文之后打印的。也就是说，使 用 fmt.Errorf(\"something bad\") 而不是 fmt.Errorf(\"Something bad\")，这样 log.Printf(\"Reading %s: %v\", filename, err) 的格式化就不会在消息中间出现一个大写字母。 这不适用于日志记录，它是隐式的、面向行的，并且不与其他消息结合在一起。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:8:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Examples 当添加一个新的包时，要包含使用示例：一个可运行的例子，或一个简单的测试，演示一个完整的调用。 更多参考 testable Example() functions 。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:9:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Goroutine Lifetimes ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:10:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Handle Errors errors 不要将 error 赋值给匿名变量 _。如果一个函数返回 error，一定要检 查它是否为空，判断函数调用是否成功。如果不为空，就需要处理这个错误，或者 return 给调用者，特殊情况下可以 panic。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:11:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Imports 除非导入之间有直接冲突，否则应避免导入别名。 导入烦人包应该进行分组。同一组的包之间不需要有空行，不同组之间的包需要一个空行。标准库的包应该放在第一组。 goimports 可以直接修正 import 包的规范。 package main import ( \"fmt\" \"hash/adler32\" \"os\" \"appengine/foo\" \"appengine/user\" \"github.com/foo/bar\" \"rsc.io/goversion/version\" ) ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:12:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Import Blank 只为其副作用而导入的包（使用语法 import _ \"pkg\"）只应在程序的 main 包中，或在需要它们的测试中导入。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:13:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Import Dot 在那些由于循环依赖关系而不能成为被测包的一部分的测试中，使用 import . \"pkg\"。 package foo_test import ( \"bar/testutil\" // also imports \"foo\" . \"foo\" ) 上面的例子，该测试文件不能定义在于 foo 包里面，因为它导入了 bar/testutil，而 bar/testutil import 了 foo，这会造成循环 引用。 所以需要将该测试文件定义在 foo_test 包中。使用了 import . \"foo\" 后，该测试文件内代码能直接调用 foo 里面的函数而不需要显式 地写上包名。 但 import . 这个特性，建议只在这种场景下使用，因为它会影响代码的可读性。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:14:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"In-Band Errors 在 C 语言和类似的语言中，通常函数会返回像 -1 或 null 来表示错误或结果丢失: // Lookup returns the value for key or \"\" if there is no mapping for key. func Lookup(key string) string // Failing to check a for an in-band error value can lead to bugs: Parse(Lookup(key)) // returns \"parse failure for value\" instead of \"no value for key\" Go 提供了更好的结局方案，就是支持返回多个值。一个函数应该返回一个额外的值来表示它的其他返回值是否有效。这个返回值可以是一个 error，也 可以是一个布尔值。 // Lookup returns the value for key or ok=false if there is no mapping for key. func Lookup(key string) (value string, ok bool) 这样可以防止调用者错误地使用结果： Parse(Lookup(key)) // compile-time error 并鼓励更健壮，可读性更好的代码: value, ok := Lookup(key) if !ok { return fmt.Errorf(\"no value for %q\", key) } return Parse(value) ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:15:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Indent Error Flow 优先处理 error，尽可能减少正常逻辑代码的缩进，这有利于提高代码的可读性，便于快速分辨出哪些还是正常逻辑代码， bad： if err != nil { // error handling } else { // normal code } good： if err != nil { // error handling return // or continue, etc. } // normal code 另一种常见的情况，如果我们需要用函数的返回值来初始化某个变量，应该把这个函数调用单独写在一行，例如： 这是一个不好的代码风格，函数调用，初始化变量x，判断错误是否为空都在同一行，并增加了正常逻辑代码的缩进： 如果 if 语句有一个初始化语句，例如： if x, err := f(); err != nil { // error handling return } else { // use x } 应该把函数调用写在单独的一行： x, err := f() if err != nil { // error handling return } // use x ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:16:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Initialisms 单词的命名，如果是首字母缩写或缩略语的词（如 “URL “或 “NATO”）的，那么大小写要一致。例如，“URL “应该作为 “URL “或 “url” （如 “urlPony”，或 “URLPony”），而不是 “Url”。例如，ServeHTTP 而不是 ServeHttp。 这条规则同样适用于 “ID”，当它是 identifier 的缩写的时候，所以应该是 “appID” 而不是 “appId”。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:17:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Interfaces Go 的接口一般属于使用这个接口类型的包，而不是实现这个接口的包。实现包返回具体的（通常是指针或结构）类型：这样，可以在不需要大量重构 的情况下添加新的方法。 不要为了 “mock” 在实现包定义接口，设计的 API 应该可以使用 public API 来测试。 在使用接口之前，不要定义接口：如果没有一个实际的使用示例，很难看出接口是否有必要，更不用说接口应该包含哪些方法了。 package consumer // consumer.go type Thinger interface { Thing() bool } func Foo(t Thinger) string { … } package consumer // consumer_test.go type fakeThinger struct{ … } func (t fakeThinger) Thing() bool { … } … if Foo(fakeThinger{…}) == \"x\" { … } // DO NOT DO IT!!! package producer type Thinger interface { Thing() bool } type defaultThinger struct{ … } func (t defaultThinger) Thing() bool { … } func NewThinger() Thinger { return defaultThinger{ … } } 相反，应该返回一个具体的类型，让 consumer 模拟 producer 实现。 package producer type Thinger struct{ … } func (t Thinger) Thing() bool { … } func NewThinger() Thinger { return Thinger{ … } } ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:18:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Line Length 在 Golang 中，没有严格限制代码行长度，但是应该尽量避免一行内写过长的代码，以及将长代码进行断行。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:19:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Mixed Caps mixed-caps Go 建议使用驼峰式命名，不建议使用下划线命名。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:20:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Named Result Parameters 如果给返回值参数命名，例如： func (n *Node) Parent1() (node *Node) {} func (n *Node) Parent2() (node *Node, err error) {} 但是会影响 godoc，建议使用： func (n *Node) Parent1() *Node {} func (n *Node) Parent2() (*Node, error) {} 另一方面，如果一个函数返回两个或三个相同类型的参数，或者如果一个返回结果的含义从上下文中看不清楚，这个时候就可以给返回值参数命名。 不要为了避免在函数中声明一个变量而给返回值参数命名；这样做是以牺牲不必要的 API 的冗长性为代价，换取了一个小的实现简洁性。 func (f *Foo) Location() (float64, float64, error) 上面的代码没有下面的示例可读性好： // Location returns f's latitude and longitude. // Negative values mean south and west, respectively. func (f *Foo) Location() (lat, long float64, err error) doc 的清晰度永远比在你的功能中保存一两行更重要。 最后，在某些情况下，当你需要在 defer 函数中对返回值做一些事情的时候，给返回值命名是有必要的。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:21:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Package Comments 与 godoc 提供的所有注释一样，包注释必须紧挨着 package 子句，不能出现空行。 // Package math provides basic constants and mathematical functions. package math /* Package template implements data-driven templates for generating textual output such as HTML. .... */ package template 对于 package main 的注释，注释可以放在二进制名之后(如果在前面，可以大写)，例如，对于 seedgen 目录中的一 个 package main，可以这样写: // Binary seedgen ... package main 或者 // Command seedgen ... package main 或者 // Program seedgen ... package main 或者 // The seedgen command ... package main 或者 // The seedgen program ... package main 或者 // Seedgen .. package main 注意，以小写单词开始的句子包注释是不接受得，因为这些都是公开可见的，应该用正确的英文书写，包括将句子的第一个单词大写。当二进制名称 是第一个单词时，即使它与命令行调用的拼写不完全一致，也需要大写。 有关注释的更多信息，可以参考 commentary ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:22:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Package Names 包名应该是全小写单词，不要使用下划线；包名应该尽可能简短。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:23:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Pass Values 不要为了节省几个字节而传递指针作为函数参数。如果一个函数在整个过程中只把参数 x 作为 *x，那么这个参数不应该是一个指针。 除非要传递的是一个庞大的结构体或者可预知在将来会变得非常庞大的结构体，这个时候可以使用指针传递。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:24:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Receiver Names 结构体函数中，接收器的命名不应该采用 “me”，“this”，“self” 等通用的名字，而应该采用简短的 1 或 2 个字符（例如 “Client” 的接收器命名 为 “c” 或 “cl”）并且能反映出结构体名的命名风格。 这个名字不需要像方法参数那样具有描述性，因为它的作用是显而易见的。它应该很简短，因为它可能会出现在该类型的每个方法的每一行中；并且 要保持一致：如果在一个方法中称接收方为 “c”，不要在另一个方法中称它为 “cl”。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:25:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Receiver Type 接收器的类型应该选择值还是指针？ 如果有疑问，那就使用指针。 但有时使用值接收器也是有意义的，通常是为了效率，例如对于一个小的不变的结构体或基本类型的值，使用值接收器。 一些有用的建议： 如果接收器是一个 map, chan, func, 不要使用指针，因为它们本身就是引用类型。 如果接收器是 slice，而这个方法不会对 slice 进行重新切片或者重新分配空间，不要使用指针。 如果方法需要修改接收器，那么必须使用指针。 如果接收器是一个结构体，并且包含了 sync.Mutex 或者类似的用于同步的成员。那么必须使用指针，避免成员拷贝。 如果接收器类型是一个很大的结构体，或者是一个大数组，建议使用指针来提高性能。 如果接收器是结构体，数组或 slice，并且其中的元素是指针，并且方法内部可能修改这些元素，那么建议使用指针。这能使方法的语义更加明确。 如果接收器是小型结构体，小数组，并且不需要修改里面的元素，里面的元素又是一些基础类型，建议使用值。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:26:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Useful Test Failures 测试失败时，应该提供有用的信息（输入是什么，实际得到了什么，以及预期的结果）来说明出现了什么错误。 一个典型的示例： if got != tt.want { t.Errorf(\"Foo(%q) = %d; want %d\", tt.in, got, tt.want) // or Fatalf, if test can't test anything more past this point } 注意，这里的顺序是 实际 != 预期，输出信息也应该使用这个顺序。有些测试框架鼓励倒着写。而 Go 并不是。 如果测试用例比较多，可以写一个 table-driven test 。 另一个消除失败测试的常用技巧，用不同的 TestFoo 函数包装每个调用者。 func TestSingleValue(t *testing.T) { testHelper(t, []int{80}) } func TestNoValues(t *testing.T) { testHelper(t, []int{}) } 总之，任何情况下，你都应该给将来调试你的代码的人一个有用的错误信息。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:27:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Variable Names Go 中的变量名是简短的，局部变量更是如此。例如用 c 来替代 lineCount。用 i 来代替 sliceIndex。 基本规则：名字离它的声明越远，描述性越强。例如方法的接收器，常见的变量，如循环索引，可以是一个字母 “i”。但是特殊的变量和全局变 量可以使用有更多的描述性的长命名。 ","date":"2020-03-11","objectID":"/posts/2020-03-11-go-code-review-comments/:28:0","tags":null,"title":"Go Code Review Comments（翻译）","uri":"/posts/2020-03-11-go-code-review-comments/"},{"categories":["Go"],"content":"Go 提供了 pprof 工具，可以用来做性能分析。pprof 可以读取分析样本的集合，并生成报告以可视化并帮助分析数据。 ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:0:0","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"如何生成分析样本 runtime/pprof：采集程序的运行数据进行分析，通过调用如 runtime.StartCPUProfile, runtime.StopCPUProfile 等 API 生成分析样本。主要用于本地测试。 net/http/pprof：采集 HTTP Server 的运行时数据进行分析，通过 HTTP 服务获取 Profile 分析样本，底层还是调用的 runtime/pprof。主要用于服务器端测试。 go test: 通过 go test -bench=. -cpuprofile cpuprofile.out ... 生成分析样本，主要用于本地基准测试。 ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:1:0","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"如何查看分析报告 ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:2:0","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"导入 pprof 只需要 import _ \"net/http/pprof\" 就可以导入 pprof。 package main import ( \"log\" \"net/http\" _ \"net/http/pprof\" ) func main() { go func() { for { log.Println(Add(\"https://github.com/shipengqi\")) } }() // 注意 net/http/pprof 注册的是默认的 mux http.ListenAndServe(\"0.0.0.0:6060\", nil) } var datas []string func Add(str string) string { data := []byte(str) sData := string(data) datas = append(datas, sData) return sData } ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:2:1","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"查看分析样本 访问 http://localhost:6060/debug/pprof/ 就可以查看分析样本。pprof 包括了一下几个子页面： cpu（CPU Profiling）: \u003cip:port\u003e/debug/pprof/profile?seconds=60，seconds 默认是 30s，表示等待时间 block（Block Profiling）：\u003cip:port\u003e/debug/pprof/block，查看导致阻塞同步的堆栈跟踪 goroutine：\u003cip:port\u003e/debug/pprof/goroutine，查看当前所有运行的 goroutines 堆栈跟踪 heap（Memory Profiling）: \u003cip:port\u003e/debug/pprof/heap，查看活动对象的内存分配情况 mutex（Mutex Profiling）：\u003cip:port\u003e/debug/pprof/mutex，查看导致互斥锁的竞争持有者的堆栈跟踪 threadcreate：\u003cip:port\u003e/debug/pprof/threadcreate，查看创建新 OS 线程的堆栈跟踪 trace\u003cip:port\u003e/debug/pprof/trace?seconds=20，下载 20 秒的 trace 记录 这些分析样本可以直接在终端查看： $ go tool pprof http://localhost:6060/debug/pprof/profile?seconds=60 Fetching profile over HTTP from http://localhost:6060/debug/pprof/profile?seconds=60 Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.samples.cpu.002.pb.gz Type: cpu Time: Jun 12, 2020 at 2:16pm (CST) Duration: 1mins, Total samples = 1.01mins (100.75%) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) top10 Showing nodes accounting for 56.80s, 93.71% of 60.61s total Dropped 142 nodes (cum \u003c= 0.30s) Showing top 10 nodes out of 26 flat flat% sum% cum cum% 55.43s 91.45% 91.45% 55.78s 92.03% runtime.cgocall 0.38s 0.63% 92.08% 57.22s 94.41% internal/poll.(*FD).writeConsole 0.20s 0.33% 92.41% 0.49s 0.81% runtime.mallocgc 0.19s 0.31% 92.72% 0.35s 0.58% unicode/utf16.Encode 0.14s 0.23% 92.95% 0.33s 0.54% runtime.scanobject 0.10s 0.16% 93.12% 0.36s 0.59% log.(*Logger).formatHeader 0.10s 0.16% 93.28% 0.31s 0.51% runtime.schedule 0.09s 0.15% 93.43% 57.60s 95.03% internal/poll.(*FD).Write 0.09s 0.15% 93.58% 0.62s 1.02% main.Add 0.08s 0.13% 93.71% 56.21s 92.74% syscall.WriteConsole # 其他 go tool pprof http://ip:port/debug/pprof/heap go tool pprof http://ip:port/debug/pprof/goroutine go tool pprof http://ip:port/debug/pprof/block go tool pprof http://ip:port/debug/pprof/mutex # 下载 20 秒的 trace 记录 curl http://localhost:6060/debug/pprof/trace?seconds=20 \u003e trace.out # 查看 go tool trace trace.out flat：给定函数上运行耗时 flat%：同上的 CPU 运行耗时总比例 sum%：给定函数累积使用 CPU 总比例 cum：当前函数加上它之上的调用运行总耗时 cum%：同上的 CPU 运行耗时总比例 ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:2:2","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"在 web 中查看 也可以在 web 页面中查看，比如上面的示例，Saved profile in C:\\Users\\shipeng.CORPDOM\\pprof\\pprof.samples.cpu.002.pb.gz 生成了一个 profile 文件，执行 go tool pprof -http=\":8081\" \u003cyour path\u003e/pprof.samples.cpu.002.pb.gz，就可以访问 http://localhost:8081 来查看。 框越大，线越粗代表它占用的时间越大。 火焰图（Flame graph）： 调用顺序由上到下，每一块代表一个函数，越大代表占用 CPU 的时间越长。 还可以查看 Top，Peek，Source 等。能够更方便、更直观的看到 Go 应用程序的调用链、使用情况等。 如果碰到 Could not execute dot; may need to install graphviz.，需要先安装 graphviz。 其他 heap，goroutine 等 profile 文件都可以使用上面的方式查看。 ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:2:3","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"Trace golang 的 GC 是很容易被忽视的性能影响因素。本地 benchmark 测试，由于时间较短，占用内存较少。一般不会触发 GC。线上 GC 问题定位有可以在 线上程序中添加 net/http/pprof，然后可以运行下面的命令： curl http://ip:port/debug/pprof/trace?seconds=20 \u003e trace.out 下载 20 秒的 trace 记录。通过 go tool trace trace.out 会打开一个 web 页面，可以查看 trace 信息。 View trace：查看跟踪 Goroutine analysis：Goroutine 分析 Network blocking profile：网络阻塞概况 Synchronization blocking profile：同步阻塞概况 Syscall blocking profile：系统调用阻塞概况 Scheduler latency profile：调度延迟概况，可以在这里查看整体的调用开销情况。 User defined tasks：用户自定义任务 User defined regions：用户自定义区域 Minimum mutator utilization：最低 Mutator 利用率 如果 View trace 打不开，报错 tr is not defined，看这里。 如果提示 Trace Viewer is running with WebComponentsV0 polyfill, and some features may be broken. As a workaround, you may try running chrome with \"--enable-blink-features=ShadowDOMV0,CustomElementsV0,HTMLImports\" flag. See crbug.com/1036492。可以到 chrome 安装目录执行 .\\chrome.exe --new-window --enable-blink-features=ShadowDOMV0,CustomElementsV0,HTMLImports，在打开 trace 页面。 ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:3:0","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"Goroutine analysis 进入 Goroutine analysis，可以看到程序运行过程中，每个函数块有多少个有 Goroutine 在跑，并且每个 Goroutine 的运行开销。 3 个 goroutine，分别是 runtime.main、runtime/trace.Start.func1、main.main.func1。点击进去查看 goroutine 具体做了些什么。 Execution Time，执行时间 Network Wait Time，网络等待时间 Sync Block Time，同步阻塞时间 Blocking Syscall Time，调用阻塞时间 Scheduler Wait Time，调度等待时间 GC Sweeping GC，GC 清扫时间 GC Pause GC，GC 暂停时间 还可以把 Graph 下载下来分析。 ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:3:1","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"View trace 最上面的刻度表示时间线，如 0μs，200μs PROCS，P 的数量，由 GOMAXPROCS 控制。Proc 0,1,2,3 分别代表 4 个 P。后面对应的是每个 P 上执行的 goroutine。 点击具体的 goroutine 可以查看详细信息： Start：开始时间 Wall Duration：持续时间 Self Time：执行时间 Start Stack Trace：开始时的堆栈信息 End Stack Trace：结束时的堆栈信息 Incoming flow：输入流 Outgoing flow：输出流 Preceding events：之前的事件 Following events：之后的事件，可以在 View 中显示事件流。 All connected：所有连接的事件 ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:3:2","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"使用 GODEBUG 线下环境可以通过添加环境变量 GODEBUG='gctrace=1' 来跟踪打印垃圾回收器信息： GODEBUG='gctrace=1' go run main.go 配置 gctrace=1，垃圾回收器在每次回收时汇总所回收内存的大小以及耗时，并将这些内容汇总成单行内容打印到标准错误输出中。 格式：gc # @#s #%: #+#+# ms clock, #+#/#/#+# ms cpu, #-\u003e#-\u003e# MB, # MB goal, # P gc #，GC 次数的编号，每次 GC 时递增 @#s，距离程序开始执行时的时间 #%，GC 占用的执行时间百分比 #+...+#，GC 使用的时间 #-\u003e#-\u003e# MB，GC 开始，结束，以及当前活跃堆内存的大小，单位M # MB goal，全局堆内存大小 # P，使用 processor 的数量 示例：gc 11 @1.985s 0%: 0+1.0+0 ms clock, 0+1.0/2.0/5.0+0 ms cpu, 4-\u003e4-\u003e0 MB, 5 MB goal, 8 P gc 11：GC 编号 11 @1.985s：程序执行时间 1.985s 0%：1.985s 中 gc 占用了 0% 0+1.0+0 ms clock：垃圾回收的时间，分别为 STW（stop-the-world）清扫的时间 + 并发标记和扫描的时间 + STW 标记的时间 0+1.0/2.0/5.0+0 ms cpu：垃圾回收占用的 cpu 时间 4-\u003e4-\u003e0 MB：GC 开始前堆内存 4M， GC 结束后堆内存 4M，当前活跃的堆内存 0M 5 MB goal：全局堆内存大小 8 P：本次 GC 使用了 8 个 P ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:3:3","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"使用 trace 包 package main import ( \"os\" \"runtime/trace\" ) func main() { // f, _ := os.Create(\"trace.out\") // defer f.Close() // trace.Start(f) trace.Start(os.Stderr) defer trace.Stop() ... } go run main.go 2\u003e trace.out 生成 trace 文件。通过 go tool trace trace.out，查看 trace 信息。 ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:3:4","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Go"],"content":"参考链接 https://github.com/eddycjy/blog/blob/master/content/posts/go/tools/2018-09-15-go-tool-pprof.md https://github.com/eddycjy/blog/blob/master/content/posts/go/tools/2019-07-12-go-tool-trace.md ","date":"2020-02-28","objectID":"/posts/2020-02-28-go-profile/:4:0","tags":null,"title":"Go 如何做性能分析","uri":"/posts/2020-02-28-go-profile/"},{"categories":["Cloud Native"],"content":"使用 kubeadm 安装 kubernetes 集群。 ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:0:0","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Cloud Native"],"content":"准备 一台或多台机器，系统可以是 CentOS 7 或者 Red Hat Enterprise Linux (RHEL) 7。 每台机器至少 2 GB RAM 至少 2 核 CPU 所有机器的网络是可以互相连接的 不可以有重复的主机名，MAC 地址或者 product_uuid。Kubernetes 使用这些值来唯一确定集群中的节点。如果不唯一，会导致安装失败。 使用命令 ip link 或 ifconfig -a 来获取网络接口的 MAC 地址 可以使用 sudo cat /sys/class/dmi/id/product_uuid 命令对 product_uuid 校验 为了保证 kubelet 正常工作，必须禁用交换分区。 关闭防火墙： systemctl stop firewalld systemctl disable firewalld 将 SELinux 设置为 permissive 模式（相当于将其禁用）: setenforce 0 sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config 关闭 swap： vim /etc/fstab 注释 swap 那一行： # # /etc/fstab # Created by anaconda on Thu May 28 14:18:10 2020 # # Accessible filesystems, by reference, are maintained under '/dev/disk' # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=35c960be-191f-4f6a-afb6-e2bf959c4bd4 /boot xfs defaults 0 0 #/dev/mapper/centos-swap swap swap defaults 0 0 ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:1:0","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Cloud Native"],"content":"安装 ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:2:0","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Cloud Native"],"content":"安装 runtime 容器 runtime 优先使用 docker。 配置 yum 代理 vim /etc/yum.conf # 添加行 proxy=\u003chttp proxy\u003e 安装依赖包 $ yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 添加 docker yum 软件源 使用官方源： $ yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装 Docker CE # 更新 yum 软件源缓存 $ yum makecache fast # 安装 docker-ce $ yum install -y docker-ce 添加 docker 代理 为 docker 配置代理： mkdir /etc/systemd/system/docker.service.d vim /etc/systemd/system/docker.service.d/http-proxy.conf # 添加下面的内容 [Service] Environment=\"HTTP_PROXY=\u003chttp proxy\u003e\" \"NO_PROXY=localhost,127.0.0.1\" # 重新载入 systemd，扫描新的或有变动的单元 systemctl daemon-reload 启动 Docker CE systemctl enable docker systemctl start docker ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:2:1","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Cloud Native"],"content":"安装 kubeadm 添加 kubernetes 源： cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF 安装 kubeadm、kubelet 和 kubectl： yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes systemctl enable --now kubelet 为了解决 iptables 被绕过而导致流量无法正确路由的问题，确保 net.bridge.bridge-nf-call-ip6tables 和 net.bridge.bridge-nf-call-iptables 值为 1： sysctl --system 如果不为 1： cat \u003c\u003cEOF \u003e /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:2:2","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Cloud Native"],"content":"初始化 kubeadm init \u003cargs\u003e 输出： Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 16.186.74.208:6443 --token oshoj8.i2up8b5judtojqjl \\ --discovery-token-ca-cert-hash sha256:77d5f9c584b7d1fc4ff7d1e9a61f8b3d29042f8e3bc729cec834a67cb65354bb 根据上面输出中的提示，执行： mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 下面的命令用来将 node 添加到集群： kubeadm join 16.186.74.208:6443 --token oshoj8.i2up8b5judtojqjl \\ --discovery-token-ca-cert-hash sha256:77d5f9c584b7d1fc4ff7d1e9a61f8b3d29042f8e3bc729cec834a67cb65354bb ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:3:0","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Cloud Native"],"content":"安装网络插件 Calico 是 kubeadm 项目中执行 e2e 测试的唯一 CNI 插件。安装 calico： kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml 如果要使用 flannel 作为网络插件，执行 kubeadm init 时使用 --pod-network-cidr 参数。 ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:3:1","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Cloud Native"],"content":"删除 taints 默认情况下，出于安全原因，集群不会在 master node 上调度 Pod。部署单机 Kubernetes 集群，要运行： kubectl taint nodes --all node-role.kubernetes.io/master- 输出看起来像： node \"test-01\" untainted taint \"node-role.kubernetes.io/master:\" not found taint \"node-role.kubernetes.io/master:\" not found Node 的 taint 标记会被删除。 ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:3:2","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Cloud Native"],"content":"查看集群状态 kubectl cluster-info kubectl get node ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:3:3","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Cloud Native"],"content":"添加节点 在一个新的 node 中以前面的步骤安装 docker，kubeadm，kubelet，kubectl。 然后使用 kubeadm init 输出的命令将 node 加入集群： kubeadm join 16.186.74.208:6443 --token oshoj8.i2up8b5judtojqjl \\ --discovery-token-ca-cert-hash sha256:77d5f9c584b7d1fc4ff7d1e9a61f8b3d29042f8e3bc729cec834a67cb65354bb 如果没有令牌，可以通过在控制平面节点上运行以下命令来获取令牌： kubeadm token list 默认情况下，令牌会在 24 小时后过期。如果要在令牌过期后将节点加入集群，运行下面的命令来创建新令牌： kubeadm token create 如果没有 --discovery-token-ca-cert-hash 的值，使用下面的命令获取 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2\u003e/dev/null | \\ openssl dgst -sha256 -hex | sed 's/^.* //' ","date":"2020-02-12","objectID":"/posts/2020-02-12-kubeadm/:4:0","tags":null,"title":"CentOS 上使用 kubeadm 安装 kubernetes","uri":"/posts/2020-02-12-kubeadm/"},{"categories":["Others"],"content":"Git 是一个非常强大的版本控制工具，是程序员必须要掌握的技能。 这里记录常用的命令技巧和碰到的一些问题。 首先应该了解 Git 里面的几个概念。 Workspace：工作区 Index/Stage：暂存区（使用 git add 命令将工作区的改动添加到暂存区） Repository：本地仓库（使用 git commit 命令将暂存区的改动提交到本地仓库） HEAD：指向本地仓库的当前版本，上一个版本就是 HEAD^，上上一个版本就是 HEAD^^，往上 10 个版本，可以 写成 HEAD~10。 Remote：远程仓库 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:0:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"克隆仓库 git clone git@github.com:shipengqi/shipengqi.github.io.git \u003ctarget dir\u003e -b \u003cbranch\u003e 将 shipengqi.github.io.git 克隆到 target dir 指定的文件夹（默认是远程仓库的名字），并切换到指定 分支 branch（默认是 master 分支）。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:1:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"未暂存的内容 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:2:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"把未暂存的内容添加到暂存区 # 提交所有改动 git add -A # 提交被修改 (modified) 和被删除 (deleted) 文件，不包括新文件 (new) git add -u # 提交新文件 (new) 和被修改 (modified) 文件，不包括被删除 (deleted) 文件 git add . # 添加指定文件到暂存区 git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 git add [dir] # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 git add -p ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:2:1","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"把未暂存的内容移动到一个新分支 git checkout -b new-branch ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:2:2","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"把未暂存的内容移动到另一个已存在的分支 git stash git checkout my-branch git stash pop ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:2:3","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"放弃未暂存的修改 git checkout \u003cfile-name\u003e # 放弃所有修改 git checkout . ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:2:4","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"暂存的内容 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:3:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"把暂存的内容添加到上一次的提交 git commit --amend ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:3:1","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"取消暂存的内容 添加到暂存区的文件，但是还没有提交，如果想要撤销暂存的文件，可以使用 git reset HEAD \u003cfile1\u003e \u003cfile2\u003e... 的方式取消暂存。 git reset HEAD file2 # 或者 git restore --staged \u003cfile\u003e... # 同时删除工作区和暂存区中的文件 git rm [file1] [file2] ... # 从暂存区删除文件, 但工作区不删除 git rm --cached [file] 这样 file2 文件又回到了之前已修改未暂存的状态。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:3:2","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"编辑提交 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"修改提交信息 # 打开默认编辑器 git commit --amend --only # 或者 git commit --amend --only -m 'xxxxxxx' 如果已经 push 了这次提交, 那么可以修改这次提交(commit)然后强推(force push), 但是不推荐。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:1","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"编辑指定 commit 的提交信息 编辑指定 commit 的提交信息，可以先使用 rebase 来修改某一次的提交信息 如果当前在 main 分支： git rebase -i main^^\r# 使用 commit 生成的哈希值来定位\rgit rebase -i aa588cd\rgit rebase -i aa588cd72b95ab35ec6e15637fb1e110281b2200 main^^ 表示当前 main 指向的 commit 之前倒数第 2 个 commit。main~2 也是一样的意思。^ 和 ~{count} 都是表示把 commit 往回偏移。 执行上面的命令之后，会进入如下的编辑界面： pick aa588cd display error\rpick e10dddf regex draft\r# Rebase aa588cd..e10dddf onto aa588cd (2 commands)\r#\r# Commands:\r# p, pick = use commit\r# r, reword = use commit, but edit the commit message\r# e, edit = use commit, but stop for amending\r# s, squash = use commit, but meld into previous commit\r# f, fixup = like \"squash\", but discard this commit's log message\r# x, exec = run command (the rest of the line) using shell\r# d, drop = remove commit\r#\r# These lines can be re-ordered; they are executed from top to bottom.\r#\r# If you remove a line here THAT COMMIT WILL BE LOST.\r#\r# However, if you remove everything, the rebase will be aborted.\r#\r# Note that empty commits are commented out 找到想要修改的 commit，将 pick 改为 edit，然后 wq 保存退出，接着再运行： git commit --amend -m 'changed commit mesasge' ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:2","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"修改提交里的用户名和邮箱 git commit --amend --author \"New Authorname \u003cwork@example.com\u003e\" 改完信息后，还需要 git rebase --continue，将基准从当前倒数第二位置移到最新一次提交。git log 去检查下状态。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:3","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"commit 添加签名 git commit -m \"xx\" -s 如果你配置了 username 和 email，参数 -s 会自动在 commit 的信息中添加签名，如下： commit d52618492b788425b7c86d25c5e37eb67fd8fba6\rAuthor: shipengqi \u003cxxx@gmail.com\u003e\rDate: Mon May 2 18:36:11 2022 +0800\rregex draft\rSigned-off-by: shipengqi \u003cxxx@gmail.com\u003e ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:4","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"从一个提交(commit)里移除一个文件 从一个提交(commit)里移除一个文件: git checkout HEAD^ myfile git add -A git commit --amend 当你有一个开放的补丁(open patch)，你往上面提交了一个不必要的文件，需要强推(force push)去更新这个远程补丁。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:5","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"撤销某一次提交 修改已经提交到了当前分支，但是还没有 push 到远程仓库 git reset --hard HEAD^ # 回退到指定的版本 git reset --hard \u003ccommit id\u003e # 只撤销提交，但不改变代码 git reset HEAD^ git reset commit-id 已经 push 到远程仓库的提交 已经 push 到远程仓库的提交，使用 git revert，回滚到指定的历史版本,再 git push 更新远程仓库。 # 撤销某个 commit 版本 git revert commit-id 对于已经 push 到远程仓库的提交，也可以使用 reset，然后执行 git push -f 强制推到远程仓库中去，但是可能导致冲突。 如果只是回退到上一个 commit，建议使用 revert，如果要回退到多个版本之前，还是要使用 reset。 revert 与 reset 的区别 reset 是在正常的 commit 历史中,删除了指定的 commit，这时 HEAD 是向后移动了，而 revert 是在正常的 commit 历史中再 commit 一 次，HEAD 是一直向前的。 对于已经把代码已经 push 到远程仓库，reset 删除指定 commit 以后，push 可能导致一大堆冲突.但是 revert 不会。 revert 是撤销指定的某个 commit 版本，但是指定 commit 之后的版本，还会保留下来。reset 是将 HEAD 移动到了指定的 commit， 指定 commit 之后的版本都会被丢弃。 如果想恢复到之前某个提交的版本，且那个版本之后提交的版本都不要了，就用 reset。 如果想撤销之前的某一版本，但是又想保留该目标版本后面的版本，就用 revert。 revert Merge Commit 执行 git revert commitId 可能会报错： error: commit xxxxxxxxxxx is a merge but no -m option was given. 这是因为指定的 commit 是一次 merge，需要 -m 参数指定要 revert 的这个 merge commit 中的哪一个。 比如：git revert HEAD~1 -m 1 会 revert 第一个 commit。 你也可以在 git log 找到你要 revert 的那个 commit。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:6","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"意外的做了一次硬重置(hard reset)，如何找回内容 当你用 git reset --hard HEAD^ 回退到上个版本时，再想恢复，就必须找到要恢复版本的 commit id。可以通过 git reflog 找到 那次 commit。 选择你想要回到的提交(commit)的 commit id，再重置一次: git reset --hard SHA1234 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:7","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"提交错分支怎么办 还没有提交代码 比如忘了创建分支，并且 master 的代码可能还不是最新的，但是已经直接在 master 分支上进行了修改。这种情况下可以先把代码暂存起来，然后把 master 分 支更新到最新，再创建并切换到新的分支，然后把暂存的代码恢复回来。 # 暂存代码 git stash # 更新 master git fetch git merge origin/master # 创建新的分支并切换过去 git checkout -b \u003cname\u003e # 把暂存的代码恢复回来 git stash pop 然后就可以直接 commit 了。 已经提交 代码提交了，还没有 push，这个时候可以先把它撤回来 git reset HEAD^ 这样就把上一次的提交恢复为未提交的状态了，如果确定当前所在的 master 分支代码已经是最新的，就可以直接 checkout 到新的分支，来进行提交。否则，就就参考第一种情况。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:8","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"查看 commit 历史 # 显示当前分支的版本历史 git log # 显示 commit 历史，以及每次 commit 发生变更的文件 git log --stat # 搜索提交历史，根据关键词 git log -S [keyword] # 显示某个 commit 之后的所有变动，每个 commit 占据一行 git log [tag] HEAD --pretty=format:%s # 显示某个 commit 之后的所有变动，其\"提交说明\"必须符合搜索条件 git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 git log --follow [file] git whatchanged [file] # 显示指定文件相关的每一次 diff git log -p [file] # 显示过去 5 次提交 git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 git shortlog -sn # 显示指定文件是什么人在什么时间修改过 git blame [file] # 查看命令历史 git reflog 回退前，用 git log 可以查看提交历史，以便确定要回退到哪个版本。 回退后，用 git reflog 查看命令历史，以便确定要回到未来的哪个版本。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:9","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"查看某次提交 # 显示某次提交的元数据和内容变化 git show [commit] # 显示某次提交发生变化的文件 git show --name-only [commit] # 显示某次提交时，某个文件的内容 git show [commit]:[filename] ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:4:10","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"Stash stash 和 add 的区别: git stash 的作用是把工作区(必须是工作区中已经被 git 追踪到的文件)和暂存区中的内容暂时存到一个栈上。而且这个堆是和分支不 相关的。切换分支后，依然可以看到并使用。 git add 命令将修改添加到暂存区。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:5:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"暂存工作目录下的所有改动 git stash ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:5:1","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"暂存所有改动，包括 untracked 的文件（新建的文件） git stash -u ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:5:2","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"暂存指定文件 # 暂存某一个文件 git stash push working-directory-path/filename.ext # 暂存多个文件 git stash push working-directory-path/filename1.ext working-directory-path/filename2.ext ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:5:3","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"暂存时记录消息 git stash save \u003cmessage\u003e # 或 git stash push -m \u003cmessage\u003e ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:5:4","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"使用某个指定暂存 # 查看 stash 记录 git stash list # apply 某个 stash git stash apply \"stash@{n}\" n 是 stash 在栈中的位置，最上层的 stash 会是 0。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:5:5","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"使用最后一个 stash 的状态，并删除这个 stash git stash pop ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:5:6","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"删除所有的 stash git stash clear ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:5:7","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"仅从 stash 中拿出某个文件的修改 git checkout \u003cstash@{n}\u003e -- \u003cfile-path\u003e ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:5:8","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"比较差异 # 显示暂存区和工作区的差异 git diff # 显示本地仓库中任意两个 commit 之间的文件变动 git diff \u003ccommit-id\u003e \u003ccommit-id\u003e # 显示暂存区和最近的 commit 的不同 git diff --cached # 显示工作区与当前分支最新 commit 之间的差异 git diff HEAD ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:6:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"分支 # 切换分支 git checkout dev # 切换并新建一个分支 git checkout -b newBranch # 删除一个分支 git branch -d branch # 列出所有本地分支 git branch # 列出所有远程分支 git branch -r # 列出所有本地分支和远程分支 git branch -a # 删除远程分支 git push origin --delete [branch-name] git branch -dr [remote/branch] # 合并指定分支到当前分支 git merge [branch] # 选择一个 commit，合并进当前分支 git cherry-pick [commit] # 关联远程分支 git branch -u origin/mybranch # 或者在 push 时加上 -u 参数 git push origin/mybranch -u # 重命名本地分支 git branch -m \u003cnew-branch-name\u003e ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:7:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"需要提交到一个新分支，但错误的提交到了 master 在 master 下创建一个新分支，不切换到新分支,仍在 master 下: (master)$ git branch my-branch 把 master 分支重置到前一个提交: (master)$ git reset --hard HEAD^ checkout 到刚才新建的分支继续工作: (master)$ git checkout my-branch ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:7:1","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"从错误的分支拉取了内容，或把内容拉取到了错误的分支 使用 git reflog 找到在这次 pull 之前 HEAD 的指向。 (master)$ git reflog ab7555f HEAD@{0}: pull origin wrong-branch: Fast-forward c5bc55a HEAD@{1}: checkout: checkout message goes here 重置分支到你所需的提交： git reset --hard c5bc55a ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:7:2","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"恢复误删除的分支 有些时候可能删除了还没有推到远程的分支，如何恢复？例，创建一个分支，并做一次提交: (master)$ git checkout -b my-branch (my-branch)$ git branch (my-branch)$ touch foo.txt (my-branch)$ ls README.md foo.txt (my-branch)$ git add . (my-branch)$ git commit -m 'foo.txt added' (my-branch)$ foo.txt added 1 files changed, 1 insertions(+) create mode 100644 foo.txt 现在我们切回到主(master)分支，‘不小心的’删除 my-branch 分支 (my-branch)$ git checkout master Switched to branch 'master' Your branch is up-to-date with 'origin/master'. (master)$ git branch -D my-branch Deleted branch my-branch (was 4e3cd85). (master)$ echo oh noes, deleted my branch! oh noes, deleted my branch! 开始恢复删除的分支，先使用 reflog 命令, 它存储了仓库(repo)里面所有动作的历史。 (master)$ git reflog 69204cd HEAD@{0}: checkout: moving from my-branch to master 4e3cd85 HEAD@{1}: commit: foo.txt added 69204cd HEAD@{2}: checkout: moving from master to my-branch 可以看到一个删除分支的提交 hash(commit hash)，开始恢复： (master)$ git checkout -b my-branch-help Switched to a new branch 'my-branch-help' (my-branch-help)$ git reset --hard 4e3cd85 HEAD is now at 4e3cd85 foo.txt added (my-branch-help)$ ls README.md foo.txt ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:7:3","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"标签 # 查看标签 git tag # 展示当前分支的最近的 tag git describe --tags --abbrev=0 # 查看标签详细信息 git tag -ln # 本地创建标签 git tag [version-number] # 默认 tag 是打在最近的一次 commit 上，指定 commit 打 tag git tag -a [version-number] -m \"v1.0 发布(描述)\" [commit-id] # 推送标签到远程仓库，保证本地创建好了标签才可以推送标签到远程仓库： git push origin [local-version-number] # 一次性推送所有标签 git push origin --tags # 删除本地标签 git tag -d [tag-name] # 删除远程标签 git push origin --delete tag [tagname] # 切回到某个标签 git checkout -b branch_name tag_name ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:8:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"恢复已删除标签 首先, 需要找到无法访问的标签(unreachable tag): git fsck --unreachable | grep tag 得到这个标签(tag)的 hash，然后: git update-ref refs/tags/\u003ctag_name\u003e \u003chash\u003e 这时标签(tag)应该已经恢复了。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:8:1","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"远程仓库 # 下载远程仓库的所有变动 git fetch # 显示所有远程仓库 git remote -v # 显示某个远程仓库的信息 git remote show [remote] # 增加一个新的远程仓库，并命名 git remote add [shortname] [url] # 修改远程仓库的 url git remote set-url [remote] [url] # 取回远程仓库的变化，并与本地分支合并 git pull [remote] [branch] # 上传本地指定分支到远程仓库 git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 git push [remote] --force # 推送所有分支到远程仓库 git push [remote] --all ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:9:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"同步远程仓库到自己 fork 的仓库 如果一个项目多人维护，每个人都 fork 了主仓库，并修改，提交 PR，那么如果在你提交自己的修改之前，主仓库 merge 了别人的 PR， 你 fork 的仓库的 commit 就会落后于主仓库，例如会有类似 This branch is 12 commit behind ITOM-Shared-Services:master. 的提示。这个时候 直接提交你的代码，创建 PR，如果 merge 你的 PR，可能就会有冲突，怎么解决？ 切换在你本地的仓库 添加 remote git remote add itom git@github.houston.softwaregrp.net:ITOM-Shared-Services/keel-service.git 上面的命令中 itom 是给这个 remote 命名，git@github.houston.softwaregrp.net:ITOM-Shared-Services/keel-service.git 是 remote 的地址。 验证 git remote -v 在每次提交前执行 git pull itom master，可以把主仓库的最新 commits 拉去到本地。 提交代码 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:9:1","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"Rebase 和 Merge ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:10:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"rebase 和 merge 有什么区别 rebase rebase 会把你当前分支的 commit 放到公共分支的最后面,所以叫变基。 例如，你从 master 拉了个 feature 分支出来,然后你提交了几个 commit,这个时候刚好有人把他开发的东西合并到 master 了,这个时 候 master 就比你拉分支的时候多了几个 commit,如果这个时候你 rebase master 的话，就会把你当前的几个 commit，放到那个 人 commit 的后面。 merge merge 会把公共分支和你当前的 commit 合并在一起，形成一个新的 commit 提交。 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:10:1","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"撤销 rebase/merge 如果 merge 或 rebase 了一个错误的分支, 或者完成不了一个进行中的 rebase/merge。 Git 在进行危险操作的时候会把原始的 HEAD 保 存在一个叫 ORIG_HEAD 的变量里, 所以要把分支恢复到 rebase/merge 前的状态是很容易的。 git reset --hard ORIG_HEAD ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:10:2","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"配置 ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:11:0","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"配置 http 和 socks 代理 git config --global https.proxy 'http://127.0.0.1:8001' git config --global http.proxy 'http://127.0.0.1:8001' git config --global socks.proxy \"127.0.0.1:1080\" ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:11:1","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"配置常用的命令别名 git config --global alias.st status git config --global alias.br branch git config --global alias.co checkout git config --global alias.ci commit 如： git config --global alias.st status 可以使用 git st 代替 git status。 或者修改配置文件，Linux 下, Git 的配置文件储存在 ~/.gitconfig。在 [alias] 部分添加快捷别名，如下： [alias] a = add amend = commit --amend c = commit ca = commit --amend ci = commit -a co = checkout d = diff dc = diff --changed ds = diff --staged f = fetch loll = log --graph --decorate --pretty=oneline --abbrev-commit m = merge one = log --pretty=oneline outstanding = rebase -i @{u} s = status unpushed = log @{u} wc = whatchanged wip = rebase -i @{u} zap = fetch -p ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:11:2","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"配置 git log 格式 原生的 git log 不太好用，一样可以配置： git config --global alias.lg 'log --color --graph --pretty=format:\"%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u003c%an\u003e%Creset\" --abbrev-commit' 然后git lg就成了下面的样子： ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:11:3","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Others"],"content":"生成压缩包 git archive ","date":"2020-01-31","objectID":"/posts/2020-01-31-git-usage/:11:4","tags":null,"title":"Git 的一些使用技巧","uri":"/posts/2020-01-31-git-usage/"},{"categories":["Go"],"content":"标准的 Go 项目布局，project-layout 翻译。 这是一个 Go 应用项目的基本布局。它不是官方核心 Go dev 团队定义的标准；然而，它是 GO 生态圈中一套历史上和新兴项目中常见的布局模式。其中 一些模式比其他模式更受欢迎。它还有一些小的增强,以及一些对于任何一个大真实世界应用程序，都通用的支持目录。 如果你正在学习 GO,或者你正在自己创建一个 PoC 或只是简单玩一玩, 那这个项目布局对你来说有点过头了。从简单的东西开始（一个 main.go 文件就足够 了）。随着你的项目的发展，确保你的代码结构良好是非常重要的，否则你最终会有很多隐藏的依赖和全局状态的混乱代码。当有更多人在项目上工作时，就需要更多 的结构。这时就需要引入一种通用的方式来管理软件 packages/libraries。当你有一个开源项目，或者其他项目从你的项目库中导入代码时，这时就需要私有 的（internal）包和代码。 Clone project-layout 仓库, 保留你需要的东西，然后删除所有其他的东西。虽然它在那里，但并不意味着你必须全部使用它。 这些模式并不是在每一个项目都会用到的。即使是 vendor 模式也不是万能的。 随着 Go 1.14 版本的发布，Go Modules 终于可以用于生产环境了。使用 Go Modules 除非 你有特定的理由不使用它。使用 Go Modules 就不再需要担心 $GOPATH 和项目要放在哪里。 项目中的 go.mod 文件会假设你的项目托管在 Github 上，但这并不是必须的。模块路径可以是任何东西，但第一个模块路径组件的名称中应该有一个 点（当前版本的 Go 不再强制要求它，但如果你使用的是稍旧的版本，如果构建失败了，不要惊讶）。如果你想了解更多，可以参 考 issue 37554 和 32819 。 这个项目布局是通用为主的，它不试图强加一个特定的 Go 包结构。 如果你在命名、格式化和样式方面需要帮助，可以从运行 gofmt 和 golint 开始。此外，请务必阅读这些 Go 的代码规范指南和建议。 https://talks.golang.org/2014/names.slide https://golang.org/doc/effective_go.html#names https://blog.golang.org/package-names https://github.com/golang/go/wiki/CodeReviewComments Style guideline for Go packages (rakyll/JBD) 可以查看 Go Project Layout 的历史背景信息。 更多关于命名和组织包以及代码结构的建议： GopherCon EU 2018: Peter Bourgon - Best Practices for Industrial Programming GopherCon Russia 2018: Ashley McNamara + Brian Ketelsen - Go best practices. GopherCon 2017: Edward Muller - Go Anti-Patterns GopherCon 2018: Kat Zien - How Do You Structure Your Go Apps ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:0:0","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"Go 目录 目录结构示例： . ├── api ├── assets ├── build │ ├── ci │ └── package ├── cmd │ └── _your_app_ ├── configs ├── deployments ├── docs ├── examples ├── githooks ├── init ├── internal │ ├── app │ │ └── _your_app_ │ └── pkg │ └── _your_private_lib_ ├── pkg │ └── _your_public_lib_ ├── scripts ├── test ├── third_party ├── tools ├── vendor ├── web │ ├── app │ ├── static │ └── template ├── website ├── README.md ├── LICENSE.md ├── Makefile ├── go.mod └── .gitignore ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:1:0","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/cmd 项目中的主要应用程序。 每个应用程序的目录名应该与你想要的可执行文件的名相匹配（例如，/cmd/myapp）。 不要在此目录中放置大量代码。如果你认为这个代码可以被其他项目引用，那么它应该存在于 /pkg 目录。如果代码不可重用，或者如果不希望其他人重用它，那么将 代码放入 /internal 目录。 比较常见的项目，有一个小的 main 函数，从 /internal 和 /pkg 目录中导入并调用代码，其他的都不需要。 例子: https://github.com/heptio/ark/tree/master/cmd (只是一个非常小的 main 函数，其他的东西都在包里) https://github.com/moby/moby/tree/master/cmd https://github.com/prometheus/prometheus/tree/master/cmd https://github.com/influxdata/influxdb/tree/master/cmd https://github.com/kubernetes/kubernetes/tree/master/cmd ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:1:1","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/internal 私有应用程序和库代码。这是你不希望别人在他们的应用程序或库中导入的代码。 注意，这个布局模式是由 Go 编译器本身执行的。更多细节请参见 Go 1.4 release notes 。 注意，你并不局限于顶层的 internal 目录。你可以在你的项目树的任何层级上有一个 internal 目录。 Go 语言的构建工具对包含 internal 名字的路径段的包导入路径做了特殊处理。一个 internal 包只能被和 internal 目录有同一个父目录的 包所导入。例如，net/http/internal/chunked 内部包只能被 net/http/httputil 或 net/http 包导入，但是不能被 net/url 包导入。 你可以选择在你的内部包中添加一些额外的结构，将共享和非共享的内部代码分开。这并不是必须的（尤其是对于较小的项目来说），但如果能有可视化的线索显 示出预定的包的用途就很好了。 将实际应用程序代码放入 /internal/app 目录(例如，/internal/app/myapp。应用程序共享的代码可以放在 /internal/pkg 目录(例如， /internal/pkg/myprivlib)。 例子： https://github.com/hashicorp/terraform/tree/master/internal https://github.com/influxdata/influxdb/tree/master/internal https://github.com/perkeep/perkeep/tree/master/internal https://github.com/jaegertracing/jaeger/tree/master/internal https://github.com/moby/moby/tree/master/internal https://github.com/satellity/satellity/tree/master/internal ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:1:2","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/pkg 可以被外部应用程序使用的库代码(例如，/pkg/mypubliclib)。其他项目将导入这些库，并希望它们能工作，所以在你把东西放在这里之前要三思。 需要注意的是，使用 internal 目录来保证你的私有包不能被导入是一个比较好的方法，因为它是由 Go 强制执行的。 /pkg 目录中的代码应该是可以被安全的导入使用的。Travis Jeffery 的 blog I'll take pkg over internal 提供了关于 pkg 和 internal 目录的一个很好的概述，以及什么时候使用它们可能有意义。 如果你的应用程序项目真的很小，而且额外的嵌套不会增加多少价值（除非你真的想用），那就不要用它。当它变得足够大，而你的根目录变得相当繁忙时，再考虑 使用（尤其是当你有很多非 Go 的应用组件时）。 例子： https://github.com/prometheus/prometheus/tree/master/pkg https://github.com/jaegertracing/jaeger/tree/master/pkg https://github.com/istio/istio/tree/master/pkg https://github.com/GoogleContainerTools/kaniko https://github.com/google/gvisor/tree/master/pkg https://github.com/google/syzkaller/tree/master/pkg https://github.com/perkeep/perkeep/tree/master/pkg https://github.com/minio/minio/tree/master/pkg https://github.com/heptio/ark/tree/master/pkg https://github.com/argoproj/argo/tree/master/pkg https://github.com/heptio/sonobuoy/tree/master/pkg https://github.com/helm/helm/tree/master/pkg https://github.com/kubernetes/kubernetes/tree/master/pkg https://github.com/kubernetes/kops/tree/master/pkg https://github.com/moby/moby/tree/master/pkg https://github.com/grafana/grafana/tree/master/pkg https://github.com/influxdata/influxdb/tree/master/pkg https://github.com/cockroachdb/cockroach/tree/master/pkg https://github.com/derekparker/delve/tree/master/pkg https://github.com/etcd-io/etcd/tree/master/pkg https://github.com/oklog/oklog/tree/master/pkg https://github.com/flynn/flynn/tree/master/pkg https://github.com/jesseduffield/lazygit/tree/master/pkg https://github.com/gopasspw/gopass/tree/master/pkg https://github.com/sosedoff/pgweb/tree/master/pkg https://github.com/GoogleContainerTools/skaffold/tree/master/pkg https://github.com/knative/serving/tree/master/pkg https://github.com/grafana/loki/tree/master/pkg https://github.com/bloomberg/goldpinger/tree/master/pkg https://github.com/crossplaneio/crossplane/tree/master/pkg https://github.com/Ne0nd0g/merlin/tree/master/pkg https://github.com/jenkins-x/jx/tree/master/pkg https://github.com/DataDog/datadog-agent/tree/master/pkg https://github.com/dapr/dapr/tree/master/pkg https://github.com/cortexproject/cortex/tree/master/pkg https://github.com/dexidp/dex/tree/master/pkg https://github.com/pusher/oauth2_proxy/tree/master/pkg https://github.com/pdfcpu/pdfcpu/tree/master/pkg https://github.com/weaveworks/kured/pkg https://github.com/weaveworks/footloose/pkg https://github.com/weaveworks/ignite/pkg https://github.com/tmrts/boilr/tree/master/pkg ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:1:3","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/vendor 应用程序依赖(手动管理，或你喜欢的依赖管理工具，Go Modules)。 go mod vendor 命令将为你创建 /vendor 目录。请注意，如果你不是使 用 Go 1.14，你可能需要在你的 go build 命令中添加 -mod=vendor 标志，因为 Go 1.14 的默认值是 on。 如果你正在构建一个库，不要提交你的应用程序依赖项。 注意，从 1.13 开始，Go 启用了模块代理功能（默认使用 https://proxy.golang.org 作为 模块代理服务器）。阅读更多关于它的 信息 ，看看它是否符合你的所有要求和限制。如果符合， 那么你就完全不需要 vendor 目录了。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:1:4","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"服务应用目录 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:2:0","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/api OpenAPI/Swagger 规范，JSON schema 文件，协议定义文件。 例子： https://github.com/kubernetes/kubernetes/tree/master/api https://github.com/openshift/origin/tree/master/api ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:2:1","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"Web 应用程序目录 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:3:0","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/web Web 应用程序特定组件:静态 Web 资产、服务器端模板和 SPAs。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:3:1","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"通用应用程序目录 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:4:0","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/configs 配置文件模板，或默认配置文件。 把你的 confd或 consul-template 模板文件放在这里。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:4:1","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/init 系统初始化(systemd, upstart, sysv)和进程管理器/supervisor (runit, supervisord)配置。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:4:2","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/scripts 执行各种构建、安装、分析等操作的脚本。 这些脚本，可让根目录的 Makefile 文件保持小而简单(例如，https://github.com/hashicorp/terraform/blob/master/Makefile) 例子： https://github.com/kubernetes/helm/tree/master/scripts https://github.com/cockroachdb/cockroach/tree/master/scripts https://github.com/hashicorp/terraform/tree/master/scripts ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:4:3","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/build 打包与持续集成。 将云(AMI)、容器(Docker)、OS(deb、rpm、pkg)包配置和脚本放入 /build/package 目录。 把你的 CI(travis， circle， drone) 配置和脚本放在 /build/ci 目录。请注意，一些 CI 工具(例如，Travis CI)对配置文件的位置非常挑剔。在 尝试将配置文件放入 /build/ci 之后，请将它们链接到 CI 工具期望的位置(如果可能的话). ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:4:4","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/deployments IaaS、PaaS、system 和 容器编排部署 配置和模板(docker-compose, kubernetes/helm, mesos, terraform, bosh)。 注意，在一些项目中（尤其是使用 kubernetes 部署的应用程序），这个目录被称为 /deploy。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:4:5","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/test 额外的外部测试应用程序和测试数据。你可以随意构造 /test。或对于更大的项目来说，可以有一个数据子目录。例如，/test/data 或/test/testdata， 如果你需要 Go 忽略这个目录中的内容。注意，Go 还将忽略以 . or _ 开头的目录或文件，因此在如何命名测试数据目录方面，具有更大的灵活性. 例子： https://github.com/openshift/origin/tree/master/test (test data is in the /testdata subdirectory) ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:4:6","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"其他目录 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:5:0","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/docs 程序设计和用户文档(除 godoc 生成的文档之外)。 见/docs目录的例子。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:5:1","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/tools 支撑该项目的工具。请注意，这些工具可以从 /pkg 和 /internal 目录导入和使用代码。 例子： https://github.com/istio/istio/tree/master/tools https://github.com/openshift/origin/tree/master/tools https://github.com/dapr/dapr/tree/master/tools ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:5:2","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/examples 应用程序，公共包的示例。 例子： https://github.com/nats-io/nats.go/tree/master/examples https://github.com/docker-slim/docker-slim/tree/master/examples https://github.com/gohugoio/hugo/tree/master/examples https://github.com/hashicorp/packer/tree/master/examples ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:5:3","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/third_party 外部辅助工具、被 fork 的代码和其他第三方实用程序(例如，Swagger UI)。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:5:4","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/githooks Git 钩子。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:5:5","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/assets 与项目一起使用的其他资源(图像、logos 等)。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:5:6","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/website 如果你没有使用 Github pages，这是放置项目网站的地方。 例子： https://github.com/hashicorp/vault/tree/master/website https://github.com/perkeep/perkeep/tree/master/website ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:5:7","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"你不应该拥有的目录 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:6:0","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"/src 一些 GO 项目确实有 src 文件夹，但这种是在 Java 世界的开发中比较常见的模式。如果你不想让你的 Go 代码或 Go 项目看起来像 Java，就尽量不要使用 这种模式。 不要把项目级别的 /src 目录与 Go 的工作空间使用的 /src 目录混为一谈，如 How to Write Go Code 中的描述。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:6:1","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"徽章 Go Report Card它会用 gofmt，go vet，gocyclo，golint，ineffassign，license 和 misspell 扫描你代码。将 github.com/golang-standards/project-layout 替换为你的项目。 GoDoc 提供 GoDoc 生成文档的在线版本。请将链接更改为指向你项目的链接。 Release 它将显示项目的最新发布号。更改 Github 链接指向你的项目。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:7:0","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Go"],"content":"Note 一个更具自信心的项目模板，具有可重用的配置、脚本和代码。WIP-工作正在进行中。 ","date":"2020-01-17","objectID":"/posts/2020-01-17-project-layout-cn/:8:0","tags":null,"title":"Go project-layout（翻译）","uri":"/posts/2020-01-17-project-layout-cn/"},{"categories":["Node.js"],"content":"Node.js 的性能分析工具 v8-profiler 可以采集性能分析样本。 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:0:0","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"性能分析工具 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:1:0","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"v8-profiler const v8Profiler = require('v8-profiler'); const title = 'test'; v8Profiler.startProfiling(title, true); setTimeout(() =\u003e { const profiler = v8Profiler.stopProfiling(title); profiler.delete(); console.log(profiler); }, 5000); 上面的示例，会采集运行 5s 内的分析样本。 v8-profiler 貌似已经不再维护了，可以尝试 v8-profiler-next。 v8-profiler 生成的 profile 文件如何分析可以看 这里。 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:1:1","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"webstrom v8 profiling 也可以使用 webstrom 的 v8 profiling： 选择 Edit Configuration，切换到 V8 Profiling，选中 Record CPU profiling info ，然后运行代码，就可以了。 Log folder 可以指定生成分析样本文件的目录，样本文件的命名格式是 isolate-\u003csession number\u003e。 我使用的就是 webstrom 的 v8 profiling。 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:1:2","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"准备工作 示例： const App = require('..'); const fs = require('fs'); function run() { let app = new App(); app.bindAny('age', 18); app.use(($age, $ctx, $next) =\u003e { console.log('app middleware1'); console.log('age' + $age); $next(); }); app.use(($ctx, $age, $next, $address) =\u003e { console.log('app middleware2'); console.log('age' + $age); console.log('address', $address); $next(); }); app.get('/users/:name', ($age, $ctx, $next, $address) =\u003e { console.log('users/name middleware1'); console.log($ctx.params.name); console.log('age' + $age); console.log('address', $address); $ctx.params.id = 'user1'; $next(); }, async ($age, $ctx, $next, $address) =\u003e { console.log('users/name middleware2'); console.log($ctx.params.name, $ctx.params.id); console.log('age' + $age); console.log('address', $address); await read(); $ctx.body = 'hello, ' + $ctx.path; }); app.get('/users/', ($age, $ctx, $next, $address) =\u003e { console.log('users middleware1'); console.log('age' + $age); console.log('address', $address); $ctx.params.id = 'user1'; $next(); }, ($age, $ctx, $next, $address) =\u003e { console.log('users middleware2'); console.log($ctx.params.id); console.log('age' + $age); $ctx.body = 'hello, ' + $ctx.path; }); app.use(($address, $ctx, $next, $age, $getAddress) =\u003e { console.log('app middleware3'); console.log('age' + $age); console.log('address', $address); console.log('getAddress', $getAddress); $next(); }); app.bindAny('address', 'shanghai'); app.bindFunction('getAddress', $address =\u003e { return $address; }); app.listen(8080); } function read() { return new Promise((resolve, reject) =\u003e { fs.writeFile('test.log', `test`, {flag:'a',encoding:'utf-8',mode:'0666'},() =\u003e { resolve(); }) }) } run(); 使用 AB 进行压力测试： [root@SGDLITVM0905 ~]# ab -n 10000 -c 100 http://10.5.41.247:8080/users/pooky This is ApacheBench, Version 2.3 \u003c$Revision: 1430300 $\u003e Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking 10.5.41.247 (be patient) Completed 1000 requests Completed 2000 requests Completed 3000 requests Completed 4000 requests Completed 5000 requests Completed 6000 requests Completed 7000 requests Completed 8000 requests Completed 9000 requests Completed 10000 requests Finished 10000 requests Server Software: Server Hostname: 10.5.41.247 Server Port: 8080 Document Path: /users/pooky Document Length: 9 bytes Concurrency Level: 100 Time taken for tests: 16.801 seconds Complete requests: 10000 Failed requests: 0 Write errors: 0 Non-2xx responses: 10000 Total transferred: 1510000 bytes HTML transferred: 90000 bytes Requests per second: 595.19 [#/sec] (mean) Time per request: 168.014 [ms] (mean) Time per request: 1.680 [ms] (mean, across all concurrent requests) Transfer rate: 87.77 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 4 2.4 3 21 Processing: 38 163 54.3 151 465 Waiting: 10 135 45.4 125 373 Total: 39 167 55.0 154 474 Percentage of the requests served within a certain time (ms) 50% 154 66% 163 75% 175 80% 189 90% 230 95% 299 98% 338 99% 370 100% 474 (longest request) ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:2:0","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"查看分析报告 程序停止运行之后，可以得到如下结果： Top Calls 按 Self 指标（函数本身代码段调用次数和执行时间）降序列出所有函数，可以看出 routergroup 的 dispatch 方法消耗调用次数最多，占用 CPU 时间最长。 Total 指标表示函数本身和其调用地其它函数总共的执行时间 Bottom-UP 会从外到里的列出函数的整个调用栈： Flame Chart 可以帮助查看程序执行时暂停的位置，是什么引起的暂停。 最上方的是 timeline，可以随意选择时间段，来查看该时间段程序的执行片段。 火焰图区域展示了 GC ，引擎，外部调用和程序本身的调用。这些调用对应的颜色在火焰图的上方有标注。 右侧展示了函数的调用栈（从下到上），和执行时间。 选中某个片段，点击左上角的 + 可以放大图表。 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:2:1","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"内存分析工具 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:3:0","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"heapdump 内存分析工具可以使用 heapdump: const heapdump = require('heapdump');\rheapdump.writeSnapshot('./test' + '.heapsnapshot'); 当前目录会生成内存快照 test.heapsnapshot 文件，后缀必须为 .heapsnapshot ，否则 Chrome devtools 不识别。 Chrome devtools 如何分析可以看 这里。 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:3:1","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"webstrom heap snapshot 和 CPU profiling 一样，进入 Edit Configuration，选中 Allow Taking heap snapshot。 运行程序，点击 Take heap snapshot： webstrom 就会收集内存的 profile 信息，并保存到指定文件。 如果已经有 .heapsnapshot 文件，也可以通过 Tools | V8 Profiling - Analyze V8 Heap Snapshot 来查看。 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:3:2","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"内存分析 Summary 视图显示应用程序中按类型分组的对象。每种类型的对象数量、它们的大小以及它们占用的内存百分比。 Constructor，表示所有通过该构造函数生成的对象 Distance， 对象到达 GC 根的最短距离 Shallow Size，对象本身占用的内存，也就是对象自身被创建时，在 V8 堆上分配的大小 Retained Size，占用总内存，包括引用的对象所占用的内存，GC 后 V8 堆能够释放出的空间大小 支配树 1 为根节点（GC 根），如果要回收对象 5 ，也就是使对象 5 从 GC 根不可达，仅仅去掉对象 4 或者对象 3 对于对象 5 的引用是不够的，只有去掉对象 2 才能将对象 5 回收，所以在上面这个图中，对象 5 的直接支配者是对象 2。 上面图中对象 3、对象 7 和对象 8 没有任何直接支配对象，因此其 Retained Size 等于其 Shallow Size。 GC 根的 Retained Size 等于堆上所有从此根出发可达对象的 Shallow Size 之和。 按照上面的介绍，Retained Size 非常大的对象，就可能是泄露的对象。 Biggest Objects 视图显示按对象大小排序，消耗内存最多的对象。 Containment view 视图可以用来探测堆内容，可以查看 function 内部，观察 VM 内部对象，可以看到底层的内存使用情况。 实际项目中，我们应该对多个内存快照进行比对分析，如果某个对象占用的内存一直持续增加，那么就又可能是泄露了。 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:3:3","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"其他工具 node-memwatch node-clinic ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:3:4","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"线上性能分析 上面的方式适合在本地做性能分析和优化，线上项目如果要分析性能问题，就要提前引入 v8-profiler 和 heapdump，使用不太方便。而且除了 CPU/Memory 的问题 ，可能还会遇到其他问题。线上项目推荐使用 阿里的 Node.js 性能平台。如何使用可以看这里。 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:4:0","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Node.js"],"content":"参看链接 https://developers.google.com/web/tools/chrome-devtools/evaluate-performance/reference https://developers.google.com/web/tools/chrome-devtools/memory-problems?utm_campaign=2016q3\u0026utm_medium=redirect\u0026utm_source=dcc#retained-size https://github.com/aliyun-node/Node.js-Troubleshooting-Guide/blob/master/0x03_%E5%B7%A5%E5%85%B7%E7%AF%87_%E6%AD%A3%E7%A1%AE%E6%89%93%E5%BC%80%20Chrome%20devtools.md https://github.com/aliyun-node/Node.js-Troubleshooting-Guide/blob/master/0x04_%E5%B7%A5%E5%85%B7%E7%AF%87_Node.js%20%E6%80%A7%E8%83%BD%E5%B9%B3%E5%8F%B0%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97.md https://juejin.im/post/5c6844b3e51d4520f0175839 ","date":"2019-12-07","objectID":"/posts/2019-12-07-node-profile/:5:0","tags":null,"title":"Node 如何做性能分析","uri":"/posts/2019-12-07-node-profile/"},{"categories":["Go"],"content":"Gin 是基于 Golang 实现的的一个 web 框架。Gin 是一个类似于 martini 但拥有更好性能的 API 框架, 由于 httprouter，速度提高了近 40 倍。 ","date":"2019-11-21","objectID":"/posts/2019-11-21-gin-resource-code-analysis/:0:0","tags":null,"title":"Gin 框架源码分析","uri":"/posts/2019-11-21-gin-resource-code-analysis/"},{"categories":["Go"],"content":"Handler 接口的实现 我们从一个官方示例开始，来分析 Gin 的实现原理： package main import \"github.com/gin-gonic/gin\" func main() { // 常见一个 gin 默认实例 r := gin.Default() // 注册路由 r.GET(\"/ping\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"pong\", }) }) r.Run() // 监听并在 0.0.0.0:8080 上启动服务 } gin.Default() 创建了一个 gin 默认的 Engine 实例，Engine 的结构： // Engine is the framework's instance, it contains the muxer, middleware and configuration settings. // Create an instance of Engine, by using New() or Default() type Engine struct { // 继承了 RouterGroup，比如 GET, POST 等路由方法 RouterGroup // 路由组 ... pool sync.Pool // 存放 context 对象 trees methodTrees // 存放所有的路由处理函数 } Engine 结构体，有三个比较重要的属性。 func New() *Engine { debugPrintWARNINGNew() engine := \u0026Engine{ RouterGroup: RouterGroup{ // 初始化 RouterGroup Handlers: nil, basePath: \"/\", root: true, // root 的 RouterGroup }, FuncMap: template.FuncMap{}, RedirectTrailingSlash: true, RedirectFixedPath: false, HandleMethodNotAllowed: false, ForwardedByClientIP: true, AppEngine: defaultAppEngine, UseRawPath: false, UnescapePathValues: true, MaxMultipartMemory: defaultMultipartMemory, trees: make(methodTrees, 0, 9), delims: render.Delims{Left: \"{{\", Right: \"}}\"}, secureJsonPrefix: \"while(1);\", } engine.RouterGroup.engine = engine // 将 engine 实例添加到了 RouterGroup.engine 上，方便调用 // 比如： // 路由分组函数 group.Group() 会用到 // group.handle() 添加路由时，最终也是调用的 engine.addRoute 将路由添加到 engine.trees // 创建 pool 来存放 context engine.pool.New = func() interface{} { return engine.allocateContext() } return engine } // Default returns an Engine instance with the Logger and Recovery middleware already attached. func Default() *Engine { debugPrintWARNINGDefault() // 调用 New 方法创建 engine 实例 engine := New() // 默认实例 添加了 Logger 和 Recovery 中间件 engine.Use(Logger(), Recovery()) return engine } 接着从 Run 方法的实现开始分析： // Run attaches the router to a http.Server and starts listening and serving HTTP requests. // It is a shortcut for http.ListenAndServe(addr, router) // Note: this method will block the calling goroutine indefinitely unless an error happens. func (engine *Engine) Run(addr ...string) (err error) { defer func() { debugPrintError(err) }() // 解析传入的地址 address := resolveAddress(addr) debugPrint(\"Listening and serving HTTP on %s\\n\", address) // 监听 address，启动服务， err = http.ListenAndServe(address, engine) return } Run 方法其实就是对标准库 http 包的 ListenAndServe 方法进行了封装。重点就是 ListenAndServe 方法的第二个参数， 这里的 engine 就是 gin 实例。ListenAndServe 方法的第二个参数是一个 Handler 接口类型。Handler 接口是用来响应 HTTP 请求的，最终 HTTP 服务会调用 Handler 接口的 ServeHTTP(ResponseWriter, *Request) 方法来处理客户端请求并响应。 gin 实例的 Handler 接口实现： // ServeHTTP conforms to the http.Handler interface. func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { // 使用 sync.Pool 缓存 context 对象，避免重复创建对象，减轻 GC 的消耗 // 从 pool 中获取一个 context c := engine.pool.Get().(*Context) // 重置 context 实例的 http.ResponseWriter c.writermem.reset(w) // 重置 context 实例的 *http.Request c.Request = req // 重置 context 实例的一些其他属性 c.reset() // 处理请求，context 实例为参数传入 engine.handleHTTPRequest(c) // 将 context 对象放回 pool engine.pool.Put(c) } engine.handleHTTPRequest(c) 是 gin 处理请求的方法： func (engine *Engine) handleHTTPRequest(c *Context) { httpMethod := c.Request.Method rPath := c.Request.URL.Path unescape := false if engine.UseRawPath \u0026\u0026 len(c.Request.URL.RawPath) \u003e 0 { rPath = c.Request.URL.RawPath unescape = engine.UnescapePathValues } // 获取请求的 path rPath = cleanPath(rPath) // Find root of the tree for the given HTTP method t := engine.trees for i, tl := 0, len(t); i \u003c tl; i++ { // 匹配请求的 method if t[i].method != httpMethod { continue } // 获取匹配到的 method 的 root 节点 root := t[i].root // Find route in tree // 根据请求的 path，参数，找到对应的路由处理函数 value := root.getValue(rPath, c.Params, unescape) if value.handlers != nil { // 更新 context 对象，将所有匹配的 handlers 路由函数缓存到 context 对象 c.handlers = value.handlers c.Params = value.params c.fullPath = value.fullPath // 执行 handlers c.Next() // 处理 response c.writermem.WriteHeaderNow() return } if httpMethod != \"CONNECT\" \u0026\u0026 rPath != \"/\" { if value.tsr \u0026\u0026 engine.RedirectTrailingSl","date":"2019-11-21","objectID":"/posts/2019-11-21-gin-resource-code-analysis/:1:0","tags":null,"title":"Gin 框架源码分析","uri":"/posts/2019-11-21-gin-resource-code-analysis/"},{"categories":["Go"],"content":"注册中间件 gin 注册中间的方法 engine.Use： // Use attaches a global middleware to the router. ie. the middleware attached though Use() will be // included in the handlers chain for every single request. Even 404, 405, static files... // For example, this is the right place for a logger or error management middleware. func (engine *Engine) Use(middleware ...HandlerFunc) IRoutes { // 调用 RouterGroup 的 Use 方法，注册中间件 engine.RouterGroup.Use(middleware...) engine.rebuild404Handlers() engine.rebuild405Handlers() return engine } // RouterGroup 的 Use 方法 // Use adds middleware to the group, see example code in GitHub. func (group *RouterGroup) Use(middleware ...HandlerFunc) IRoutes { // 合并所有的中间件 handlers group.Handlers = append(group.Handlers, middleware...) return group.returnObj() } 上面的代码可以看出 engine.Use() 方法把所有的中间件添加到了一个全局的 Handlers 数组中。 ##　注册路由 路由是如何被添加到 engine.trees 的？以示例中 r.GET(\"/ping\", func) 为例，engine 的 GET 方法是继承自 RouterGroup 的： // GET is a shortcut for router.Handle(\"GET\", path, handle). func (group *RouterGroup) GET(relativePath string, handlers ...HandlerFunc) IRoutes { return group.handle(\"GET\", relativePath, handlers) } 其他路由方法也是类似的实现（如 POST，DELETE），调用 group.handle 来添加路由。 func (group *RouterGroup) handle(httpMethod, relativePath string, handlers HandlersChain) IRoutes { absolutePath := group.calculateAbsolutePath(relativePath) // 把中间件的 handlers 和对应路由的 handlers 合并 handlers = group.combineHandlers(handlers) // 将合并的 handlers 集合，注册到 engine.trees，group.engine 在 New() 的时候已经赋值 group.engine.addRoute(httpMethod, absolutePath, handlers) return group.returnObj() } func (group *RouterGroup) combineHandlers(handlers HandlersChain) HandlersChain { // Use() 方法将所有的中间件都存放在了 group.Handlers 数组中 // 所以这里计算的是 中间件 handlers 和 路由 handlers 的总数 finalSize := len(group.Handlers) + len(handlers) // 注册的中间件 handlers 和 路由 handlers 总数不能超过 abortIndex if finalSize \u003e= int(abortIndex) { panic(\"too many handlers\") } mergedHandlers := make(HandlersChain, finalSize) // 将中间件 handlers 和 路由 handlers 拷贝到一个新的切片 copy(mergedHandlers, group.Handlers) copy(mergedHandlers[len(group.Handlers):], handlers) return mergedHandlers } func (engine *Engine) addRoute(method, path string, handlers HandlersChain) { // 路由校验 assert1(path[0] == '/', \"path must begin with '/'\") assert1(method != \"\", \"HTTP method can not be empty\") assert1(len(handlers) \u003e 0, \"there must be at least one handler\") debugPrintRoute(method, path, handlers) // 遍历 trees 数组，获取 method 的路由的 root 节点 // 这里 trees 的数据结构并没有使用 map，可能是觉得 method 没几个，遍历也无所谓 root := engine.trees.get(method) if root == nil { // 如果没有，就创建路由的 root 节点 root = new(node) root.fullPath = \"/\" engine.trees = append(engine.trees, methodTree{method: method, root: root}) } // 将 handlers 集合添加到 root.handlers root.addRoute(path, handlers) } ","date":"2019-11-21","objectID":"/posts/2019-11-21-gin-resource-code-analysis/:2:0","tags":null,"title":"Gin 框架源码分析","uri":"/posts/2019-11-21-gin-resource-code-analysis/"},{"categories":["Go"],"content":"路由组 gin 可以添加路由组，比如： func main() { router := gin.Default() // 简单的路由组: v1 v1 := router.Group(\"/v1\") { v1.POST(\"/login\", loginEndpoint) v1.POST(\"/submit\", submitEndpoint) v1.POST(\"/read\", readEndpoint) } // 简单的路由组: v2 v2 := router.Group(\"/v2\") { v2.POST(\"/login\", loginEndpoint) v2.POST(\"/submit\", submitEndpoint) v2.POST(\"/read\", readEndpoint) } router.Run(\":8080\") } // Group creates a new router group. You should add all the routes that have common middlewares or the same path prefix. // For example, all the routes that use a common middleware for authorization could be grouped. func (group *RouterGroup) Group(relativePath string, handlers ...HandlerFunc) *RouterGroup { return \u0026RouterGroup{ Handlers: group.combineHandlers(handlers), basePath: group.calculateAbsolutePath(relativePath), engine: group.engine, // 全局的 engine 实例 } } 可以看出 Group() 虽然返回了一个新的 RouterGroup 实例，但是 engine 仍然指向了全局唯一的 engine 实例。也就意味着 v1.POST 和 v2.POST 添加的路由 handlers 和 中间件 handlers 最终都添加到了 handlers 树 engine.trees 上。 ","date":"2019-11-21","objectID":"/posts/2019-11-21-gin-resource-code-analysis/:2:1","tags":null,"title":"Gin 框架源码分析","uri":"/posts/2019-11-21-gin-resource-code-analysis/"},{"categories":["Go"],"content":"Next 方法的调用流程 前面已经知道 engine.handleHTTPRequest 在路由匹配之后，会调用 Next 方法来执行对应的 handlers： // Next should be used only inside middleware. // It executes the pending handlers in the chain inside the calling handler. // See example in GitHub. func (c *Context) Next() { // c.index 的值在 c.reset() 方法中被重置为 -1 了，也就是从 0 开始遍历 handlers 数组 c.index++ for c.index \u003c int8(len(c.handlers)) { // 遍历所有的 handlers，包括中间件 和 路由处理函数 c.handlers[c.index](c) // 执行 handler c.index++ } } 上面的代码，for 循环遍历 handlers 执行，也就意味着在中间件 handlers 中， c.Next() 并不是必须的，根据情况调用。 Next 方法可以在中间件函数中主动调用，例如： func Logger() gin.HandlerFunc { return func(c *gin.Context) { t := time.Now() // 设置 example 变量 c.Set(\"example\", \"12345\") // 请求前 c.Next() // 请求后 latency := time.Since(t) log.Print(latency) // 获取发送的 status status := c.Writer.Status() log.Println(status) } } func main() { r := gin.New() r.Use(Logger()) r.GET(\"/test\", func(c *gin.Context) { example := c.MustGet(\"example\").(string) // 打印：\"12345\" log.Println(example) }) // 监听并在 0.0.0.0:8080 上启动服务 r.Run(\":8080\") } Next() 方法中，使用的 c.index 这个成员变量，这个变量相对于整个流程是全局的，这样就可以保证每个 handler 只执行一次。 当在中间件中调用 c.Next() 时，这个中间件就得到了控制权，执行 c.Next()，c.index 先加 1，然后进入 for 循环，循环执行结束，控制权还 给 context。这个实现有点类似 koa 的洋葱模型。 ","date":"2019-11-21","objectID":"/posts/2019-11-21-gin-resource-code-analysis/:3:0","tags":null,"title":"Gin 框架源码分析","uri":"/posts/2019-11-21-gin-resource-code-analysis/"},{"categories":["Go"],"content":"路由树 gin router 的底层数据结构是基树（Radix tree），类似 Trie 树。 Radix tree 的节点： type node struct { // 相对路径 path string // 索引 indices string // 子节点 children []*node // 处理者列表 handlers HandlersChain priority uint32 // 结点类型：static, root, param, catchAll nType nodeType // 最多的参数个数 maxParams uint8 // 是否是通配符(:param_name | *param_name) wildChild bool // 完整路径 fullPath string } 一个路由示例： package main import ( \"fmt\" \"github.com/gin-gonic/gin\" ) func m1(c *gin.Context) { fmt.Println(\"middleware1\") } func m2(c *gin.Context) { fmt.Println(\"middleware2\") } func f(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"ok\", }) } func f1(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"ok\", }) } func f2(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"ok\", }) } func f3(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"ok\", }) } func f4(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"ok\", }) } func main() { r := gin.Default() r.Get(\"/\", f) r.Use(m1) r.GET(\"/index\", f1) r.GET(\"/ins\", f2) r.Use(m2) r.GET(\"/go\", f3) r.GET(\"/golang\", f4) r.Run() // listen and serve on 0.0.0.0:8080 (for windows \"localhost:8080\") } 上面的示例，生成树结构示意图： ","date":"2019-11-21","objectID":"/posts/2019-11-21-gin-resource-code-analysis/:4:0","tags":null,"title":"Gin 框架源码分析","uri":"/posts/2019-11-21-gin-resource-code-analysis/"},{"categories":["Go"],"content":"Go 的标准库 net/http 用来处理 HTTP 协议，包括 HTTP server 和 HTTP client。这里主要分析 HTTP server 部分。 ","date":"2019-11-12","objectID":"/posts/2019-11-12-go-http-resouce-code-analysis/:0:0","tags":null,"title":"Go http 库 server 源码分析","uri":"/posts/2019-11-12-go-http-resouce-code-analysis/"},{"categories":["Go"],"content":"请求处理流程分析 从一个示例开始： package main import ( \"fmt\" \"html\" \"net/http\" ) func barHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \"Hello, %q\", html.EscapeString(r.URL.Path)) } func main() { http.HandleFunc(\"/bar\", barHandler) // 监听端口并启动服务 _ = http.ListenAndServe(\":8080\", nil) } http.ListenAndServe： // ListenAndServe always returns a non-nil error. // 第二个参数是 Handler 接口类型，但是上面的示例传入的是 nil，这个后面会说到 func ListenAndServe(addr string, handler Handler) error { server := \u0026Server{Addr: addr, Handler: handler} return server.ListenAndServe() } http.ListenAndServe 内部创建了一个 server 实例，并调用了 server 实例的 ListenAndServe 方法，server.ListenAndServe： func (srv *Server) ListenAndServe() error { if srv.shuttingDown() { return ErrServerClosed } // 如果 srv.Addr 是空的话，则使用 \":http\" addr := srv.Addr if addr == \"\" { addr = \":http\" } // 监听 tcp 端口 ln, err := net.Listen(\"tcp\", addr) if err != nil { return err } // 接受 l Listener 的连接，并创建一个新的 goroutine 处理请求 return srv.Serve(ln) } srv.Serve 的实现： func (srv *Server) Serve(l net.Listener) error { if fn := testHookServerServe; fn != nil { fn(srv, l) // call hook with unwrapped listener } origListener := l l = \u0026onceCloseListener{Listener: l} defer l.Close() if err := srv.setupHTTP2_Serve(); err != nil { return err } if !srv.trackListener(\u0026l, true) { return ErrServerClosed } defer srv.trackListener(\u0026l, false) var tempDelay time.Duration // how long to sleep on accept failure // 为每一个 request 创建 context 实例 baseCtx := context.Background() if srv.BaseContext != nil { baseCtx = srv.BaseContext(origListener) if baseCtx == nil { panic(\"BaseContext returned a nil context\") } } ctx := context.WithValue(baseCtx, ServerContextKey, srv) for { // 接受请求数据，返回一个新的连接句柄 rw, e := l.Accept() if e != nil { select { case \u003c-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := e.(net.Error); ok \u0026\u0026 ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay \u003e max { tempDelay = max } srv.logf(\"http: Accept error: %v; retrying in %v\", e, tempDelay) time.Sleep(tempDelay) continue } return e } if cc := srv.ConnContext; cc != nil { ctx = cc(ctx, rw) if ctx == nil { panic(\"ConnContext returned nil\") } } tempDelay = 0 // 创建一个新连接 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return // 创建一个新的 goroutine，处理请求 go c.serve(ctx) } } 具体的请求处理逻辑就在 c.serve(ctx) 中： // Serve a new connection. func (c *conn) serve(ctx context.Context) { c.remoteAddr = c.rwc.RemoteAddr().String() ctx = context.WithValue(ctx, LocalAddrContextKey, c.rwc.LocalAddr()) defer func() { if err := recover(); err != nil \u0026\u0026 err != ErrAbortHandler { const size = 64 \u003c\u003c 10 buf := make([]byte, size) buf = buf[:runtime.Stack(buf, false)] c.server.logf(\"http: panic serving %v: %v\\n%s\", c.remoteAddr, err, buf) } if !c.hijacked() { c.close() c.setState(c.rwc, StateClosed) } }() if tlsConn, ok := c.rwc.(*tls.Conn); ok { if d := c.server.ReadTimeout; d != 0 { c.rwc.SetReadDeadline(time.Now().Add(d)) } if d := c.server.WriteTimeout; d != 0 { c.rwc.SetWriteDeadline(time.Now().Add(d)) } if err := tlsConn.Handshake(); err != nil { // If the handshake failed due to the client not speaking // TLS, assume they're speaking plaintext HTTP and write a // 400 response on the TLS conn's underlying net.Conn. if re, ok := err.(tls.RecordHeaderError); ok \u0026\u0026 re.Conn != nil \u0026\u0026 tlsRecordHeaderLooksLikeHTTP(re.RecordHeader) { io.WriteString(re.Conn, \"HTTP/1.0 400 Bad Request\\r\\n\\r\\nClient sent an HTTP request to an HTTPS server.\\n\") re.Conn.Close() return } c.server.logf(\"http: TLS handshake error from %s: %v\", c.rwc.RemoteAddr(), err) return } c.tlsState = new(tls.ConnectionState) *c.tlsState = tlsConn.ConnectionState() if proto := c.tlsState.NegotiatedProtocol; validNPN(proto) { if fn := c.server.TLSNextProto[proto]; fn != nil { h := initNPNRequest{ctx, tlsConn, serverHandler{c.server}} fn(c.server, tlsConn, h) } return } } // HTTP/1.x from here on. ctx, cancelCtx := context.WithCancel(ctx) c.cancelCtx = cancelCtx","date":"2019-11-12","objectID":"/posts/2019-11-12-go-http-resouce-code-analysis/:1:0","tags":null,"title":"Go http 库 server 源码分析","uri":"/posts/2019-11-12-go-http-resouce-code-analysis/"},{"categories":["Go"],"content":"路由注册 在来看示例中的 http.HandleFunc 是怎么添加 Handler 的： func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } 可以看出 http.HandleFunc 其实是调用了默认的 DefaultServeMux 的 HandleFunc 添加 Handler。这就对应了上面的 ServeHTTP 方法中 下面的这段代码： // 如果 handler 为空则使用默认的 DefaultServeMux if handler == nil { handler = DefaultServeMux } 也就是说在调用 http.ListenAndServe 如果没有传入 mux，那么就会使用默认的 DefaultServeMux。 DefaultServeMux.HandleFunc 的实现： // HandleFunc registers the handler function for the given pattern. func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(\"http: nil handler\") } // 根据示例，这里应该是 mux.Handle(\"/bar\", HandlerFunc(barHandler)) // 将 handler 显示转换成了 HandlerFunc 类型 mux.Handle(pattern, HandlerFunc(handler)) } // Handle registers the handler for the given pattern. // If a handler already exists for pattern, Handle panics. func (mux *ServeMux) Handle(pattern string, handler Handler) { mux.mu.Lock() defer mux.mu.Unlock() // 校验路由 path 和 路由 handler 函数 if pattern == \"\" { panic(\"http: invalid pattern\") } if handler == nil { panic(\"http: nil handler\") } // 不能重复注册 if _, exist := mux.m[pattern]; exist { panic(\"http: multiple registrations for \" + pattern) } // 初始化 map，存放注册的路由 if mux.m == nil { mux.m = make(map[string]muxEntry) } // 保存路由对象 e := muxEntry{h: handler, pattern: pattern} mux.m[pattern] = e if pattern[len(pattern)-1] == '/' { mux.es = appendSorted(mux.es, e) } if pattern[0] != '/' { mux.hosts = true } } ","date":"2019-11-12","objectID":"/posts/2019-11-12-go-http-resouce-code-analysis/:2:0","tags":null,"title":"Go http 库 server 源码分析","uri":"/posts/2019-11-12-go-http-resouce-code-analysis/"},{"categories":["Go"],"content":"其他用法 ","date":"2019-11-12","objectID":"/posts/2019-11-12-go-http-resouce-code-analysis/:3:0","tags":null,"title":"Go http 库 server 源码分析","uri":"/posts/2019-11-12-go-http-resouce-code-analysis/"},{"categories":["Go"],"content":"自定义 http.Server package main import ( \"fmt\" \"net/http\" ) func MyHandler(w http.ResponseWriter, r *http.Request) { _, _ = fmt.Fprintf(w, \"hi\") } func main() { // 更多http.Server的字段可以根据情况初始化 server := http.Server{ Addr: \":8080\", ReadTimeout: 0, WriteTimeout: 0, } http.HandleFunc(\"/\", MyHandler) _ = server.ListenAndServe() } ","date":"2019-11-12","objectID":"/posts/2019-11-12-go-http-resouce-code-analysis/:3:1","tags":null,"title":"Go http 库 server 源码分析","uri":"/posts/2019-11-12-go-http-resouce-code-analysis/"},{"categories":["Go"],"content":"指定 http.Servemux: package main import ( \"fmt\" \"net/http\" ) func MyHandler(w http.ResponseWriter, r *http.Request) { _, _ = fmt.Fprintf(w, \"hi\") } func main() { mux := http.NewServeMux() mux.HandleFunc(\"/\", MyHandler) _ = http.ListenAndServe(\":8080\", mux) } 也可以直接把 Servemux 变量作为 Server.Handler： package main import ( \"fmt\" \"net/http\" ) func MyHandler(w http.ResponseWriter, r *http.Request) { _, _ = fmt.Fprintf(w, \"hi\") } func main() { server := http.Server{ Addr: \":8080\", ReadTimeout: 0, WriteTimeout: 0, } mux := http.NewServeMux() server.Handler = mux mux.HandleFunc(\"/\", MyHandler) _ = server.ListenAndServe() } ","date":"2019-11-12","objectID":"/posts/2019-11-12-go-http-resouce-code-analysis/:3:2","tags":null,"title":"Go http 库 server 源码分析","uri":"/posts/2019-11-12-go-http-resouce-code-analysis/"},{"categories":["Go"],"content":"自定义 mux 标准库 http 提供了 Handler 接口，自定义 mux 必须实现这个 Handler 接口。也就是实现 ServeHTTP 方法。 ","date":"2019-11-12","objectID":"/posts/2019-11-12-go-http-resouce-code-analysis/:4:0","tags":null,"title":"Go http 库 server 源码分析","uri":"/posts/2019-11-12-go-http-resouce-code-analysis/"},{"categories":["Node.js"],"content":"lerna 是一个基于 git 和 npm 的多包管理工具。 ","date":"2019-10-31","objectID":"/posts/2019-10-31-node-lerna-usage/:0:0","tags":null,"title":"使用 lerna 管理 npm packages","uri":"/posts/2019-10-31-node-lerna-usage/"},{"categories":["Node.js"],"content":"为什么需要 lerna 解决多个 packages 之间的依赖关系。 比如，现在有两个 packages，分别是 package-1 和 package-2。 package-1 的 package.json 文件： { \"name\": \"package-1\", \"version\": \"1.0.0\", \"scripts\": { \"start\": \"hexo s -p 8081\" }, \"dependencies\": { \"package-2\": \"1.0.0\" } } package-2 的 package.json 文件： { \"name\": \"package-2\", \"version\": \"1.0.0\", \"dependencies\": {} } 可以看出 package-2 是 package-1 的依赖包。如果 package-2 要 publish 1.0.1。那么 package-1 也要修改依赖的 package-2 的 版本，并且 publish。 如果互相依赖的 package 很多，工作量就会变得很大。 通过 git 检测文件改动，自动发布。 根据 git 提交记录，自动生成 CHANGELOG。 ","date":"2019-10-31","objectID":"/posts/2019-10-31-node-lerna-usage/:1:0","tags":null,"title":"使用 lerna 管理 npm packages","uri":"/posts/2019-10-31-node-lerna-usage/"},{"categories":["Node.js"],"content":"使用 ","date":"2019-10-31","objectID":"/posts/2019-10-31-node-lerna-usage/:2:0","tags":null,"title":"使用 lerna 管理 npm packages","uri":"/posts/2019-10-31-node-lerna-usage/"},{"categories":["Node.js"],"content":"全局安装 lerna npm install lerna -g ","date":"2019-10-31","objectID":"/posts/2019-10-31-node-lerna-usage/:2:1","tags":null,"title":"使用 lerna 管理 npm packages","uri":"/posts/2019-10-31-node-lerna-usage/"},{"categories":["Node.js"],"content":"初始化一个 lerna 工程 # 创建 lerna 工程目录 lerna-demo mkdir lerna-demo cd lerna-demo # 初始化 lerna init # 在 packages 目录下添加 package cd packages mkdir package-1 package-2 # 初始化 package cd package-1 npm init -y cd package-2 npm init -y 最后，项目结构像下面这样： lerna-demo/ package.json lerna.json # 配置文件 packages/ # package 目录 package-1/ package.json package-2/ package.json 安装 packages 依赖： # 在 lerna 根目录（lerna-demo）下执行 lerna bootstrap lerna bootstrap 会安装 packages 下所有 packages 的依赖。 ","date":"2019-10-31","objectID":"/posts/2019-10-31-node-lerna-usage/:2:2","tags":null,"title":"使用 lerna 管理 npm packages","uri":"/posts/2019-10-31-node-lerna-usage/"},{"categories":["Node.js"],"content":"两种工作模式 ","date":"2019-10-31","objectID":"/posts/2019-10-31-node-lerna-usage/:3:0","tags":null,"title":"使用 lerna 管理 npm packages","uri":"/posts/2019-10-31-node-lerna-usage/"},{"categories":["Node.js"],"content":"Fixed/Locked mode Fixed/Locked mode 是默认的模式。这种模式下，packages 下的所有包共用一个版本号 (version)，会自动将所有的包绑定到一个版本号上(该版本号 就是 lerna.json 中的 version 字段)，所以任意一个包发生了更新，这个共用的版本号就会发生改变。这种模式下，每次发布 packages，都是全量 发布，无论是否修改。 ","date":"2019-10-31","objectID":"/posts/2019-10-31-node-lerna-usage/:3:1","tags":null,"title":"使用 lerna 管理 npm packages","uri":"/posts/2019-10-31-node-lerna-usage/"},{"categories":["Node.js"],"content":"Independent mode 在 Independent mode 下，lerna 会配合 Git，检查文件变动，只发布有改动的 packages。如果要使用 Independent mode，使用 lerna init --independent 来初始化项目。 Independent mode 允许每一个包有一个独立的版本号，在使用 lerna publish 命令时，可以为每个包制定具体的操作，同时可以只更新某一个包的版本号。 更多 lerna 使用可以查看 官方文档 。 ","date":"2019-10-31","objectID":"/posts/2019-10-31-node-lerna-usage/:3:2","tags":null,"title":"使用 lerna 管理 npm packages","uri":"/posts/2019-10-31-node-lerna-usage/"},{"categories":["Linux"],"content":"make 是构建大型项目的首选方案。 ","date":"2019-10-23","objectID":"/posts/2019-10-23-make/:0:0","tags":null,"title":"make","uri":"/posts/2019-10-23-make/"},{"categories":["Linux"],"content":"Makefile Makefile 基本格式: target ... : prerequisites ... command ... target - 目标，目标通常是文件名，Make 命令所要构建的对象。 prerequisites - 前置条件，通常是一组文件名，之间用空格分隔。 command - 命令，生成目标所需要执行的命令，由一行或多行的 shell 命令组成，是构建 target 的具体指令。 Makefile 中的命令必须以 [tab] 开头。 ","date":"2019-10-23","objectID":"/posts/2019-10-23-make/:1:0","tags":null,"title":"make","uri":"/posts/2019-10-23-make/"},{"categories":["Linux"],"content":"target 一个 target 构成一条规则。target 可以是一个文件名，也可以是多个文件名，之间用空格分隔。 运行 make 时没有指定目标，默认会执行 Makefile 文件的第一个目标。 伪目标 当 target 是某个操作的名字时，被称为伪目标（phony target）。 clean: rm -f apiserver clean 就是伪目标，做一些清理操作。 make clean 如果当前目录中，存在一个文件叫做 clean，那么 clean 操作不会执行。因为 Make 任务 clean 已经存在，不需要重新构建。 这个时候可以声明 clean 是\"伪目标\"： .PHONY: clean clean: rm -f apiserver 声明\"伪目标\"之后， make 就不会检查 clean 文件是否存在。 .PHONY: 后面可以声明一个或多个伪目标，之间用空格分隔。 ","date":"2019-10-23","objectID":"/posts/2019-10-23-make/:1:1","tags":null,"title":"make","uri":"/posts/2019-10-23-make/"},{"categories":["Linux"],"content":"prerequisites prerequisites 指定了 target 是否重新构建的判断标准：只要有一个前置文件不存在，或者有过更新，target 就需要重新构建。 .PHONY: buildimg buildimg: apisevergo cp apisevergo /apisevergo apisevergo: ./build_binary.sh 上面的示例，buildimg 的前置条件是 apisevergo。如果 apisevergo 已经存在，那么 make buildimg 可以正常运行， 否则必须再写一条规则，来生成 apisevergo。 make buildimg make buildimg 上面连续执行两次 make buildimg。第一次执行会先生成 apisevergo，然后再执行 cp apisevergo /apisevergo。 第二次执行，make 发现 apisevergo 存在而且没有变动，就不会执行任何操作。 ","date":"2019-10-23","objectID":"/posts/2019-10-23-make/:1:2","tags":null,"title":"make","uri":"/posts/2019-10-23-make/"},{"categories":["Linux"],"content":"command command 是构建 target 的具体指令，它的运行结果通常就是生成目标文件。 命令必须以 [tab] 开头，可以用内置变量 .RECIPEPREFIX 声明，来使用其他键。 .RECIPEPREFIX = \u003e all: \u003e echo Hello, world .RECIPEPREFIX指定了 \u003e 替代 tab 键。 每行命令在一个单独的 shell 中执行。也就是说 shell 之间没有继承关系。 var-lost: export foo=bar echo \"foo=[$$foo]\" 执行 var-lost 取不到 foo 的值。因为两行命令在两个不同的进程执行。有三种解决办法： 将两行命令写在一行，中间用分号分隔。 在换行符前加反斜杠转义。 使用 .ONESHELL # 1 var-kept: export foo=bar; echo \"foo=[$$foo]\" # 2 var-kept2: export foo=bar; \\ echo \"foo=[$$foo]\" # 3 .ONESHELL: var-kept3: export foo=bar; echo \"foo=[$$foo]\" ","date":"2019-10-23","objectID":"/posts/2019-10-23-make/:1:3","tags":null,"title":"make","uri":"/posts/2019-10-23-make/"},{"categories":["Linux"],"content":"语法 # 表示注释。 @ 放在行首，表示不打印此行。默认情况下会打印每条命令。 通配符 通配符（wildcard）用来指定一组符合条件的文件名。与 Bash 一致，主要有星号 *、?、[...]。 # *.log 表示所有后缀名为 log 的文件。 clean: rm -f *.log 匹配符 可以对文件名，进行类似正则运算的匹配，主要用到的匹配符是 %。可以将大量同类型的文件，只用一条规则就完成构建。 %.o: %.c # 等同于 f1.o: f1.c f2.o: f2.c 变量和赋值符 # 使用等号自定义变量 txt = Hello World test: @echo $(txt) # 调用自定义变量需要放在 `$( )` 之中 test: @echo $$HOME # 调用 shell 变量时，变量前需要多加一个 `$`，这样才会对对 `$` 符号转义 赋值 VARIABLE = value # 在执行时扩展，允许递归扩展。 VARIABLE := value # 在定义时扩展。 VARIABLE ?= value # 只有在该变量为空时才设置值。 VARIABLE += value # 将值追加到变量的尾端。 内置变量 内置变量，如 $(CC) 指向当前使用的编译器，$(MAKE) 指向当前使用的 make 工具。 内置变量 自动变量 make 的自动变量与当前规则有关。 $@ - 指代当前构建的那个目标。比如，make foo 的 $@ 就指代 foo。 $\u003c - 指代第一个前置条件。比如，t: p1 p2，那么 $\u003c 就指代 p1。 $? - 指代比目标更新的所有前置条件，之间以空格分隔。比如，t: p1 p2，p2 的时间戳比 t 新，$? 就指代 p2。 $^ - 指代所有前置条件，之间以空格分隔。比如，t: p1 p2，$? 就指代 p1 p2。 $* - 指代匹配符 % 匹配的部分， 比如 % 匹配 f1.txt 中的 f1，$* 就表示 f1。 $(@D) 和 $(@F) - 分别指向 $@ 的目录名和文件名。比如，$@ 是 src/input.c，那么 $(@D) 为 src ，$(@F) 的 值为 input.c。 $(\u003cD) 和 $(\u003cF) - 分别指向 $\u003c 的目录名和文件名。 控制语句 控制语句使用 Bash 语法。 ifeq ($(CC),gcc) libs=$(libs_for_gcc) else libs=$(normal_libs) endif LIST = one two three all: for i in $(LIST); do \\ echo $$i; \\ done # 等同于 all: for i in one two three; do \\ echo $i; \\ done 函数 函数格式：$(function arguments) 或者 ${function arguments}。 常用内置函数： # shell 函数用来执行 shell 命令 srcfiles := $(shell echo src/{00..99}.txt) # wildcard 函数替换 Bash 的通配符 srcfiles := $(wildcard src/*.txt) # subst 函数用来文本替换 $(subst from,to,text) $(subst ee,EE,feet on the street) # \"feet on the street\"替换成\"fEEt on the strEEt\" # patsubst 函数用于模式匹配的替换 $(patsubst pattern,replacement,text) $(patsubst %.c,%.o,x.c.c bar.c) # 将文件名\"x.c.c bar.c\"，替换成\"x.c.o bar.o\" # 替换后缀名 # 替换后缀名函数的写法是：变量名 + 冒号 + 后缀名替换规则 min: $(OUTPUT:.js=.min.js) # 将变量 OUTPUT 中的后缀名 .js 全部替换成 .min.js 。 ","date":"2019-10-23","objectID":"/posts/2019-10-23-make/:1:4","tags":null,"title":"make","uri":"/posts/2019-10-23-make/"},{"categories":["Linux"],"content":"include include 可以引用其他 makefile。include 不能以 [tab] 开头。 makefile 入口文件，引用 build 目录下的 makefile。 include build/Makefile ","date":"2019-10-23","objectID":"/posts/2019-10-23-make/:1:5","tags":null,"title":"make","uri":"/posts/2019-10-23-make/"},{"categories":["Linux"],"content":"构建 Go 项目 SHELL := /bin/bash BASEDIR := $(shell pwd) BACKENDDIR := $(BASEDIR)/backend PROXY = http://web-proxy.net:8080 BINARY_NAME = installer IMAGE_NAME = installer VERSION = 0.1.2 .PHONY: all build image build-fips proxy module lint golint govet test benchmark clean help all: proxy build .ONESHELL: build: module lint govet @echo \"build binary: $(BINARY_NAME) ..\" @cd $(BACKENDDIR) @go build -o $(BINARY_NAME) ./app/main.go @echo \"build $(BINARY_NAME) completed.\" image: build-fips @echo \"build image: $(IMAGE_NAME):$(VERSION) ..\" @docker build --rm --no-cache \\ --label com.sample.image-version=$(VERSION) \\ --label com.sample.image-name=$(IMAGE_NAME) \\ --label com.sample.itom.$(IMAGE_NAME)=$(VERSION) \\ --label vendor=\"Example plc\" \\ -t localhost:5000/$(IMAGE_NAME):$(VERSION) $(BASEDIR) build-fips: @echo \"docker build binary: $(BINARY_NAME) ..\" @docker run --rm -v $(BACKENDDIR)/app:/backend/app \\ -v $(BACKENDDIR)/library:/backend/library \\ -v $(BACKENDDIR)/build:/backend/build \\ -v $(BACKENDDIR)/build/build.sh:/backend/build.sh \\ -w /backend \\ example.swinfra.net/golang-fips:1.0.0 \\ sh build.sh proxy: @echo \"set http proxy ..\" @export http_proxy=$(PROXY) @export https_proxy=$(PROXY) .ONESHELL: module: @echo \"download dependencies ..\" @cd $(BACKENDDIR) @go mod tidy lint: @echo \"run go lint ..\" @golint $(BACKENDDIR) golint: @echo \"install golint ..\" @go get -u golang.org/x/lint/golint @go install golang.org/x/lint/golint .ONESHELL: govet: @echo \"run go vet ..\" @cd $(BACKENDDIR) @go vet ./app/main.go test: @echo \"run go test ..\" benchmark: @echo \"run go test benchmark ..\" clean: @echo \"clean ..\" @rm -rf $(BACKENDDIR)/build/$(BINARY_NAME) @rm -rf $(BINARY_NAME) @docker system prune .PHONY: show show: @echo \"$(BASEDIR)\" help: @echo \"make - compile the source code\" @echo \"make image - build image, please make sure the docker is installed\" @echo \"make build-fips - compile the source code with golang-fips image\" @echo \"make lint - run go lint\" @echo \"make vet - run go vet\" @echo \"make clean - remove binary file and prune image\" build.sh 的内容： #!/bin/sh # Proxy export http_proxy=http://web-proxy.net:8080 export https_proxy=http://web-proxy.net:8080 # Enable go module export GO111MODULE=on # Install tools apk --update add gcc git musl-dev # Download dependencies, remove unused dependencies go mod tidy # Fix clinet-go unsupport go.mod go get k8s.io/client-go@kubernetes-1.15.0 # Fix github.com/ugorji/go import issue go get github.com/ugorji/go@v1.1.2-0.20180831062425-e253f1f20942 # Build the renewCert echo \"Build apiservergo ...\" CGO_ENABLED=0 go build -a -o installer ./app/main.go echo \"Build apiservergo completed.\" ","date":"2019-10-23","objectID":"/posts/2019-10-23-make/:2:0","tags":null,"title":"make","uri":"/posts/2019-10-23-make/"},{"categories":["Linux"],"content":"参考链接 Make 命令教 使用 Make 构建网站 ","date":"2019-10-23","objectID":"/posts/2019-10-23-make/:3:0","tags":null,"title":"make","uri":"/posts/2019-10-23-make/"},{"categories":["Go"],"content":"通常，我们会对不同等级的日志输出不同的颜色来区分。 fmt.Printf(\"\\033[1;31;40m%s\\033[0m\\n\",\"Red.\") fmt.Printf(\"\\033[1;37;41m%s\\033[0m\\n\",\"Red.\") 第一行是红字黑底，第二行红底白字。 我们来解析 \\033[1;31;40m%s\\033[0m\\n 这个字符串中的字符分别代表了什么。 \\033：\\ 表示转义，\\033 表示设置颜色。 [1;31;40m：定义颜色，[ 表示开始颜色设置，m 为颜色设置结束，以 ; 号分隔。1 代码，表示显示方式，31 表示前景颜色（文字的 颜色），40 表示背景颜色。 \\033[0m：表示恢复终端默认样式。 // 前景 背景 颜色 // --------------------------------------- // 30 40 黑色 // 31 41 红色 // 32 42 绿色 // 33 43 黄色 // 34 44 蓝色 // 35 45 紫红色 // 36 46 青蓝色 // 37 47 白色 // 3 位前景色, 4 位背景色 // 代码 意义 // ------------------------- // 0 终端默认设置 // 1 高亮显示 // 4 使用下划线 // 5 闪烁 // 7 反白显示 // 8 不可见 // Color defines a single SGR Code type Color int // Foreground text colors const ( FgBlack Color = iota + 30 FgRed FgGreen FgYellow FgBlue FgMagenta FgCyan FgWhite ) // Foreground Hi-Intensity text colors const ( FgHiBlack Color = iota + 90 FgHiRed FgHiGreen FgHiYellow FgHiBlue FgHiMagenta FgHiCyan FgHiWhite ) // Colorize a string based on given color. func Colorize(s string, c Color) string { return fmt.Sprintf(\"\\033[1;%s;40m%s\\033[0m\", strconv.Itoa(int(c)), s) } 上面的代码输出： ","date":"2019-09-18","objectID":"/posts/2019-09-18-go-color/:0:0","tags":null,"title":"Go 实现在终端输出颜色","uri":"/posts/2019-09-18-go-color/"},{"categories":["Go"],"content":"这里记录一个使用 Go base64 标准库解码 token 时遇到的问题。 import ( \"encoding/base64\" \"fmt\" ) func tokenParser(token string) { tokenStr, err := base64.StdEncoding.DecodeString(token) if err != nil { fmt.Println(err) } } 上面的代码输出了错误 illegal base64 data at input byte xxx。 上面的错误是因为 jwt 的 base64 是 no padding 的，要使用 base64.RawStdEncoding 来解码： tokenStr, err := base64.RawStdEncoding.DecodeString(token) if err != nil { fmt.Println(err) } ","date":"2019-09-06","objectID":"/posts/2019-09-06-go-base64/:0:0","tags":null,"title":"记录一个 Go base64 解码的问题","uri":"/posts/2019-09-06-go-base64/"},{"categories":["Go"],"content":"什么是 no padding 要知道什么是 no padding，需要先简单了解一下 base64 的原理。 ","date":"2019-09-06","objectID":"/posts/2019-09-06-go-base64/:1:0","tags":null,"title":"记录一个 Go base64 解码的问题","uri":"/posts/2019-09-06-go-base64/"},{"categories":["Go"],"content":"base64 编码原理 base64 是网络上最常见的用于传输 8 bit 字节码的编码方式之一，base64 就是一种基于 64 个可打印字符来表示二进制数据的方法。 64 个打印字符： 索引 对应字符 索引 对应字符 索引 对应字符 索引 对应字符 0 A 17 R 34 i 51 z 1 B 18 S 35 j 52 0 2 C 19 T 36 k 53 1 3 D 20 U 37 l 54 2 4 E 21 V 38 m 55 3 5 F 22 W 39 n 56 4 6 G 23 X 40 o 57 5 7 H 24 Y 41 p 58 6 8 I 25 Z 42 q 59 7 9 J 26 a 43 r 60 8 10 K 27 b 44 s 61 9 11 L 28 c 45 t 62 + 12 M 29 d 46 u 63 / 13 N 30 e 47 v 14 O 31 f 48 w 15 P 32 g 49 x 16 Q 33 h 50 y base64 就是使用上面的 64 个可打印字符来表示二进制数据。2^6 = 64 也就是说，上面 64 个字符的索引，最多用 6 个 bit 就可以表示了。 但是常用的字符集没有使用 6 bit 表示的，比如 ASCII 码需要 8 个 bit 来表示。 那么如何使用 6 个 bit 表示 8 个 bit 的数据？ 使用 4*6 个 bit 来存储 3*8 个 bit。例如： Son 经过 base64 编码以后转换成了 U29u。 3 个 ASCII 字符刚好转换成对应的 4 个 base64 字符，但是如果需要转换的字符不是 3 的倍数，也就是说在分组时最后一组不够 3 个字节如何转换？ base64 有一条规则：当需要转换的字符不是 3 的倍数时，一律采用补 0 的方式凑足 3 的倍数。例如： S 经过 base64 编码以后转换成了 Uw==。第二组末尾补 4 个 0 转换后为字符 w。剩下两个字节使用 = 填补。 no padding 是非填补的意思，也就是说当需要转换的字符不是 3 的倍数时，剩下的 1 到 2 个 0 字节不使用 = 填补。 ","date":"2019-09-06","objectID":"/posts/2019-09-06-go-base64/:1:1","tags":null,"title":"记录一个 Go base64 解码的问题","uri":"/posts/2019-09-06-go-base64/"},{"categories":["Go"],"content":"Go base64 标准库 Go base64 标准库的源码： // StdEncoding is the standard base64 encoding, as defined in // RFC 4648. var StdEncoding = NewEncoding(encodeStd) // URLEncoding is the alternate base64 encoding defined in RFC 4648. // It is typically used in URLs and file names. var URLEncoding = NewEncoding(encodeURL) // RawStdEncoding is the standard raw, unpadded base64 encoding, // as defined in RFC 4648 section 3.2. // This is the same as StdEncoding but omits padding characters. var RawStdEncoding = StdEncoding.WithPadding(NoPadding) // RawURLEncoding is the unpadded alternate base64 encoding defined in RFC 4648. // It is typically used in URLs and file names. // This is the same as URLEncoding but omits padding characters. var RawURLEncoding = URLEncoding.WithPadding(NoPadding) StdEncoding 代表的是标准加解密，URLEncoding，则是 URL 加解密。RawStdEncoding 和 RawURLEncoding 非别对应它们在 no padding 时应该 使用的方法。 ","date":"2019-09-06","objectID":"/posts/2019-09-06-go-base64/:2:0","tags":null,"title":"记录一个 Go base64 解码的问题","uri":"/posts/2019-09-06-go-base64/"},{"categories":["Go"],"content":"golang 1.11 已经支持 Go Module。这是官方提倡的新的包管理，乃至项目管理机制，可以不再需要 GOPATH 的存在。 ","date":"2019-07-24","objectID":"/posts/2019-07-24-go-mod-migrate/:0:0","tags":null,"title":"Go 项目迁移到 mod","uri":"/posts/2019-07-24-go-mod-migrate/"},{"categories":["Go"],"content":"Module 机制 Go Module 不同于以往基于 GOPATH 和 Vendor 的项目构建，其主要是通过 $GOPATH/pkg/mod 下的缓存包来对项目进行构建。 Go Module 可以通过 GO111MODULE 来控制是否启用，GO111MODULE 有三种类型: on 所有的构建，都使用 Module 机制 off 所有的构建，都不使用 Module 机制，而是使用 GOPATH 和 Vendor auto 在 GOPATH 下的项目，不使用 Module 机制，不在 GOPATH 下的项目使用 ","date":"2019-07-24","objectID":"/posts/2019-07-24-go-mod-migrate/:1:0","tags":null,"title":"Go 项目迁移到 mod","uri":"/posts/2019-07-24-go-mod-migrate/"},{"categories":["Go"],"content":"和 dep 的区别 dep 是解析所有的包引用，然后在 $GOPATH/pkg/dep 下进行缓存，再在项目下生成 vendor，然后基于 vendor 来构建项目，无法脱离 GOPATH。 mod 是解析所有的包引用，然后在 $GOPATH/pkg/mod 下进行缓存，直接基于缓存包来构建项目，所以可以脱离 GOPATH ","date":"2019-07-24","objectID":"/posts/2019-07-24-go-mod-migrate/:1:1","tags":null,"title":"Go 项目迁移到 mod","uri":"/posts/2019-07-24-go-mod-migrate/"},{"categories":["Go"],"content":"准备环境 golang 1.11 的环境需要开启 GO11MODULE ，并且确保项目目录不在 GOPATH 中。 export GO111MODULE=on golang 1.12只需要确保实验目录不在 GOPATH 中。 配置代理 export GOPROXY=https://goproxy.io。（如果拉取包失败，会报 cannot find module for path xxx 的错误） ","date":"2019-07-24","objectID":"/posts/2019-07-24-go-mod-migrate/:2:0","tags":null,"title":"Go 项目迁移到 mod","uri":"/posts/2019-07-24-go-mod-migrate/"},{"categories":["Go"],"content":"迁移项目 # clone 项目, 不要在 `GOPATH` 中, 之前的项目的结构是 `GOPATH/src/keel-mannager` git clone https://github.com/xxx/keel-mannager # 删除 vender cd keel-mannager rm -rf vender # init go mod init keel-mannager # 下载依赖 也可以不执行这一步， go run 或 go build 会自动下载 go mod download Go 会把 Gopkg.lock 或者 glide.lock 中的依赖项写入到 go.mod 文件中。go.mod 文件的内容像下面这样： module keel-manager\rrequire (\rgithub.com/fsnotify/fsnotify v1.4.7\rgithub.com/gin-contrib/sse v0.0.0-20170109093832-22d885f9ecc7\rgithub.com/gin-gonic/gin v0.0.0-20180814085852-b869fe1415e4\rgithub.com/golang/protobuf v0.0.0-20170601230230-5a0f697c9ed9\rgithub.com/hashicorp/hcl v1.0.0\rgithub.com/inconshreveable/mousetrap v0.0.0-20141017200713-76626ae9c91c\rgithub.com/json-iterator/go v0.0.0-20170829155851-36b14963da70\rgithub.com/lexkong/log v0.0.0-20180607165131-972f9cd951fc\rgithub.com/magiconair/properties v1.8.0\rgithub.com/mattn/go-isatty v0.0.0-20170307163044-57fdcb988a5c\rgithub.com/mitchellh/mapstructure v1.1.2\rgithub.com/pelletier/go-toml v1.2.0\rgithub.com/satori/go.uuid v0.0.0-20180103152354-f58768cc1a7a\rgithub.com/spf13/afero v1.1.2\rgithub.com/spf13/cast v1.3.0\rgithub.com/spf13/cobra v0.0.0-20180427134550-ef82de70bb3f\rgithub.com/spf13/jwalterweatherman v1.0.0\rgithub.com/spf13/pflag v1.0.3\rgithub.com/spf13/viper v0.0.0-20181207100336-6d33b5a963d9\rgithub.com/ugorji/go v1.1.2-0.20180831062425-e253f1f20942\rgithub.com/willf/pad v0.0.0-20160331131008-b3d780601022\rgolang.org/x/sys v0.0.0-20190116161447-11f53e031339\rgolang.org/x/text v0.3.0\rgopkg.in/go-playground/validator.v8 v8.0.0-20160718134125-5f57d2222ad7\rgopkg.in/yaml.v2 v2.2.2\r) 如果是一个新项目，或者删除了 Gopkg.lock 文件，可以直接运行： go mod init keel-mannager # 拉取必须模块 移除不用的模块 go mod tidy 接下来就可以运行 go run main.go 了。 ","date":"2019-07-24","objectID":"/posts/2019-07-24-go-mod-migrate/:3:0","tags":null,"title":"Go 项目迁移到 mod","uri":"/posts/2019-07-24-go-mod-migrate/"},{"categories":["Go"],"content":"添加新依赖包 添加新依赖包有下面几种方式： 直接修改 go.mod 文件，然后执行 go mod download。 使用 go get packagename@vx.x.x，会自动更新 go.mod 文件的。 go run、go build 也会自动下载依赖。 ","date":"2019-07-24","objectID":"/posts/2019-07-24-go-mod-migrate/:4:0","tags":null,"title":"Go 项目迁移到 mod","uri":"/posts/2019-07-24-go-mod-migrate/"},{"categories":["Go"],"content":"依赖包冲突问题 迁移后遇到了下面的报错： ../gowork/pkg/mod/github.com/gin-gonic/gin@v0.0.0-20180814085852-b869fe1415e4/binding/msgpack.go:12:2: unknown import path \"github.com/ugorji/go/codec\": ambiguous import: found github.com/ugorji/go/codec in multiple modules: github.com/ugorji/go v0.0.0-20170215201144-c88ee250d022 (/root/gowork/pkg/mod/github.com/ugorji/go@v0.0.0-20170215201144-c88ee250d022/codec) github.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8 (/root/gowork/pkg/mod/github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8) 通过 go mod graph 可以查看具体依赖路径： github.com/spf13/viper@v1.3.2 github.com/ugorji/go/codec@v0.0.0-20181204163529-d75b2dcb6bc8 github.com/gin-gonic/gin@v1.3.1-0.20190120102704-f38a3fe65f10 github.com/ugorji/go@v1.1.1 可以看到 viper 和 gin 分别依赖了 github.com/ugorji/go 和 github.com/ugorji/go/codec。 应该是 go 把这两个 path 当成不同的模块引入导致的冲突。workaround。 ","date":"2019-07-24","objectID":"/posts/2019-07-24-go-mod-migrate/:5:0","tags":null,"title":"Go 项目迁移到 mod","uri":"/posts/2019-07-24-go-mod-migrate/"},{"categories":["Node.js"],"content":"koa2 是基于 Node.js 实现的一个 web 框架。非常简洁，轻量，所有的功能都以插件的形式实现，开发者可以 按需引入。 我们从一个官方示例开始，来看看 koa 的实现原理： const Koa = require('koa'); const app = new Koa(); app.use(async ctx =\u003e { ctx.body = 'Hello World'; }); app.listen(3000); koa 的源码主要有四个文件，分别是 application.js、context.js、request.js、response.js。 application.js 是 koa 的入口文件，app.use 和 app.listen 的实现就在这个文件中。 ","date":"2019-06-10","objectID":"/posts/2019-06-10-koa2-resource-code-analysis/:0:0","tags":null,"title":"koa2 框架源码分析","uri":"/posts/2019-06-10-koa2-resource-code-analysis/"},{"categories":["Node.js"],"content":"application.js new Koa() 创建了一个 Application 实例，Application 的构造函数： const Emitter = require('events'); class Application extends Emitter { constructor(options) { super(); options = options || {}; this.proxy = options.proxy || false; this.subdomainOffset = options.subdomainOffset || 2; this.proxyIpHeader = options.proxyIpHeader || 'X-Forwarded-For'; this.maxIpsCount = options.maxIpsCount || 0; this.env = options.env || process.env.NODE_ENV || 'development'; if (options.keys) this.keys = options.keys; this.middleware = []; this.context = Object.create(context); this.request = Object.create(request); this.response = Object.create(response); if (util.inspect.custom) { this[util.inspect.custom] = this.inspect; } } } Application 类继承了 events，这样 app 就有了事件监听的能力。构造函数还为实例添加了一系列的属性，比如经常会用到的 middleware、 context、request、response 等。 Application 还暴露了一些常用的方法，比如 listen、use 等等。 我们从 listen 方法开始分析： listen(...args) { debug('listen'); const server = http.createServer(this.callback()); return server.listen(...args); } listen 方法其实就是对 http.createServer 进行了一个简单的封装。这里启动的 http server。如果要启用 https，就不能使用 listen 方法了，可以直接使用 https 包来创建： const https = require('https'); const Koa = require('koa'); const app = new Koa(); https.createServer(app.callback()).listen(3001); listen 方法中应该关注 callback 的实现： callback() { const fn = compose(this.middleware); if (!this.listenerCount('error')) this.on('error', this.onerror); const handleRequest = (req, res) =\u003e { const ctx = this.createContext(req, res); return this.handleRequest(ctx, fn); }; return handleRequest; } compose(this.middleware) 是引用的插件 koa-compose 的方法。 middlleware 是一个数组，存放的是通过 app.use 添加的中间件。 app.use 如何添加中间件： use(fn) { // 检查传入的中间件是否是函数 if (typeof fn !== 'function') throw new TypeError('middleware must be a function!'); if (isGeneratorFunction(fn)) { // 检查是否是 generator 函数，为了兼容 koa1 deprecate('Support for generators will be removed in v3. ' + 'See the documentation for examples of how to convert old middleware ' + 'https://github.com/koajs/koa/blob/master/docs/migration.md'); fn = convert(fn); // 将 koa1 中的 generator 函数转为 Promise 函数 } debug('use %s', fn._name || fn.name || '-'); this.middleware.push(fn); // 把中间件添加到 middleware 数组 return this; // 返回 this，链式调用 } compose 方法是 koa 中间件机制最重要的部分： /** * Compose `middleware` returning * a fully valid middleware comprised * of all those which are passed. * * @param {Array} middleware * @return {Function} * @api public */ function compose (middleware) { // 检查传入的中间件数组，是否是一个真的数组 if (!Array.isArray(middleware)) throw new TypeError('Middleware stack must be an array!') for (const fn of middleware) { // 检查数组中的元素是否是函数 if (typeof fn !== 'function') throw new TypeError('Middleware must be composed of functions!') } /** * @param {Object} context * @return {Promise} * @api public */ return function (context, next) { // 这里返回一个函数，koa 的 ctx 和 next 作为参数 // last called middleware # let index = -1 return dispatch(0) function dispatch (i) { if (i \u003c= index) return Promise.reject(new Error('next() called multiple times')) index = i let fn = middleware[i] if (i === middleware.length) fn = next if (!fn) return Promise.resolve() try { return Promise.resolve(fn(context, dispatch.bind(null, i + 1))); } catch (err) { return Promise.reject(err) } } } } compose 返回了一个函数， 先不管函数里面怎么执行，接着回到 Application 的callback 方法： callback() { const fn = compose(this.middleware); if (!this.listenerCount('error')) this.on('error', this.onerror); // listenerCount 是继承与 event 对象的方法。判断是否监听了 error 事件, // 如果没有，添加 error 事件监听 const handleRequest = (req, res) =\u003e { // req 和 res 作为参数 const ctx = this.createContext(req, res); // 使用原生 request 和 response 对象创建 koa 的 Context 对象 return this.handleRequest(ctx, fn); // 处理请求，传入 compose 返回的 fn 函数，串行执行中间件 }; return handleRequest; } callback 方法返回了一个 handleRequest 函数，这是 http.createServer 接收的回调函数。handleRequest 方法被加入到 request 事件中。当服务器接收到 http 请求时，request 事件被触发，然后调用 handleRequest 方法。 handleRequest 方法又调用了 this.handleRequest(ctx, fn)： handleRequest(ctx, fnMiddleware) { const res = ctx.res; res.statusCode = 404","date":"2019-06-10","objectID":"/posts/2019-06-10-koa2-resource-code-analysis/:1:0","tags":null,"title":"koa2 框架源码分析","uri":"/posts/2019-06-10-koa2-resource-code-analysis/"},{"categories":["Node.js"],"content":"context.js Context 包含了两个部分： 自身属性，框架内部使用 通过 delegates 库，代理了 request, response 对象上的属性。 application.js 的 createContext 方法创建 ctx 对象： createContext(req, res) { const context = Object.create(this.context); const request = context.request = Object.create(this.request); const response = context.response = Object.create(this.response); context.app = request.app = response.app = this; context.req = request.req = response.req = req; context.res = request.res = response.res = res; request.ctx = response.ctx = context; request.response = response; response.request = request; context.originalUrl = request.originalUrl = req.url; context.state = {}; return context; } /** * Response delegation. */ delegate(proto, 'response') .method('attachment') .method('redirect') .method('remove') .method('vary') .method('has') .method('set') .method('append') .method('flushHeaders') .access('status') .access('message') .access('body') .access('length') .access('type') .access('lastModified') .access('etag') .getter('headerSent') .getter('writable'); /** * Request delegation. */ delegate(proto, 'request') .method('acceptsLanguages') .method('acceptsEncodings') .method('acceptsCharsets') .method('accepts') .method('get') .method('is') .access('querystring') .access('idempotent') .access('socket') .access('search') .access('method') .access('query') .access('path') .access('url') .access('accept') .getter('origin') .getter('href') .getter('subdomains') .getter('protocol') .getter('host') .getter('hostname') .getter('URL') .getter('header') .getter('headers') .getter('secure') .getter('stale') .getter('fresh') .getter('ips') .getter('ip'); 上面的代码通过 delegate 代理了 ctx.request 和 ctx.response 两个对象上的属性。 也就是说，你可以直接通过访问 ctx.status 来得到 ctx.repsponse.status 的值。 ","date":"2019-06-10","objectID":"/posts/2019-06-10-koa2-resource-code-analysis/:2:0","tags":null,"title":"koa2 框架源码分析","uri":"/posts/2019-06-10-koa2-resource-code-analysis/"},{"categories":["Node.js"],"content":"request.js、response.js 这两部分就是对原生的 http 模块 request、response 对象进行了封装，在对象属性上添加了 setter 和 getter。暴露了一些新的方法。 ","date":"2019-06-10","objectID":"/posts/2019-06-10-koa2-resource-code-analysis/:3:0","tags":null,"title":"koa2 框架源码分析","uri":"/posts/2019-06-10-koa2-resource-code-analysis/"},{"categories":["Node.js"],"content":"错误处理 koa 有两个 onerror 方法，一个是 Application 的，监听整个应用的 error 事件。一个是 Context 对象的 onerror，监听处理 http request 和 response 时的 error 事件。 application.js 的 onerror： onerror(err) { // 判断是否是 Error 类型 if (!(err instanceof Error)) throw new TypeError(util.format('non-error thrown: %j', err)); // 忽略 404 错误 if (404 == err.status || err.expose) return; // 如果有静默设置, 则忽略 if (this.silent) return; // 打印 error const msg = err.stack || err.toString(); console.error(); console.error(msg.replace(/^/gm, ' ')); console.error(); } application.js 的 callback 方法中有段代码：if (!this.listenerCount('error')) this.on('error', this.onerror);，如果开 发者没有调用 app.on('error', func)监听 error 事件，那么就会在这里添加默认的 onerror 回调来监听 error 事件。 context.js 的 onerror： onerror(err) { // don't do anything if there is no error. // this allows you to pass `this.onerror` // to node-style callbacks. if (null == err) return; // 将错误转化 Error 类型 if (!(err instanceof Error)) err = new Error(util.format('non-error thrown: %j', err)); let headerSent = false; if (this.headerSent || !this.writable) { headerSent = err.headerSent = true; } // delegate // 触发 koa app 对象的 error 事件, application 上的 onerror 函数会执行 this.app.emit('error', err, this); // nothing we can do here other // than delegate to the app-level // handler and log. // 如果响应头部已经发送(或者 socket 不可写), 退出函数 if (headerSent) { return; } // 获取原生 http response 对象 const { res } = this; // first unset all headers /* istanbul ignore else */ if (typeof res.getHeaderNames === 'function') { res.getHeaderNames().forEach(name =\u003e res.removeHeader(name)); } else { res._headers = {}; // Node \u003c 7.7 } // then set those specified this.set(err.headers); // force text/plain // 出错后响应类型为 text/plain this.type = 'text'; // ENOENT support // 对 ENOENT 错误进行处理, ENOENT 的错误 message 是文件或者路径不存在, 所以状态码应该是 404 if ('ENOENT' == err.code) err.status = 404; // default to 500 // 默认状态码为 500 if ('number' != typeof err.status || !statuses[err.status]) err.status = 500; // respond const code = statuses[err.status]; const msg = err.expose ? err.message : code; // 设置响应状态码 this.status = err.status; // 设置响应 body 长度 this.length = Buffer.byteLength(msg); // 响应结束 res.end(msg); } application.js 的 handleRequest 方法： handleRequest(ctx, fnMiddleware) { const res = ctx.res; res.statusCode = 404; const onerror = err =\u003e ctx.onerror(err); const handleResponse = () =\u003e respond(ctx); onFinished(res, onerror); return fnMiddleware(ctx).then(handleResponse).catch(onerror); } 在 onFinish 函数中会调用 context 的 onerror 方法，来处理响应中的 error 事件。 ","date":"2019-06-10","objectID":"/posts/2019-06-10-koa2-resource-code-analysis/:4:0","tags":null,"title":"koa2 框架源码分析","uri":"/posts/2019-06-10-koa2-resource-code-analysis/"},{"categories":["Node.js"],"content":"koa-router koa 本身并没有实现 router 的功能。需要引入插件。我们通过的 koa-router 的官方示例，来分析 一下路由是如何注册并执行的： var Koa = require('koa'); var Router = require('koa-router'); var app = new Koa(); var router = new Router(); // use middleware only with given path router.use('/users', userAuth()); // or with an array of paths router.use(['/users', '/admin'], userAuth()); router.get('/', (ctx, next) =\u003e { // ctx.router available }); app .use(router.routes()) .use(router.allowedMethods()); koa-router 实现路由的核心文件是 router.js。router.js 也是入口文件。 Router 的构造函数： function Router(opts) { if (!(this instanceof Router)) { return new Router(opts); } this.opts = opts || {}; this.methods = this.opts.methods || [ // 路由方法 'HEAD', 'OPTIONS', 'GET', 'PUT', 'PATCH', 'POST', 'DELETE' ]; this.params = {}; this.stack = []; // 存放注册的路由对象 }; router.js 中定义 router.get 或者 router.post 等方法： // 遍历所有的 method methods.forEach(function (method) { // 添加原型方法 Router.prototype[method] = function (name, path, middleware) { var middleware; // 处理参数，第一个参数可以是路由 name，也可以是路由的 path if (typeof path === 'string' || path instanceof RegExp) { middleware = Array.prototype.slice.call(arguments, 2); } else { middleware = Array.prototype.slice.call(arguments, 1); path = name; name = null; } // 注册路由，这里的第二个参数是一个数组，是为了 all 方法注册时使用 this.register(path, [method], middleware, { name: name }); return this; }; }); 所以调用 router.get 等方法（包括 router.all 和 router.use）注册路由是其实是调用了 register 方法： Router.prototype.register = function (path, methods, middleware, opts) { opts = opts || {}; var router = this; var stack = this.stack; // support array of paths if (Array.isArray(path)) { // 如果 path 是一个数组，遍历所有 path，分别为每一个 path 注册路由 path.forEach(function (p) { router.register.call(router, p, methods, middleware, opts); }); return this; } // create route // 创建路由对象 var route = new Layer(path, methods, middleware, { end: opts.end === false ? opts.end : true, name: opts.name, sensitive: opts.sensitive || this.opts.sensitive || false, strict: opts.strict || this.opts.strict || false, prefix: opts.prefix || this.opts.prefix || \"\", ignoreCaptures: opts.ignoreCaptures }); // 添加路由前缀 if (this.opts.prefix) { route.setPrefix(this.opts.prefix); } // add parameter middleware // // 设置 param 前置处理函数 Object.keys(this.params).forEach(function (param) { route.param(param, this.params[param]); }, this); // 存储路由对象 stack.push(route); return route; }; 注册完路由，必须通过 app.use(router.routes()) 方法将所有的路由，添加到 koa 的中间件，router.routes() 方法做了什么： Router.prototype.routes = Router.prototype.middleware = function () { var router = this; // 有点似曾相识，类似 compose 的实现 var dispatch = function dispatch(ctx, next) { debug('%s %s', ctx.method, ctx.path); var path = router.opts.routerPath || ctx.routerPath || ctx.path; // 匹配路由 var matched = router.match(path, ctx.method); var layerChain, layer, i; // 将匹配的路由缓存到 context 对象 if (ctx.matched) { ctx.matched.push.apply(ctx.matched, matched.path); } else { ctx.matched = matched.path; } ctx.router = router; if (!matched.route) return next(); // // 未匹配到路由，执行下一个中间件 var matchedLayers = matched.pathAndMethod var mostSpecificLayer = matchedLayers[matchedLayers.length - 1] ctx._matchedRoute = mostSpecificLayer.path; if (mostSpecificLayer.name) { ctx._matchedRouteName = mostSpecificLayer.name; } // 路由的前置处理中间件 将 params、路由别名以及捕获数组属性挂载到 context 上下文对象中 layerChain = matchedLayers.reduce(function(memo, layer) { // 将所有的 layer 封装成了 koa 的中间件函数 memo.push(function(ctx, next) { ctx.captures = layer.captures(path, ctx.captures); ctx.params = layer.params(path, ctx.captures, ctx.params); ctx.routerName = layer.name; // 进入下一个路由中间件 return next(); }); return memo.concat(layer.stack); }, []); // 返回了 compose 函数，这个函数也同样式依赖 `koa-compose` // 将所有匹配的路由 和 路由中间件的数组传入，并执行 compose 返回的函数 // 注意 koa 是在 `application.js` 的 `callback` 方法中执行 compose 返回的函数 // 这里利用 compose 函数，又实现了一个洋葱模型 return compose(layerChain)(ctx, next); }; dispatch.router = this; return dispatch; }; routes 方法返回了 dispatch 函数。dispatch 函数被注册到了 koa 的中间件，那么按照 koa 中间件的执行机制，dispatch 函数 最终会在某个 koa 中间件中执行 next 时被执行。 router.match 的实现： Router","date":"2019-06-10","objectID":"/posts/2019-06-10-koa2-resource-code-analysis/:5:0","tags":null,"title":"koa2 框架源码分析","uri":"/posts/2019-06-10-koa2-resource-code-analysis/"},{"categories":["Linux"],"content":"Linux 下使用 AB 进行压力测试。 ","date":"2019-03-06","objectID":"/posts/2019-03-06-http-tools/:0:0","tags":null,"title":"Linux 下使用 AB 进行压力测试","uri":"/posts/2019-03-06-http-tools/"},{"categories":["Linux"],"content":"安装 AB 测试工具安装：yum install -y httpd-tools ","date":"2019-03-06","objectID":"/posts/2019-03-06-http-tools/:1:0","tags":null,"title":"Linux 下使用 AB 进行压力测试","uri":"/posts/2019-03-06-http-tools/"},{"categories":["Linux"],"content":"GET 请求 ab -n 1000 -c 100 http://www.baidu.com/ -n，总的请求数 -c，单个时刻并发数 压测结果： This is ApacheBench, Version 2.3 \u003c$Revision: 1430300 $\u003e Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking juejin.im (be patient) Completed 100 requests Completed 200 requests Completed 300 requests Completed 400 requests Completed 500 requests Completed 600 requests Completed 700 requests Completed 800 requests Completed 900 requests Completed 1000 requests Finished 1000 requests Server Software: nginx Server Hostname: juejin.im Server Port: 443 SSL/TLS Protocol: TLSv1.2,ECDHE-RSA-AES256-GCM-SHA384,2048,256 Document Path: / Document Length: 271405 bytes Concurrency Level: 100（并发数：100） Time taken for tests: 120.042 seconds（一共用了 120 秒） Complete requests: 1000（总的请求数：1000） Failed requests: 0（失败的请求次数） Write errors: 0 Total transferred: 271948000 bytes HTML transferred: 271405000 bytes Requests per second: 8.33 [#/sec] (mean)（QPS 系统吞吐量，平均每秒请求数，计算公式 = 总请求数 / 总时间数） Time per request: 12004.215 [ms] (mean)（毫秒，平均每次并发 100 个请求的处理时间） Time per request: 120.042 [ms] (mean, across all concurrent requests)（毫秒，并发 100 下，平均每个请求处理时间） Transfer rate: 2212.34 [Kbytes/sec] received（平均每秒网络流量） Connection Times (ms) min mean[+/-sd] median max Connect: 57 159 253.6 77 1002 Processing: 1139 11570 2348.2 11199 36198 Waiting: 156 1398 959.4 1279 22698 Total: 1232 11730 2374.1 11300 36274 Percentage of the requests served within a certain time (ms) 50% 11300 66% 11562 75% 11863 80% 12159 90% 13148 95% 15814 98% 18882 99% 22255 100% 36274 (longest request) ","date":"2019-03-06","objectID":"/posts/2019-03-06-http-tools/:2:0","tags":null,"title":"Linux 下使用 AB 进行压力测试","uri":"/posts/2019-03-06-http-tools/"},{"categories":["Linux"],"content":"POST 请求 ab -n 5000 -c 200 -p data.txt -T application/x-www-form-urlencoded http://your.api -p，请求数据的文件的完整路经。 -T，Content-Type。 -p 指定文件的格式应该是 name1=value1\u0026name2=value2。 注意，如果是在内网请求外网，要加上 -X hostname:port，指定你的 http 代理。 ","date":"2019-03-06","objectID":"/posts/2019-03-06-http-tools/:3:0","tags":null,"title":"Linux 下使用 AB 进行压力测试","uri":"/posts/2019-03-06-http-tools/"},{"categories":["Linux"],"content":"其他参数 可以使用ab --help查看： Usage: ab [options] [http[s]://]hostname[:port]/path Options are: -n requests Number of requests to perform -c concurrency Number of multiple requests to make -t timelimit Seconds to max. wait for responses -b windowsize Size of TCP send/receive buffer, in bytes -p postfile File containing data to POST. Remember also to set -T -u putfile File containing data to PUT. Remember also to set -T -T content-type Content-type header for POSTing, eg. 'application/x-www-form-urlencoded' Default is 'text/plain' -v verbosity How much troubleshooting info to print -w Print out results in HTML tables -i Use HEAD instead of GET -x attributes String to insert as table attributes -y attributes String to insert as tr attributes -z attributes String to insert as td or th attributes -C attribute Add cookie, eg. 'Apache=1234. (repeatable) -H attribute Add Arbitrary header line, eg. 'Accept-Encoding: gzip' Inserted after all normal header lines. (repeatable) -A attribute Add Basic WWW Authentication, the attributes are a colon separated username and password. -P attribute Add Basic Proxy Authentication, the attributes are a colon separated username and password. -X proxy:port Proxyserver and port number to use -V Print version number and exit -k Use HTTP KeepAlive feature -d Do not show percentiles served table. -S Do not show confidence estimators and warnings. -g filename Output collected data to gnuplot format file. -e filename Output CSV file with percentages served -r Don't exit on socket receive errors. -h Display usage information (this message) -Z ciphersuite Specify SSL/TLS cipher suite (See openssl ciphers) ","date":"2019-03-06","objectID":"/posts/2019-03-06-http-tools/:4:0","tags":null,"title":"Linux 下使用 AB 进行压力测试","uri":"/posts/2019-03-06-http-tools/"},{"categories":["Linux"],"content":"常见问题 ","date":"2019-03-06","objectID":"/posts/2019-03-06-http-tools/:5:0","tags":null,"title":"Linux 下使用 AB 进行压力测试","uri":"/posts/2019-03-06-http-tools/"},{"categories":["Linux"],"content":"当并发设置为 250 以上的时候就会出现 apr_socket_recv Connection refused 111 错误 这是因为是 linux 网络参数设置。一般 apache 默认最大并发量为 150，可以进入配置文件修改 Threadperchild 等参数值。 如何调整 Apache 的最大并发量： vi /etc/sysctl.conf net.nf_conntrack_max = 655360 net.netfilter.nf_conntrack_tcp_timeout_established = 1200 sysctl -p /etc/sysctl.conf 修改后，重新启用 apache ab 进行测试，问题解决。 ","date":"2019-03-06","objectID":"/posts/2019-03-06-http-tools/:5:1","tags":null,"title":"Linux 下使用 AB 进行压力测试","uri":"/posts/2019-03-06-http-tools/"},{"categories":["Linux"],"content":"NVM 是 Node.js 版本管理工具，可以更方便的安装、更新、切换 Node.js 的版本。 ","date":"2018-10-23","objectID":"/posts/2018-10-23-linux-nvm/:0:0","tags":null,"title":"CentOs 安装 NVM","uri":"/posts/2018-10-23-linux-nvm/"},{"categories":["Linux"],"content":"安装 ","date":"2018-10-23","objectID":"/posts/2018-10-23-linux-nvm/:1:0","tags":null,"title":"CentOs 安装 NVM","uri":"/posts/2018-10-23-linux-nvm/"},{"categories":["Linux"],"content":"安装脚本 使用 curl 安装： curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.11/install.sh | bash 使用 wget 安装： wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.11/install.sh | bash 这个脚本会克隆 nvm 仓库到 ~/.nvm，并且在你的 profile 文件(~/.bash_profile, ~/.zshrc, ~/.profile,或者 ~/.bashrc)中 添加下面的内容： export NVM_DIR=\"$HOME/.nvm\" [ -s \"$NVM_DIR/nvm.sh\" ] \u0026\u0026 \\. \"$NVM_DIR/nvm.sh\" # This loads nvm 然后就可以使用 nvm 命令查看是否安装成功，如果这是提示找不到命令，说明环境变量没有生效，执行 source ~/.bashrc 或者 ~/.zshrc。 ","date":"2018-10-23","objectID":"/posts/2018-10-23-linux-nvm/:1:1","tags":null,"title":"CentOs 安装 NVM","uri":"/posts/2018-10-23-linux-nvm/"},{"categories":["Linux"],"content":"简单使用 nvm 上面的命令会列出所有的nvm命令： ","date":"2018-10-23","objectID":"/posts/2018-10-23-linux-nvm/:2:0","tags":null,"title":"CentOs 安装 NVM","uri":"/posts/2018-10-23-linux-nvm/"},{"categories":["Linux"],"content":"常用命令 nvm --help # 显示所有信息 nvm --version # 显示当前安装的 nvm 版本 nvm install [-s] \u003cversion\u003e # 安装指定的版本，如果不存在 .nvmrc ,就从指定的资源下载安装 nvm install [-s] \u003cversion\u003e -latest-npm # 安装指定的版本，并且下载最新的 npm nvm uninstall \u003cversion\u003e # 卸载指定的 nodejs 版本 nvm use [--silent] \u003cversion\u003e # 切换使用已经安装的 nodejs 版本 nvm current # 查看当前 nodejs 版本 nvm ls # 查看所有已经安装的 nodejs 版本 nvm ls \u003cversion\u003e # 查看指定版本的 nodejs nvm ls-remote # 显示远程所有可以安装的 nodejs 版本 nvm ls-remote --lts # 查看所有长期支持的 nodejs 版本 nvm alias \u003cname\u003e \u003cversion\u003e # 给指定的版本号添加别名 nvm unalias \u003cname\u003e # 删除已定义的别名 nvm install-latest-npm # 安装最新版本的 npm nvm reinstall-packages \u003cversion\u003e # 重新安装指定版本的 nodejs nvm cache dir # 显示 nvm 的 cache nvm cache clear # 清空 nvm 的 cache ","date":"2018-10-23","objectID":"/posts/2018-10-23-linux-nvm/:2:1","tags":null,"title":"CentOs 安装 NVM","uri":"/posts/2018-10-23-linux-nvm/"},{"categories":["Linux"],"content":"在 Linux 下如何实现定时执行脚本。可以使用 crontab。 Linux 默认安装 crontab，一般被用来执行周期性任务。crond 进程会定期检查是否有要执行的任务，如果有，则自动执行。 ","date":"2018-08-22","objectID":"/posts/2018-08-22-linux-crontrab/:0:0","tags":null,"title":"Linux 定时任务","uri":"/posts/2018-08-22-linux-crontrab/"},{"categories":["Linux"],"content":"crontab 命令 crontab [OPTIONS] [ARGS] OPTIONS -e：设置指定用户计时器； -l：列出指定用户的所有计时器设置； -r：删除指定用户的计时器设置； -u：指定用户名，如果不指定，默认是当前用户。 ARGS 指定要执行脚本文件。 ","date":"2018-08-22","objectID":"/posts/2018-08-22-linux-crontrab/:1:0","tags":null,"title":"Linux 定时任务","uri":"/posts/2018-08-22-linux-crontrab/"},{"categories":["Linux"],"content":"系统任务和用户任务 ","date":"2018-08-22","objectID":"/posts/2018-08-22-linux-crontrab/:2:0","tags":null,"title":"Linux 定时任务","uri":"/posts/2018-08-22-linux-crontrab/"},{"categories":["Linux"],"content":"系统任务 /etc/crontab 文件是系统任务的配置文件： SHELL=/bin/bash # 指定系统要使用的shell 这里是bash PATH=/sbin:/bin:/usr/sbin:/usr/bin # 指定系统执行命令的路径 MAILTO=\"\" # 指定 crond 的任务执行信息将通过电子邮件发送给 root 用户，为空则不发送 HOME=/ # 指定在执行命令或者脚本时使用的主目录。 0 1 * * * root /user/local/run.sh 注意系统任务要指定用户，如上面例子中的 root，否则会报错 ERROR (getpwnam() failed)。 ","date":"2018-08-22","objectID":"/posts/2018-08-22-linux-crontrab/:2:1","tags":null,"title":"Linux 定时任务","uri":"/posts/2018-08-22-linux-crontrab/"},{"categories":["Linux"],"content":"用户任务 用户定义的 crontab 文件保存在 /var/spool/cron，文件名与用户名一致。 还有两个文件比较重要： /etc/cron.deny: 包含了所有不允许使用 crontab 命令的用户 /etc/cron.deny: 包含了所有允许使用 crontab 命令的用户 在用户的 crontab 文件中，每一行就是一个任务，怎么定义用户任务，我们以上面的 crontab 文件中的任务 0 1 * * * root /user/local/run.sh 为例，一行任务分为六段： minute hour day month week command minute： 分钟，从 0 到59 之间的任何整数。 hour：小时，从 0 到 23 之间的任何整数。 day：日期，从 1 到 31 之间的任何整数。 month：月份，从 1 到 12 之间的任何整数。 week: 星期几，从 0 到 7 之间的任何整数，0 或 7 代表星期日。 command: 行的命令，可以是系统命令，也可以是脚本文件。 各段中还可以使用下面的字符： *：代表所有可能的值，例如 month 字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 ,：可以用逗号隔开的值指定一个列表范围，例如，1,2,5,7,8 -：可以用整数之间的中杠表示一个整数范围，如 1-5 表示 1,2,3,4,5 /：可以用正斜线指定时间的间隔频率，例如 0-23/2 表示每两小时执行一次。同时正斜线可以和星号一起使用，如 */10，如果用在 minute 字段， 表示每十分钟执行一次。 Example * * * * * command 每分钟执行一次 command。 10,20 * * * * command 每小时的第 10 和第 20 分钟执行一次。 10,20 8-11 */2 * * command 每隔两天的上午 8 点到 11 点的第 10 和第 20 分钟执行。 10 1 * * 6,0 /etc/init.d/smb restart 每周六、周日的一点十分重启 smb ","date":"2018-08-22","objectID":"/posts/2018-08-22-linux-crontrab/:2:2","tags":null,"title":"Linux 定时任务","uri":"/posts/2018-08-22-linux-crontrab/"},{"categories":["Linux"],"content":"crontab 中的环境变量 crontab 执行定时任务时自动执行失败，但是手动执行可以，报类似的错：xx command not found，这说明配置的环境变量未找到。这是应为 crontab 执行脚本时用的是系统的环境变量，用户定义的环境变量找不到。 解决方案： 脚本中涉及到的的文件路径使用绝对路径。 脚本中的命令式用户自定义的环境变量可以在脚本头部执行 source 命令引入环境变量，如 source /etc/profile。 如果上述方法都无效，可以在 crontab 文件中引入环境变量，如 * * * * * . /etc/profile;/bin/bash command ","date":"2018-08-22","objectID":"/posts/2018-08-22-linux-crontrab/:3:0","tags":null,"title":"Linux 定时任务","uri":"/posts/2018-08-22-linux-crontrab/"},{"categories":["Linux"],"content":"其他问题 可以在任务后面加上 * * * * * /root/install.sh \u003e/dev/null 2\u003e\u00261 将日志重定向处理，避免 crontab 运行中有内容输出。 也可以追加到日志文件，如 * * * * * /root/install.sh \u003e\u003e /root/install.log 2\u003e\u00261。 ","date":"2018-08-22","objectID":"/posts/2018-08-22-linux-crontrab/:4:0","tags":null,"title":"Linux 定时任务","uri":"/posts/2018-08-22-linux-crontrab/"},{"categories":["Others"],"content":"最近在工作中，碰到了一个 security 的问题，产品容易被 CSRF 攻击，于是就对 CSRF 的攻击和防御原理，做了调研。 ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:0:0","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"什么是 CSRF CSRF（Cross Site Request Forgery, 跨站域请求伪造）是一种网络的攻击方式，它在 2007 年曾被列为互联网 20 大安全隐患之一。 简单地说，攻击者盗用了你的身份，在你非自愿的情况下，以你的名义发送恶意的请求。（发送邮件，发消息，盗取你的账号，购买商品，虚拟货币转账） CSRF 攻击之所以能够成功，是因为黑客通过借助用户的 cookie 骗取服务器的信任，伪造用户的请求。要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的 信息，并且该信息不存在于 cookie 之中。 ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:1:0","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"防御策略 在业界常用的防御 CSRF 攻击的策略有三种： 验证 HTTP Referer 字段 CSRF Token 验证码 ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:2:0","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"验证 HTTP Referer ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:3:0","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"Referer 在 HTTP 请求的 Headers 部分 Referer 通常是像这样： Referer http://www.baidu.com/s?tn=98835442_hao_pg\u0026ie=utf-8\u0026f=3\u0026wd=126.com\u0026oq=126.\u0026bs=126.com\u0026rsv_bp=1\u0026inputT=5799\u0026rsp=0 Referer 主要用来让服务器判断来源页面，通常被网站用来统计用户来源，比如是从搜索页面，还是从其他网站链接过来，或是从书签访问，方便网站定位。 Referer 有时也被用作防盗链，即下载时判断来源地址是不是在网站域名之内，否则就不能下载或显示。还可用做电子商务网站的安全，在提交信用卡等重要 信息的页面用 Referer 来判断上一页是不是自己的网站，如果不是，可能是黑客用自己写的一个表单，来提交，为了能跳过你上一页里的 javascript 的验证 等目的。 ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:3:1","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"优点 简单易行，不需要做过多的修改，在敏感的请求前统一加拦截器检查 Referer 就可以了。 ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:3:2","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"缺点 Referer 的值是由浏览器给的，虽然使用最新的浏览器，黑客无法篡改 Referer 值，但是 HTML5 添加了一大堆有用的新值到 rel 属性上，其中有一个 值是 noreferrer。当这个属性被添加上之后，用户请求该链接资源时，浏览器不设置 Referer 头。 安全性依赖于浏览器来保障，并不安全，Referer 值在一些浏览器中可能被篡改，比如 IE6 或 FF2。 ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:3:3","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"CSRF Token 要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的信息，并且该信息不存在于 cookie 之中。可以在用户登陆后，服务器返回一个 Token，储存在客户 端（可以将 token 存在 localstorage/sessionstorage 中）。 在请求的时候，把 Token 当做参数放到 URL 中，或者放到 Headers 的自定义属性中。服务端（可以将 token 保存在 memcache/redis）在收到请求后， 对 Token 进行校验。 生成 token 有很多种方法，任何的随机算法都可以使用，UUID 也是一个不错的选择。 ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:4:0","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"优点 比验证 HTTP Referer 的方式要更安全。 ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:4:1","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"缺点 把 Token 当做参数放到 URL 中，就难以保证 token 本身的安全。特别是在一些论坛之类支持用户自己发表内容的网站，黑客可以在上面发布自己个人网站的地址。 由于系统也会在这个地址后面加上 token，黑客可以在自己的网站上得到这个 token，并马上就可以发动 CSRF 攻击。为了避免这一点，系统可以在添加 token 的 时候增加一个判断，如果这个链接是链到自己本站的，就在后面添加 token，如果是通向外网则不加。 把 Token 放到 Headers 的自定义属性中，不用担心 token 会透过 Referer 泄露到其他网站中去，但是有局限性，就是必须使用 Ajax 方法的请求才适用。 示例 // 从 headers 中取得 Referer 值 let referer = req.headers[\"Referer\"]; // 判断 Referer 是否以 www.shipengqi.top 开头 if((referer !== null) \u0026\u0026 (referer.trim().startsWith(“www.shipengqi.top”))){ // do someTing // 验证 Token validateToken(req, res); }else{ // error } ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:4:2","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"验证码 通过在表单中添加一个随机的数字或字母验证码的方式，强制用户和应用进行交互，来有效地遏制 CSRF 攻击。 ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:5:0","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Others"],"content":"Node.js CSRF 相关的第三方库 csurf CSRF token middleware for express. alt-xsrf XSRF prevention middleware for express. koa-csrf CSRF token middleware for Koa. koa-atomic-session Atomic sessions for Koa. csrf Logic behind CSRF token creation and verification. ","date":"2018-07-25","objectID":"/posts/2018-07-25-csrf/:6:0","tags":null,"title":"关于 CSRF","uri":"/posts/2018-07-25-csrf/"},{"categories":["Node.js"],"content":"最近要实现一个 web terminal，调研了几个开源的包，最后选择了 Cloud Commander。 选择 Cloud Commander 几个原因： 功能更丰富，支持 vim，支持查看多种文件(images, txt, video …)，Hot keys，Terminal。 文档详细。 还在不断的完善，已经更新到 v10.3.2。 ","date":"2018-07-03","objectID":"/posts/2018-07-03-web-terminal/:0:0","tags":null,"title":"Node.js 实现浏览器终端","uri":"/posts/2018-07-03-web-terminal/"},{"categories":["Node.js"],"content":"安装 npm install cloudcmd -g 因为 Cloud Commander 的 Terminal 功能默认是关闭的，如果使用需要安装 gritty ： npm i gritty -g 安装好之后要配置 --terminal 和 --terminal-path。 ","date":"2018-07-03","objectID":"/posts/2018-07-03-web-terminal/:1:0","tags":null,"title":"Node.js 实现浏览器终端","uri":"/posts/2018-07-03-web-terminal/"},{"categories":["Node.js"],"content":"安装中的错误 如果碰到下面两种错误，都是因为权限引起的错误： 解决： npm config set user 0 npm config set unsafe-perm true npm install cloudcmd -g npm install gritty -g ","date":"2018-07-03","objectID":"/posts/2018-07-03-web-terminal/:1:1","tags":null,"title":"Node.js 实现浏览器终端","uri":"/posts/2018-07-03-web-terminal/"},{"categories":["Node.js"],"content":"简单使用 安装好之后直接运行 cloudcmd 就会打开一个默认的端口 8000，然后访问 http://localhost:8000 就可以了。 如果要使用 terminal 功能： # 查看 gritty 的路径 gritty --path # 输出 /usr/local/lib/node_modules/gritty cloudcmd --terminal --terminal-path /usr/local/lib/node_modules/gritty --save 然后访问 http://localhost:8000： 关于更多配置使用查看 Cloud Commander 官方文档。 如果只是想实现 terminal 功能，可以直接安装使用 gritty。 ","date":"2018-07-03","objectID":"/posts/2018-07-03-web-terminal/:2:0","tags":null,"title":"Node.js 实现浏览器终端","uri":"/posts/2018-07-03-web-terminal/"},{"categories":["Node.js"],"content":"与 Express 集成 ","date":"2018-07-03","objectID":"/posts/2018-07-03-web-terminal/:3:0","tags":null,"title":"Node.js 实现浏览器终端","uri":"/posts/2018-07-03-web-terminal/"},{"categories":["Node.js"],"content":"gritty 与 Express 集成 npm i gritty socket.io express --save 创建服务端： const gritty = require('gritty'); const http = require('http'); const express = require('express'); const io = require('socket.io'); const app = express(); const server = http.createServer(app); const socket = io.listen(server); const port = 1337; app.use(gritty()) app.use(express.static(__dirname)); gritty.listen(socket); server.listen(port); 页面 index.html： \u003cdiv class=\"gritty\"\u003e\u003c/div\u003e \u003cscript src=\"/gritty/gritty.js\"\u003e\u003c/script\u003e \u003cscript\u003e gritty('.gritty'); \u003c/script\u003e ","date":"2018-07-03","objectID":"/posts/2018-07-03-web-terminal/:3:1","tags":null,"title":"Node.js 实现浏览器终端","uri":"/posts/2018-07-03-web-terminal/"},{"categories":["Node.js"],"content":"cloudcmd 与 Express 集成 npm i cloudcmd socket.io express --save 创建服务端： const http = require('http'); const cloudcmd = require('cloudcmd'); const io = require('socket.io'); const app = require('express')(); const port = 1337; const prefix = '/cloudcmd'; const server = http.createServer(app); const socket = io.listen(server, { path: `${prefix}/socket.io` }); const config = { prefix // base URL or function which returns base URL (optional) }; const plugins = [ __dirname + '/plugin.js' ]; const filePicker = { data: { FilePicker: { key: 'key' } } }; // override option from json/modules.json const modules = { filePicker, }; app.use(cloudcmd({ socket, // used by Config, Edit (optional) and Console (required) config, // config data (optional) plugins, // optional modules, // optional })); server.listen(port); ","date":"2018-07-03","objectID":"/posts/2018-07-03-web-terminal/:3:2","tags":null,"title":"Node.js 实现浏览器终端","uri":"/posts/2018-07-03-web-terminal/"},{"categories":["Node.js"],"content":"Axios 是一个基于 promise 的 HTTP 库，同时支持浏览器和 Node.js，可以用来替代 ajax 请求。 ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:0:0","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"简单使用 ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:1:0","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"安装 npm install axios # 或者 yarn add axios # cdn \u003cscript src=\"https://unpkg.com/axios/dist/axios.min.js\"\u003e\u003c/script\u003e ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:1:1","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"API axios(options) // 或者 axios(url[, options]) // 或者使用请求方法别名 axios.request(options) axios.get(url[, options]) axios.delete(url[, options]) axios.head(url[, options]) axios.post(url[, data[, options]]) axios.put(url[, data[, options]]) axios.patch(url[, data[, options]]) 在使用别名方法发送请求时， url、method、data 这些属性都可以不在配置中指定。 options options: Object, 创建请求时的配置选项。 { // `url` 是用于请求的服务器 URL，必需的选项。 url: '/users', // `method` 是创建请求时使用的方法 method: 'post', // 默认是 get // `baseURL` 将自动加在 `url` 前面，除非 `url` 是一个绝对 URL。 // 可以通过设置一个 `baseURL` 便于为 axios 实例的方法传递相对 URL baseURL: 'https://demo:8080/api/', // `transformRequest` 钩子函数 before request，允许在向服务器发送前，修改请求数据 // 只能用在 'PUT', 'POST' 和 'PATCH' 方法 // 后面数组中的函数必须返回一个字符串，或 ArrayBuffer，或 Stream transformRequest: [function (data) { // 对 data 进行任意转换处理 return data; }], // `transformResponse` 钩子函数 after response，在传递给 then/catch 前，允许修改响应数据 transformResponse: [function (data) { // 对 data 进行任意转换处理 return data; }], // `headers` 设置请求头 headers: {'X-Requested-With': 'XMLHttpRequest'}, // `params` 与请求一起发送的 URL 参数，比如下面的例子中的id会转化为`https://demo:8080/api/users?id=123` // 必须是一个无格式对象(plain object)或 URLSearchParams 对象 params: { id: 123 }, // `paramsSerializer` `params` 序列化的函数 // (e.g. https://www.npmjs.com/package/qs, http://api.jquery.com/jquery.param/) paramsSerializer: function(params) { return Qs.stringify(params, {arrayFormat: 'brackets'}) }, // `data` 是作为请求主体被发送的数据 // 只适用于 'PUT', 'POST', 和 'PATCH' 方法 // 在没有设置 `transformRequest` 时，必须是以下类型之一： // - string, plain object, ArrayBuffer, ArrayBufferView, URLSearchParams // - 浏览器专属：FormData, File, Blob // - Node 专属： Stream data: { firstName: 'Fred' }, // `timeout` 指定请求超时的毫秒数(0 表示无超时时间) // 如果请求话费了超过 `timeout` 的时间，请求将被中断 timeout: 1000, // `withCredentials` 表示跨域请求时是否需要使用凭证 withCredentials: false, // 默认的 // `adapter` 自定义处理请求，以使测试更轻松 // 返回一个 promise 并应用一个有效的响应. adapter: function (config) { /* ... */ }, // `auth` 表示应该使用 HTTP 基础验证，并提供凭据 // 这将设置一个 `Authorization` 头，覆写掉现有的任意使用 `headers` 设置的自定义 `Authorization` 头 auth: { username: 'janedoe', password: 's00pers3cret' }, // `responseType` 表示服务器响应的数据类型，可以是 'arraybuffer', 'blob', 'document', 'json', 'text', 'stream' responseType: 'json', // 默认的 // `xsrfCookieName` 是用作 xsrf token 的值的cookie的名称 xsrfCookieName: 'XSRF-TOKEN', // default // `xsrfHeaderName` 是承载 xsrf token 的值的 HTTP 头的名称 xsrfHeaderName: 'X-XSRF-TOKEN', // 默认的 // `onUploadProgress` 允许为上传处理进度事件 onUploadProgress: function (progressEvent) { // 对原生进度事件的处理 }, // `onDownloadProgress` 允许为下载处理进度事件 onDownloadProgress: function (progressEvent) { // 对原生进度事件的处理 }, // `maxContentLength` 定义允许的响应内容的最大尺寸 maxContentLength: 2000, // `validateStatus` 定义对于给定的HTTP 响应状态码是 resolve 或 reject promise 。如果 `validateStatus` 返回 `true` (或者设置为 `null` 或 `undefined`)，promise 将被 resolve; 否则，promise 将被 rejecte validateStatus: function (status) { return status \u003e= 200 \u0026\u0026 status \u003c 300; // 默认的 }, // `maxRedirects` 定义在 node.js 中 follow 的最大重定向数目 // 如果设置为0，将不会 follow 任何重定向 maxRedirects: 5, // 默认的 // `httpAgent` 和 `httpsAgent` 分别在 node.js 中用于定义在执行 http 和 https 时使用的自定义代理。允许像这样配置选项： // `keepAlive` 默认没有启用 httpAgent: new http.Agent({ keepAlive: true }), httpsAgent: new https.Agent({ keepAlive: true }), // 'proxy' 定义代理服务器的主机名称和端口 // `auth` 表示 HTTP 基础验证应当用于连接代理，并提供凭据 // 这将会设置一个 `Proxy-Authorization` 头，覆写掉已有的通过使用 `header` 设置的自定义 `Proxy-Authorization` 头。 proxy: { host: '127.0.0.1', port: 9000, auth: : { username: 'mikeymike', password: 'rapunz3l' } }, // `cancelToken` 指定用于取消请求的 cancel token cancelToken: new CancelToken(function (cancel) { }) } 并发请求 axios.all([]) axios.spread(callback) //example function getUsers() { return axios.get('/users'); } function getChannels() { return axios.get('/channels'); } axios.all([getUsers(), getChannels()]) .then(axios.spread(function (acct, perms) { // 两个请求现在都执行完成 })); 创建 axios 实例 var axiosInstance = axios.create(options); 使用 axios.create 方法创建的实例，和直接使用 axios 的使用方法是一样的。 ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:1:2","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"响应结构 axios 对服务端的响应进行了封装： { // `data` 服务端返回的响应数据 data: {}, // `status` 服务端响应的 HTTP 状态码 status: 200, // `statusText` 服务端响应的 HTTP 状态信息 statusText: 'OK', // `headers` 服务端响应的头 headers: {}, // `config` 该请求的所有配置选型，一般可以通过这个 config 拿到请求 options 中的一些信息，比如 url,data 等 config: {} } // example 请求成功 axios.get('/users') .then(function(response) { console.log(response.data); console.log(response.status); console.log(response.statusText); console.log(response.headers); console.log(response.config); }); ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:1:3","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"配置默认选项 全局配置默认选项 axios.defaults.baseURL = 'https://demo'; axios.defaults.responseType = 'blob'; 配置实例默认值 var instance = axios.create({ baseURL: 'https://demo' }); instance.defaults.responseType = 'blob'; ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:1:4","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"配置的优先级 前面已经知道，axios 的可以在发送请求时配置 options，创建实例时可以配置 options，还有默认的 options，所以配置的合并有优先级。 lib/defaults.js 库的默认值 -\u003e 实例的 defaults 属性 -\u003e 发送请求的 options 参数 也就是发送请求时的 options 参数会覆盖前两者的 options。 ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:1:5","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"拦截器 拦截器与 transformRequest,transformResponse 函数的作用有些类似，都是在发送请求前，和收到服务端响应后，做一些处理。 // 请求拦截器 axios.interceptors.request.use(function (config) { // 在发送请求之前做些什么 return config; }, function (error) { // 对请求错误做些什么 return Promise.reject(error); }); // 响应拦截器 axios.interceptors.response.use(function (response) { // 对响应数据做点什么 return response; }, function (error) { // 对响应错误做点什么 return Promise.reject(error); }); 一个请求拦截器可以用来添加token的例子： function getToken() { // ... } axios.interceptors.request.use(function (config) { let token = getToken(); if (token) { config.headers['Authorization'] = token; } //处理url //config.url }, function (error) { return Promise.reject(error); }); 移除拦截器 var interceptor = axios.interceptors.request.use(function () {/*...*/}); axios.interceptors.request.eject(interceptor); ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:1:6","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"实现文件下载 let opts = { responseType = 'blob'; transformResponse: [async function (data) { let resBlob = data; let resData = null; try { let resText = await new Promise((resolve, reject) =\u003e { let reader = new FileReader(); reader.addEventListener('abort', reject); reader.addEventListener('error', reject); reader.addEventListener('loadend', () =\u003e { resolve(reader.result); }); reader.readAsText(resBlob); }); resData = JSON.parse(resText) // try to parse as json eventually } catch (err) { // ignore } if (resData) { if (resData.error) { return null; } else { return data; } } else { fileDownload(resBlob, filename); } }] } let fetch = axios.create(opts); fetch.get('http://demo/api/download') .catch(error =\u003e { //todo }) 上面通过 axios blob 实现下载，能够处理 JSON 和 文件流 的通用逻辑，这里设置 responseType 为 blob，所有响应先转换为 blob 数据。 处理响应数据的逻辑也可以放到拦截器里。还可以通过设置 onDownloadProgress 函数实现下载进度条。 ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:2:0","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"实现文件上传 axios 实现文件上传就简单的多： var self = this let file = e.target.file let formData = new FormData() formData.append('file', file, file.name) // 添加请求头 axios({ url: 'http://demo/api/upload', method; 'post', data: formData, headers: {'Content-Type': 'multipart/form-data'} }) .then(response =\u003e { console.log(response.data) }) .catch(error =\u003e { console.error(error) }) ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:3:0","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Node.js"],"content":"参考链接 https://www.kancloud.cn/yunye/axios/234845 https://www.zhihu.com/question/263323250/answer/267842980 ","date":"2018-06-01","objectID":"/posts/2018-06-01-axios-use/:4:0","tags":null,"title":"Axios 使用","uri":"/posts/2018-06-01-axios-use/"},{"categories":["Life"],"content":"今天，5.20，我爱你，我们结婚了。 You are so beautiful in white. （老婆说，我只爱我的代码 。。。） ","date":"2018-05-20","objectID":"/posts/2018-05-20-beautiful-in-white/:0:0","tags":null,"title":"Beautiful in white","uri":"/posts/2018-05-20-beautiful-in-white/"},{"categories":["Others"],"content":"Swagger 是目前最受欢迎的 REST API 文档生成工具之一。 本文只介绍 Koa 与 Swagger 的集成。 ","date":"2018-05-01","objectID":"/posts/2018-05-01-swagger/:0:0","tags":null,"title":"使用 Swagger 生成 API 文档","uri":"/posts/2018-05-01-swagger/"},{"categories":["Others"],"content":"安装依赖 安装 koa2-swagger-ui 。 npm install koa2-swagger-ui --save ","date":"2018-05-01","objectID":"/posts/2018-05-01-swagger/:1:0","tags":null,"title":"使用 Swagger 生成 API 文档","uri":"/posts/2018-05-01-swagger/"},{"categories":["Others"],"content":"配置 关于 Swagger UI 配置参考： Swagger 从入门到精通 swagger-ui ","date":"2018-05-01","objectID":"/posts/2018-05-01-swagger/:2:0","tags":null,"title":"使用 Swagger 生成 API 文档","uri":"/posts/2018-05-01-swagger/"},{"categories":["Others"],"content":"集成 const Koa = require('koa'); const koaSwagger = require('koa2-swagger-ui'); const app = new Koa(); app.use( koaSwagger({ routePrefix: '/swagger', swaggerOptions: { url: 'http://petstore.swagger.io/v2/swagger.json', // example path to json }, }), ); app.listen(5000); OPTIONS routePrefix， 默认是 /docs，访问 Swagger 的 url。 swaggerOptions，Swagger UI 配置选项。 url，指定 Swagger API 的配置。 配置好之后可以直接通过 http://localhost:5000/swagger 访问。 ","date":"2018-05-01","objectID":"/posts/2018-05-01-swagger/:3:0","tags":null,"title":"使用 Swagger 生成 API 文档","uri":"/posts/2018-05-01-swagger/"},{"categories":["Node.js"],"content":"JSDoc 是一个根据 Javascript 文件中的代码注释，生成 API 文档的工具。 ","date":"2018-03-28","objectID":"/posts/2018-03-28-nodejs-jsdoc/:0:0","tags":null,"title":"Node.js 生成 API 文档","uri":"/posts/2018-03-28-nodejs-jsdoc/"},{"categories":["Node.js"],"content":"简单使用 JSDoc 注释放置在方法或函数声明之前，它必须以 / ** 开始，其他以 /*，/*** 或者超过 3 个星号的注释，都将被 JSDoc 解析器忽略。例如一下代码： /** * Student类，学生. * @constructor * @param {string} name - 学生姓名. * @param {string} address - 学生家庭住址. */ function Student(name, address) { this.name = name; this.address = address; } Student.prototype={ /** * 获取学生的住址 * @returns {string|*} */ getAddress: function(){ return this.address; } }; 上面的代码中，以 @ 开头的是 JSDoc 的。因为 JSDoc 考虑向后兼容，所以一些注释标签存在别名。 比如 @param 有两个别名：@arg，@argument。 ","date":"2018-03-28","objectID":"/posts/2018-03-28-nodejs-jsdoc/:1:0","tags":null,"title":"Node.js 生成 API 文档","uri":"/posts/2018-03-28-nodejs-jsdoc/"},{"categories":["Node.js"],"content":"标签 关于标签参考： JSDoc 中文文档 JSDoc 官网 ","date":"2018-03-28","objectID":"/posts/2018-03-28-nodejs-jsdoc/:2:0","tags":null,"title":"Node.js 生成 API 文档","uri":"/posts/2018-03-28-nodejs-jsdoc/"},{"categories":["Node.js"],"content":"生成 Markdown 文档 ","date":"2018-03-28","objectID":"/posts/2018-03-28-nodejs-jsdoc/:3:0","tags":null,"title":"Node.js 生成 API 文档","uri":"/posts/2018-03-28-nodejs-jsdoc/"},{"categories":["Node.js"],"content":"安装依赖 npm install -g jsdoc-to-markdown ","date":"2018-03-28","objectID":"/posts/2018-03-28-nodejs-jsdoc/:3:1","tags":null,"title":"Node.js 生成 API 文档","uri":"/posts/2018-03-28-nodejs-jsdoc/"},{"categories":["Node.js"],"content":"使用 如 docs.sh 文件： PROJECT_ROOT=\"$PWD\" MARKDOWN_DOCS_DIR=\"${PROJECT_ROOT}/docs\" node_modules/.bin/jsdoc2md \\ --files \"lib/**/*.js\" \\ \u003e \"${MARKDOWN_DOCS_DIR}/api_docs.md\" 运行 docs.sh 会在当前目录下的 docs 目录生成 api_docs.md 文件。 查看命令帮助： jsdoc2md --help ","date":"2018-03-28","objectID":"/posts/2018-03-28-nodejs-jsdoc/:3:2","tags":null,"title":"Node.js 生成 API 文档","uri":"/posts/2018-03-28-nodejs-jsdoc/"},{"categories":["Node.js"],"content":"Node.js，实现文件监听，可以使用 fs.watch 和 fs.watchFile 。 也可以通过第三方库 chokidar 来实现。 ","date":"2018-03-20","objectID":"/posts/2018-03-20-nodejs-file-watch/:0:0","tags":null,"title":"Node.js 实现文件监听","uri":"/posts/2018-03-20-nodejs-file-watch/"},{"categories":["Node.js"],"content":"fs.watch 官网例子： fs.watch('somedir', (eventType, filename) =\u003e { console.log(`event type is: ${eventType}`); if (filename) { console.log(`filename provided: ${filename}`); } else { console.log('filename not provided'); } }); fs.watch 的不支持子文件夹的侦听，而且在很多情况下会侦听到两次事件。 ","date":"2018-03-20","objectID":"/posts/2018-03-20-nodejs-file-watch/:1:0","tags":null,"title":"Node.js 实现文件监听","uri":"/posts/2018-03-20-nodejs-file-watch/"},{"categories":["Node.js"],"content":"chokidar 安装什么的就不介绍了，参考 官方文档 。 例子： class ContentPackWatcher { constructor(robot, options = {awaitWriteFinish: true}) { let dirPath = `${process.env.HUBOT_ENTERPRISE_PACKAGES_DIR}/*.zip`; this.watcher = Chokidar.watch(dirPath, options); this.watcher .on('add', this.addFileListener.bind(this)) .on('addDir', this.addDirectoryListener.bind(this)) .on('change', this.fileChangeListener.bind(this)) .on('unlink', this.fileDeleteListener.bind(this)) .on('unlinkDir', this.directoryDeleteListener.bind(this)) .on('error', this.errorListener.bind(this)) .on('ready', this.readyListener.bind(this)); } getWatched() { return this.watcher.getWatched(); } stopWatch(paths) { this.watcher.unwatch(paths); } readyListener() { logger.info('Initial scan complete. Ready for changes.'); } errorListener(error) { logger.error('Error happened', error) } //add new file addFileListener(filePath, stats) { if (stats.size \u003e 0) { logger.info(`File ${filePath} has been added, size: ${stats.size}.`); } } //add new directory addDirectoryListener(dirPath) { logger.info(`Directory ${dirPath} has been added.`); } //watch file change fileChangeListener(filePath, stats) { if (stats.size \u003e 0) { logger.info(`File ${filePath} has been changed, size: ${stats.size}.`); } } //watch file delete fileDeleteListener(filePath) { logger.info(`File ${filePath} has been removed.`); } //watch directory delete directoryDeleteListener(dirPath) { logger.info(`Directory ${dirPath} has been removed.`); } } ","date":"2018-03-20","objectID":"/posts/2018-03-20-nodejs-file-watch/:2:0","tags":null,"title":"Node.js 实现文件监听","uri":"/posts/2018-03-20-nodejs-file-watch/"},{"categories":["Node.js"],"content":"API chokidar.watch(paths, [options]) paths: 可以是一个字符串数组或一个字符串。 options: 对象。 persistent: 默认true，进程是否持续监听文件，如果设置为 false，当使用 fsevents 监听时，ready 之后不会触发任何监听事件。 ignored: 忽略某些文件的监听， ignoreInitial: 默认 false，如果设置为 false,在初始化 chokidar 实例时，如果监听到匹配的文件也会被触发 add/addDir 事件。 followSymlinks: 默认 true，如果设置为 false,只看符号链接本身的变化。 cwd: 监听的路径的 base 目录。 disableGlobbing: 默认 false，如果设置为 true,那么传递给.watch()和add()的字符串被视为文字路径名,即使它们看起来就像 globs。 usePolling: 默认 false，是否使用 fs.watchFile (backed by polling), 或者 fs.watch，如果轮询导致CPU占用过高，可以设置 为 false。它通常需要设置 true 当通过网络监听文件时和非标准的情况下。在 OS X 上设置为 true，会覆盖 useFsEvents，也可以设 置 CHOKIDAR_USEPOLLING 环境变量来覆盖它。 Polling-specific 设置（只在 usePolling: true 是有效） interval:(default: 100) 文件系统轮询时间间隔，也可以通过设置环境变量 CHOKIDAR_INTERVAL 来覆盖它。 binaryInterval:(default: 300) 二进制文件系统轮询时间间隔。 useFsEvents:(default: true on OS X)当 fsevents 的监听接口可用时，是否启用。当显式地设置为 true,fsevents 取代 usePolling。 在 OS X 上设置为 false 时，usePolling: true 变为默认。 alwaysStat: 默认 false，如果 add,addDir，change 事件依赖 fs.Stats 对象（callback的第二个参数），设置为 true 时， 可以确保传入这个对象，尽管它不是可用的。 depth: 默认 undefined，遍历子目录的层级。 awaitWriteFinish: 默认 false，默认情况下，文件第一次出现在磁盘上，文件被写完之前，就会触发 add 事件。此外,在某些情况下会触 发 change 事件，在一些情况下，特别是监听大文件，需要在等待写操作完成以后回复一个文件创建或者修改。设置为 true，会检查文件大小，直到文件在 设置的时间内(stabilityThreshold)不再改变，才会触发 add 或者 change 事件。设置适当的时间依赖系统和硬件。awaitWriteFinish 可以是 一个对象，包含下面的属性: stabilityThreshold: (default: 2000)单位毫秒，等待文件大小不再改变的时间，在设置时间之后触发事件。 pollInterval: (default: 100)，检查文件大小的时间间隔。 ignorePermissionErrors: 默认 false，忽略没有权限操作文件的 error。 ","date":"2018-03-20","objectID":"/posts/2018-03-20-nodejs-file-watch/:3:0","tags":null,"title":"Node.js 实现文件监听","uri":"/posts/2018-03-20-nodejs-file-watch/"},{"categories":["Node.js"],"content":"事件 chokidar 可以通过 on 方法监听到下面的事件： add, 文件添加 addDir, 文件夹添加 change, 文件变化 unlink, 文件删除 unlinkDir, 文件夹删除 ready raw error 除了 ready，raw，error 这三个事件，其他事件触发都可以拿到文件路径。 ","date":"2018-03-20","objectID":"/posts/2018-03-20-nodejs-file-watch/:4:0","tags":null,"title":"Node.js 实现文件监听","uri":"/posts/2018-03-20-nodejs-file-watch/"},{"categories":["Node.js"],"content":"方法 .add(path / paths): 添加监听文件。参数可以是一个字符串数组或一个字符串。 .on(event, callback): 监听事件，除了 ready，raw，error 这三个事件，其他事件的 callback 函数的第一个参数是文件路径。 .unwatch(path / paths): 停止监听某个文件。参数可以是一个字符串数组或一个字符串。 .close(): 删除所有文件监听。 .getWatched(): 返回一个包含所有被监听的文件的对象。 ","date":"2018-03-20","objectID":"/posts/2018-03-20-nodejs-file-watch/:5:0","tags":null,"title":"Node.js 实现文件监听","uri":"/posts/2018-03-20-nodejs-file-watch/"},{"categories":["Node.js"],"content":"exports 变量是在模块的文件级别作用域内有效的，它在模块被执行前被赋予 module.exports。 我们通过一个依赖循环的例子来理解 exports 和 module.exports 的区别。 ","date":"2018-03-17","objectID":"/posts/2018-03-17-nodejs-exports-moduleexports/:0:0","tags":null,"title":"关于 exports 和 module.exports","uri":"/posts/2018-03-17-nodejs-exports-moduleexports/"},{"categories":["Node.js"],"content":"依赖循环 如下面官网的例子: 文件 a.js: console.log('a 开始'); exports.done = false; const b = require('./b.js'); console.log('在 a 中，b.done = %j', b.done); exports.done = true; console.log('a 结束'); 文件 b.js: console.log('b 开始'); exports.done = false; const a = require('./a.js'); console.log('在 b 中，a.done = %j', a.done); exports.done = true; console.log('b 结束'); main.js： console.log('main 开始'); const a = require('./a.js'); const b = require('./b.js'); console.log('在 main 中，a.done=%j，b.done=%j', a.done, b.done); 运行结果： main 开始 a 开始 b 开始 在 b 中，a.done = false b 结束 在 a 中，b.done = true a 结束 在 main 中，a.done=true，b.done=true 当 main.js 加载 a.js 时，a.js 又加载 b.js。 此时，b.js 会尝试去加载 a.js。 为了防止无限的循环，会返回一个a.js 的 exports 对象的 未完成的副本({done: false}) 给 b.js 模块。 然后 b.js 完成加载，并将 exports 对象提供给 a.js 模块。当 main.js 加载这两个模块时，它们都已经完成加载。所以输 出：在 main 中，a.done=true，b.done=true。 ","date":"2018-03-17","objectID":"/posts/2018-03-17-nodejs-exports-moduleexports/:1:0","tags":null,"title":"关于 exports 和 module.exports","uri":"/posts/2018-03-17-nodejs-exports-moduleexports/"},{"categories":["Node.js"],"content":"exports 和 module.exports 的区别 exports 是 module.exports 的引用 module.exports 初始值为一个空对象 {}，所以 exports 初始值也是 {} require() 返回的是 module.exports 而不是 exports module.exports.foo = ... 可以写成 exports.foo = ...。 注意，如果一个新的 objetc 被赋值给 exports，它就不再绑定 到 module.exports： module.exports.done = true; // 从对模块的引用中导出 exports = { done: false }; // 不导出，只在模块内有效 当 module.exports 属性被一个新的对象完全替代时，也会重新赋值 exports，例如： module.exports = exports = function hello() { //TODO }; 把依赖循环的例子中的 a.js 稍作修改如下: console.log('a 开始'); module.exports = { done: false }; const b = require('./b.js'); console.log('在 a 中，b.done = %j', b.done); exports.done = true; console.log('a 结束'); 运行结果： main 开始 a 开始 b 开始 在 b 中，a.done = false b 结束 在 a 中，b.done = true a 结束 在 main 中，a.done=false，b.done=true 所以说 require() 返回的是 module.exports 而不是 exports。 再修改文件 a.js 如下: console.log('a 开始'); const b = require('./b.js'); console.log('在 a 中，b.done = %j', b.done); exports.done = true; console.log('a 结束'); 运行结果： main 开始 a 开始 b 开始 在 b 中，a.done = undefined b 结束 在 a 中，b.done = true a 结束 在 main 中，a.done=true，b.done=true 我们看到 在 b 中，a.done = undefined，这是因为 b.js 尝试加载 a.js 时，这是 a.js 的 module.exports 对象是 {}。 ","date":"2018-03-17","objectID":"/posts/2018-03-17-nodejs-exports-moduleexports/:2:0","tags":null,"title":"关于 exports 和 module.exports","uri":"/posts/2018-03-17-nodejs-exports-moduleexports/"},{"categories":["Node.js"],"content":"require 方法的的实现 通过下面 require() 方法实现的伪代码，更容易理解： function require(/* ... */) { const module = { exports: {} }; ((module, exports) =\u003e { // 模块代码在这。在这个例子中，定义了一个函数。 function someFunc() {} exports = someFunc; // 此时，exports 不再是一个 module.exports 的快捷方式， // 且这个模块依然导出一个空的默认对象。 module.exports = someFunc; // 此时，该模块导出 someFunc，而不是默认对象。 })(module, module.exports); return module.exports; } 参考文章 Node.js 中文文档 ","date":"2018-03-17","objectID":"/posts/2018-03-17-nodejs-exports-moduleexports/:3:0","tags":null,"title":"关于 exports 和 module.exports","uri":"/posts/2018-03-17-nodejs-exports-moduleexports/"},{"categories":["Node.js"],"content":"Node 中的异常处理是一个应该注意的点。 ","date":"2018-03-07","objectID":"/posts/2018-03-07-nodejs-exception-catch/:0:0","tags":null,"title":"Node.js 中的异常处理","uri":"/posts/2018-03-07-nodejs-exception-catch/"},{"categories":["Node.js"],"content":"try/catch 通常我们在代码中捕获异常，会用下面的方式： try { //process } catch (e) { errorHandler(e) } 但是在 Node 中，这种方式对于处理异步编程并不一定适用，例如： function asyncFunc (callback) { process.nextTick(callback); } try { asyncFunc(callback); } catch (e) { errorHandler(e) } 上面的代码中，调用 asyncFunc(callback)，callback 在下一个事件循环才会执行，但是 try/catch 只能捕获当前事件循环内的异常， 所以当 callback 执行时抛出的异常将无法捕获。 ","date":"2018-03-07","objectID":"/posts/2018-03-07-nodejs-exception-catch/:1:0","tags":null,"title":"Node.js 中的异常处理","uri":"/posts/2018-03-07-nodejs-exception-catch/"},{"categories":["Node.js"],"content":"不要对回调函数进行异常捕获 如下下面的写法： try { process(); callback(null, result); } catch (e) { callback(e, result); } 上面的代码中，不仅会捕获 process() 中的异常，callback() 中的异常一样会捕获，所以如果 callback() 执行抛出异常，catch() 代码块一样 会捕获，这样的话 callback() 将会执行两次，正确的写法应该是： try { process(); } catch (e) { return callback(e, result); } callback(null, result); ","date":"2018-03-07","objectID":"/posts/2018-03-07-nodejs-exception-catch/:2:0","tags":null,"title":"Node.js 中的异常处理","uri":"/posts/2018-03-07-nodejs-exception-catch/"},{"categories":["Node.js"],"content":"处理异常的常规写法 通常回调函数的第一个参数是异常，如果第一个参数为空，则表示没有异常。 ","date":"2018-03-07","objectID":"/posts/2018-03-07-nodejs-exception-catch/:3:0","tags":null,"title":"Node.js 中的异常处理","uri":"/posts/2018-03-07-nodejs-exception-catch/"},{"categories":["Node.js"],"content":"Node.js 提供了四个定时器，分别是：setTimeout()，setInterval()，setImmediate()，process.nextTick()。 它们的用法都差不多，但是在一些特殊情况下很难区分。如下面的例子： // test.js setTimeout(() =\u003e console.log(1)); setImmediate(() =\u003e console.log(2)); process.nextTick(() =\u003e console.log(3)); Promise.resolve().then(() =\u003e console.log(4)); (() =\u003e console.log(5))(); 输出结果是： $ node test.js 5 3 4 1 2 这是为什么？ (() =\u003e console.log(5))(); 这行是同步任务，所以最先输出。 异步任务可以分成两种。 追加在本轮循环的异步任务 追加在次轮循环的异步任务 所谓\"循环\"，指的是事件循环（event loop）。这是 JavaScript 引擎处理异步任务的方式，后文会详细解释。这里只要理解，本轮循环一定早于次轮循环 执行即可。 Node 规定，process.nextTick 和 Promise 的回调函数，追加在本轮循环，即同步任务一旦执行完成，就开始执行它们。 而 setTimeout、setInterval、setImmediate 的回调函数，追加在次轮循环。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:0:0","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"process.nextTick() process.nextTick 这个名字有点误导，它是在本轮循环执行的，而且是所有异步任务里面最快执行的。 Node 执行完所有同步任务，接下来就会执行 process.nextTick 的任务队列。所以，第二个输出结果是 3。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:1:0","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"微任务 Promise 对象的回调函数，会进入异步任务里面的\"微任务\"（microtask）队列。 微任务队列追加在 process.nextTick 队列的后面，也属于本轮循环。所以，下面的代码总是先输出 3，再输出 4。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:2:0","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"事件循环的概念 下面开始介绍次轮循环的执行顺序，这就必须理解什么是事件循环（event loop）了。 Node 的 官方文档 是这样介绍的。 “When Node.js starts, it initializes the event loop, processes the provided input script which may make async API calls, schedule timers, or call process.nextTick(), then begins processing the event loop.” 这段话很重要，它表达了三层意思。 首先，Node 只有一个主线程，事件循环是在主线程上完成的。 其次，Node 开始执行脚本时，会先进行事件循环的初始化，但是这时事件循环还没有开始，会先完成下面的事情。 同步任务 发出异步请求 规划定时器生效的时间 执行 process.nextTick() 等等 最后，上面这些事情都干完了，事件循环就正式开始了。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:3:0","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"事件循环的六个阶段 事件循环会无限次地执行，一轮又一轮。只有异步任务的回调函数队列清空了，才会停止执行。 每一轮的事件循环，分成六个阶段。这些阶段会依次执行。 timers I/O callbacks idle, prepare poll check close callbacks 每个阶段都有一个先进先出的回调函数队列。只有一个阶段的回调函数队列清空了，该执行的回调函数都执行了，事件循环才会进入下一个阶段。 下面简单介绍一下每个阶段的含义，详细介绍可以看 官方文档 ， 也可以参考 libuv 的源码解读 。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:4:0","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"timers 这个是定时器阶段，处理 setTimeout() 和 setInterval() 的回调函数。进入这个阶段后，主线程会检查一下当前时间，是否满足定时器的条件。如 果满足就执行回调函数，否则就离开这个阶段。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:4:1","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"I/O callbacks 除了以下操作的回调函数，其他的回调函数都在这个阶段执行。 setTimeout() 和 setInterval() 的回调函数 setImmediate() 的回调函数 用于关闭请求的回调函数，比如 socket.on('close', ...) ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:4:2","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"idle, prepare 该阶段只供 libuv 内部调用，这里可以忽略。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:4:3","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"Poll 这个阶段是轮询时间，用于等待还未返回的 I/O 事件，比如服务器的回应、用户移动鼠标等等。 这个阶段的时间会比较长。如果没有其他异步任务要处理（比如到期的定时器），会一直停留在这个阶段，等待 I/O 请求返回结果。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:4:4","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"check 该阶段执行 setImmediate() 的回调函数。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:4:5","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"close callbacks 该阶段执行关闭请求的回调函数，比如 socket.on('close', ...)。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:4:6","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"事件循环的示例 下面是来自官方文档的一个示例。 const fs = require('fs'); const timeoutScheduled = Date.now(); // 异步任务一：100ms 后执行的定时器 setTimeout(() =\u003e { const delay = Date.now() - timeoutScheduled; console.log(`${delay}ms`); }, 100); // 异步任务二：文件读取后，有一个 200ms 的回调函数 fs.readFile('test.js', () =\u003e { const startCallback = Date.now(); while (Date.now() - startCallback \u003c 200) { // 什么也不做 } }); 上面代码有两个异步任务，一个是 100ms 后执行的定时器，一个是文件读取，它的回调函数需要 200ms。请问运行结果是什么？ 脚本进入第一轮事件循环以后，没有到期的定时器，也没有已经可以执行的 I/O 回调函数，所以会进入 Poll 阶段，等待内核返回文件读取的结果。 由于读取小文件一般不会超过 100ms，所以在定时器到期之前，Poll 阶段就会得到结果，因此就会继续往下执行。 第二轮事件循环，依然没有到期的定时器，但是已经有了可以执行的 I/O 回调函数，所以会进入 I/O callbacks 阶段，执行 fs.readFile 的回调函数。 这个回调函数需要 200ms，也就是说，在它执行到一半的时候，100ms 的定时器就会到期。但是，必须等到这个回调函数执行完，才会离开这个阶段。 第三轮事件循环，已经有了到期的定时器，所以会在 timers 阶段执行定时器。最后输出结果大概是 200 多毫秒。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:5:0","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"setTimeout 和 setImmediate 由于 setTimeout 在 timers 阶段执行，而 setImmediate 在 check 阶段执行。所以，setTimeout 会先于 setImmediate 执行。 setTimeout(() =\u003e console.log(1)); setImmediate(() =\u003e console.log(2)); 上面代码应该先输出 1，再输出 2，但是实际执行的时候，结果却是不确定，有时还会先输出 2，再输出 1。 这是因为 setTimeout 的第二个参数默认为 0。但是实际上，Node 做不到 0 毫秒，最少也需要 1 毫秒，根据官方文档，第二个参数的取值范围在 1 毫秒 到 2147483647 毫秒之间。也就是说，setTimeout(f, 0) 等同于 setTimeout(f, 1)。 实际执行的时候，进入事件循环以后，有可能到了 1 毫秒，也可能还没到 1 毫秒，取决于系统当时的状况。如果没到 1 毫秒，那么 timers 阶段就会跳过， 进入 check 阶段，先执行 setImmediate 的回调函数。 但是，下面的代码一定是先输出 2，再输出 1。 const fs = require('fs'); fs.readFile('test.js', () =\u003e { setTimeout(() =\u003e console.log(1)); setImmediate(() =\u003e console.log(2)); }); 上面代码会先进入 I/O callbacks 阶段，然后是 check 阶段，最后才是 timers 阶段。因此，setImmediate 才会早于 setTimeout 执行。 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:6:0","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Node.js"],"content":"async 函数和 promise async function async1() { console.log(\"async1 start\"); await async2(); console.log(\"async1 end\"); } async function async2() { console.log( 'async2 end'); } console.log(\"script start\"); setTimeout(function () { console.log(\"settimeout\"); }, 0); async1(); new Promise(function (resolve) { console.log(\"promise1\"); resolve(); }).then(function () { console.log(\"promise2\"); }); console.log('script end'); 上面代码的执行结果是： script start async1 start async2 end promise1 script end promise2 async1 end settimeout 为什么 async2 会在 promise1 之前输出？ 先简单了解一下 async/await 的机制。 async 其实就是将 Generator 函数和自动执行器，包装在一个函数里。关于 Generator 函数，可以参考 这里 。 async function fn(args) { // ... } // 等同于 function fn(args) { return spawn(function* () { // ... }); } function spawn(genF) { return new Promise(function(resolve, reject) { const gen = genF(); function step(nextF) { let next; try { next = nextF(); } catch(e) { return reject(e); } if(next.done) { return resolve(next.value); } Promise.resolve(next.value).then(function(v) { step(function() { return gen.next(v); }); }, function(e) { step(function() { return gen.throw(e); }); }); } step(function() { return gen.next(undefined); }); }); } spawn 函数就是自动执行器。 async 函数返回了一个 Promise 作为结果的函数，可以简单理解为，await 后面的函数执行完毕时，await 会产生一个微任务（Promise.then）。 注意，这个微任务实在执行完 await 之后产生的，也就是说 async 函数在执行时，如果碰到 await，就会跳出当前 async 函数，执行其他代码， 执行完其他代码后，再回到 async 函数，执行剩下的代码，并把 await 后面的代码，添加到微任务队列。 上面的例子，执行过程应该是： 执行同步代码，输出 script start。 遇到 setTimeout，添加到宏任务队列。 执行 async1()，输出 async1 start。 async1() 函数里调用了 async2()，执行 async2() 中的代码，输出 async2 end。跳出 async1() 函数。 创建 promise 对象里面的代码属于同步代码，所以接下来输出 promise1。遇到 then，产生第一个微任务，添加到微任务队列。 执行同步代码，输出 script end。 执行产生的微任务，输出 promise2 回到 async1() 函数，执行 await，产生一个新的 promise，添加到微任务队列。 执行 await 后面的代码，输出 async1 end 最后，没有 process.nextTick，进入事件循环的 timers 阶段，实行 setTimeout 的回调函数，输出 settimeout。 原文出自 Node 定时器详解 ","date":"2018-02-11","objectID":"/posts/2018-02-11-nodejs-settimeout-nexttick/:7:0","tags":null,"title":"Node.js 定时器与事件循环","uri":"/posts/2018-02-11-nodejs-settimeout-nexttick/"},{"categories":["Linux"],"content":"记录常用的 Vim 快捷键。 Vim 官网：http://www.vim.org/ ","date":"2018-01-08","objectID":"/posts/2018-01-08-vim-usage/:0:0","tags":null,"title":"Vim 快捷键","uri":"/posts/2018-01-08-vim-usage/"},{"categories":["Linux"],"content":"常用快捷键 使用 Vim 应该注意的几点： 区分字母大小写 含有 Ctrl 字眼都表示 Ctrl 键盘按钮 移动 k，上 j，下 h，左 l，右 v，按 v 之后按方向键可以选中你要选中的文字 gg，跳到第 1 行 G，跳到第最后行 16G 或 :16，跳到第 16 行 $，到本行 行尾 0，到本行 行头 w，到下一个单词的 开头 e，到下一个单词的 结尾 Ctrl + u，向 上翻 半屏 Ctrl + d，向 下翻 半屏 Ctrl + f，向 下翻 一屏 Ctrl + b，向 上翻 一屏 * 或 n，匹配光标当前所在的单词，移动光标到 下一个 匹配单词 #，匹配光标当前所在的单词，移动光标到 上一个 匹配单词 %，匹配括号移动，包括 (、{、[ 插入 I，在当前 行首 插入 A，在当前 行尾 插入 i，在当前字符的 左边 插入 a，在当前字符的 右边 插入 o，在当前行 下面 插入一个新行 O，在当前行 上面 插入一个新行 编辑 删除 x，删除 光标后 的 1 个字符 2x，删除 光标后 的 2 个字符 X，删除 光标前 的 1 个字符 2X，删除 光标前 的 2 个字符 dd，删除当前行 cc，删除当前行后进入 insert 模式 dw，删除当前光标下的单词/空格 d$，删除光标至 行尾 所有字符 dG，删除光标至 文件尾 所有字符 3dd，从当前光标开始，删掉 3 行 复制 y，复制光标所选字符 yw，复制光标后单词 yy，复制当前行 4yy，复制当前行及下面 4 行 y$，复制光标位置至 行尾 的内容 y^，复制光标位置至 行首 的内容 粘贴 p，将粘贴板中内容复制到 光标之后 P（注意是大写），将粘贴板中内容复制到 光标之前 其他 ddp，交换当前光标所在行和下一行的位置 u，撤销 :wq，退出并 保存 :q!，退出并 不保存 Ctrl + v，进入 Vim 列编辑 guu，把当前行的字母全部转换成 小写 gUU，把当前行的字母全部转换成 大写 g~~，把当前行的字母是大写的转换成小写，是小写的转换成大写 :saveas /opt/setups/text.txt，另存到 /opt/setups/text.txt 搜索 /hello，从光标开始处向文件尾搜索 hello 字符，按 n 继续向下找，按 N 继续向上找 ?hello，从光标开始处向文件首搜索 hello 字符，按 n 继续向下找，按 N 继续向上找 替换 :%s/hello/hi/g，把文件中所有 hello 替换为：hi :%s/hello/hi/，把文件中所有行中第一个 hello 替换为：hi :s/hello/hi/，把光标当前行第一个 hello 替换为 hi :s/hello/hi/g，把光标当前行所有 hello 替换为 hi :s#hello/#hi/#，除了使用斜杠作为分隔符之外，还可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符，该命令表示：把光标当 前行第一个 hello/ 替换为 hi/ :10,31s/hello/hig，把第 10 行到 31 行之间所有 hello 替换为 hi 显示行号 set number或者set nu ","date":"2018-01-08","objectID":"/posts/2018-01-08-vim-usage/:1:0","tags":null,"title":"Vim 快捷键","uri":"/posts/2018-01-08-vim-usage/"},{"categories":["Linux"],"content":"特殊的复制、黏贴 Vim 提供了 12 个剪贴板，分别是：0,1,2,3,4,5,6,7,8,9,a,\"，默认采用的是 \"，也就是双引号。 复制到某个剪切板的命令：\"3y，表示使用 3 号剪切板。 黏贴某个剪切板内容：\"3p，表示使用 3 号剪切板内容进行黏贴 ","date":"2018-01-08","objectID":"/posts/2018-01-08-vim-usage/:2:0","tags":null,"title":"Vim 快捷键","uri":"/posts/2018-01-08-vim-usage/"},{"categories":["Linux"],"content":"配置 ","date":"2018-01-08","objectID":"/posts/2018-01-08-vim-usage/:3:0","tags":null,"title":"Vim 快捷键","uri":"/posts/2018-01-08-vim-usage/"},{"categories":["Linux"],"content":"备份老的 Vim 配置文件 cp ~/.vimrc ~/.vimrc_bak ","date":"2018-01-08","objectID":"/posts/2018-01-08-vim-usage/:3:1","tags":null,"title":"Vim 快捷键","uri":"/posts/2018-01-08-vim-usage/"},{"categories":["Linux"],"content":"下载 下载 vim-for-server curl https://raw.githubusercontent.com/wklken/vim-for-server/master/vimrc \u003e ~/.vimrc 或者通过 git clone git clone https://github.com/wklken/vim-for-server.git ln -s vim-for-server/vimrc ~/.vimrc ","date":"2018-01-08","objectID":"/posts/2018-01-08-vim-usage/:3:2","tags":null,"title":"Vim 快捷键","uri":"/posts/2018-01-08-vim-usage/"},{"categories":["Linux"],"content":"jq 是一个很好用的处理 json 的工具，可以使用它直接在命令行下对 json 进行操作，分片、过滤、映射和转换。 ","date":"2017-11-22","objectID":"/posts/2017-11-22-linux-json-parse/:0:0","tags":null,"title":"Linux jq 使用","uri":"/posts/2017-11-22-linux-json-parse/"},{"categories":["Linux"],"content":"安装 # ubuntu安装 apt-get update apt-get install jq # 编译安装 git clone https://github.com/stedolan/jq.git cd jq autoreconf -i ./configure --disable-maintainer-mode make sudo make install ","date":"2017-11-22","objectID":"/posts/2017-11-22-linux-json-parse/:1:0","tags":null,"title":"Linux jq 使用","uri":"/posts/2017-11-22-linux-json-parse/"},{"categories":["Linux"],"content":"简单使用 ","date":"2017-11-22","objectID":"/posts/2017-11-22-linux-json-parse/:2:0","tags":null,"title":"Linux jq 使用","uri":"/posts/2017-11-22-linux-json-parse/"},{"categories":["Linux"],"content":"格式化输出 如 test.json 文件的内容： [{\"name\":\"xiaoming\",\"age\":\"18\",\"address\":{\"city\":\"上海\",\"country\":\"中国\"},\"contacts\":[{\"phone\":\"132156465\"}]}] 格式化输出： cat test.json | jq '.' # 或者 jq '.' test.json 输出： [ { \"name\":\"xiaoming\", \"age\":\"18\", \"address\":{ \"city\":\"上海\", \"country\":\"中国\" }, \"contacts\": [ { \"phone\":\"132156465\" } ] } ] ","date":"2017-11-22","objectID":"/posts/2017-11-22-linux-json-parse/:2:1","tags":null,"title":"Linux jq 使用","uri":"/posts/2017-11-22-linux-json-parse/"},{"categories":["Linux"],"content":"访问 json 对象的属性 访问元素的操作: .\u003cattributename\u003e 和 .[index]。 jq 支持管道 |，它如同 linux 命令中的管道线——把前面命令的输出当作是后面命令的输入。 如下命令把 .[0] 作为 {...} 的输入，进而访问嵌套的属性，如 .name 和 .address.city。 cat test.json | jq '.[0] | {name:.name,city:.address.city}' # 输出： { \"name\": \"xiaoming\", \"city\": \"上海\" } cat test.json | jq '.[0] | {phone:.contacts[0].phone,city:.address.city}' #输出： { \"phone\": \"132156465\", \"city\": \"上海\" } ","date":"2017-11-22","objectID":"/posts/2017-11-22-linux-json-parse/:2:2","tags":null,"title":"Linux jq 使用","uri":"/posts/2017-11-22-linux-json-parse/"},{"categories":["Linux"],"content":"修改 json # 修改属性的值，重定向到新的文件 MM_FILE=info.json MM_AGE=18 get_name() { return 'xiaoming' } jq '.people.address = \"shanghai\"' $MM_FILE \u003e $MM_FILE.tmp jq '.people.name = \"'$(get_name)'\"' $MM_FILE \u003e $MM_FILE.tmp jq '.people.age = \"'${MM_AGE}'\"' $MM_FILE \u003e $MM_FILE.tmp # 输出数组，输出加上`[]` cat test.json | jq '[.[0] | {name:.name,city:.address.city}]' # 输出： [ { \"name\": \"xiaoming\", \"city\": \"上海\" } ] # 添加属性 cat test.json | jq '[.[0] | {name_cp:.name,city_cp:.address.city}]' # 输出： [ { \"name_cp\": \"xiaoming\", \"city_cp\": \"上海\" } ] ","date":"2017-11-22","objectID":"/posts/2017-11-22-linux-json-parse/:2:3","tags":null,"title":"Linux jq 使用","uri":"/posts/2017-11-22-linux-json-parse/"},{"categories":["Linux"],"content":"参考资料 官方文档 ","date":"2017-11-22","objectID":"/posts/2017-11-22-linux-json-parse/:3:0","tags":null,"title":"Linux jq 使用","uri":"/posts/2017-11-22-linux-json-parse/"},{"categories":["Javascript"],"content":"ESLint 是 JavaScript 的代码检查工具，使用它可以避免低级错误和统一代码的风格。ESlint 被设计为是完全可配置的，这意味着你可以关闭每一个规则，只 运行基本语法验证，或混合和匹配绑定的规则和自定义规则，以让 ESLint 更适合于你的项目。 ESLint 中文文档 。 ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:0:0","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"使用 ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:1:0","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"安装 npm install -g eslint # 生成配置文件 eslint --init eslint --init 适用于对某个项目进行设置和配置 ESLint，并在其运行的的目录执行本地安装的 ESLint 及 插件。如果你倾向于使用全局安装的 ESLint， 你配置中使用的任何插件也必须是全局安装的。运行 eslint --init 之后，.eslintrc 文件会在你的文件夹中自动创建。 ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:1:1","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"配置 ESlint 配置 ESlint 有种方式，常用的两种方式： 添加 .eslintrc.json 文件，放在项目根目录，也可以是 .eslintrc.yml，.eslintrc.js，.eslintrc。 在 package.json 文件中添加 eslintConfig 属性，所有的配置包含在此属性中。 优先级顺序：.eslintrc.js \u003e .eslintrc.yaml \u003e .eslintrc.yml \u003e .eslintrc.json \u003e .eslintrc \u003e package.json。 ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:1:2","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"配置规则 ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:2:0","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"配置环境 \"env\": { \"es6\": true, \"browser\": true, \"node\": true, \"mocha\": true }, ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:2:1","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"配置全局变量 \"globals\": { \"var1\": true, \"var2\": true, \"var3\": false }, true 代表允许重写、false 代表不允许重写。 ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:2:2","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"配置 Rules 规则的等级有三种： off 或者 0：关闭规则。 warn 或者 1：打开规则，并且作为一个警告（不影响 exit code）。 error 或者 2：打开规则，并且作为一个错误（exit code 将会是 1）。 例如： \"rules\": { \"eqeqeq\": \"off\", \"curly\": \"off\" }, 所有的规则默认都是禁用的。在配置文件中，使用 \"extends\": \"eslint:recommended\" 将会默认开启所有在 ESLint规则页面 被标记为 绿色对钩图标 的规则。 在 ESLint规则页面 ，规则的旁边带有一个橙色扳手图标，表示在执行 eslint 命令时指定 --fix 参数可以 自动修复该问题。 可以在 npm 搜索 “eslint-config” 使用别人创建好的配置。只有在你的配置文件中扩展了一个可分享的配置或者明确开启一个规则，ESLint 才会去校验你的代码。 ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:2:3","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"高级配置 ESLint 允许你指定你想要支持的 JavaScript 语言选项。默认情况下，ESLint 支持 ECMAScript 5 语法。可以覆盖该设置启用对 ECMAScript 其它版本和 JSX 的支持。 请注意，对 JSX 语法的支持不用于对 React 的支持。React 适用于特定 ESLint 无法识别的 JSX 语法。如果你正在使用 React 和 想要 React 语义，推 荐用 eslint-plugin-react 。 同样的，支持 ES6 语法并不意味着支持新的 ESLint 全局变量或类型（如，新类型比如 Set）。对于 ES6 语法，使 用 { \"parserOptions\": { \"ecmaVersion\": 6 } }；对于新的 ES6 全局变量，使用 { \"env\":{ \"es6\": true } }(这个设置会自动启用 ES6 语法)。 在 .eslintrc.* 文件使用 parserOptions 属性设置解析器选项。可用的选项有： ecmaVersion - 设置为 3， 5 (默认)， 6、7 或 8 指定你想要使用的 ECMAScript 版本。你也可以指定为 2015（同 6），2016（同 7），或 2017（同 8）使用年份命名 ourceType - 设置为 “script” (默认) 或 “module”（如果你的代码是 ECMAScript 模块)。 ecmaFeatures - 这是个对象，表示你想使用的额外的语言特性: globalReturn - 允许在全局作用域下使用 return 语句 impliedStrict - 启用全局 strict mode (如果 ecmaVersion 是 5 或更高) jsx - 启用 JSX experimentalObjectRestSpread- 启用对实验性的 object rest/spread properties 的支持。(重要：这是一个实验性的功能,在未来可 能会改变明显。 建议你写的规则 不要依赖该功能，除非当它发生改变时你愿意承担维护成本。) 更多详细配置 Configuring ESLint ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:3:0","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"集成 webstrom 打开 webstorm，选择 File | Settings | Languages \u0026 Frameworks | JavaScript | Code Quality Tools | ESLint 勾选 Enable 。 webstorm 可以自动提示 eslint 指出的代码问题。 ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:4:0","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"使用现有的通用规则 eslint 官方提供了 3 种预安装包： ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:5:0","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"eslint-config-google Google 标准 执行安装： npm install eslint eslint-config-google -g ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:5:1","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"eslint-config-airbnb Airbnb 标准,它依赖 eslint, eslint-plugin-import, eslint-plugin-react, and eslint-plugin-jsx-a11y 等插件，并且 对各个插件的版本有所要求。 你可以执行以下命令查看所依赖的各个版本： npm info \"eslint-config-airbnb@latest\" peerDependencies 你会看到以下输出信息，包含每个了每个 plugins 的版本要求 { eslint: '^3.15.0', 'eslint-plugin-jsx-a11y': '^3.0.2 || ^4.0.0', 'eslint-plugin-import': '^2.2.0', 'eslint-plugin-react': '^6.9.0' } 知道了每个 plugins 的版本要求后，代入以下命令执行安装即可使用： npm install eslint-config-airbnb eslint@^#.#.# eslint-plugin-jsx-a11y@^#.#.# eslint-plugin-import@^#.#.# eslint-plugin-react@^#.#.# -g ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:5:2","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Javascript"],"content":"eslint-config-standard Standard 标准，它是一些前端工程师自定的标准。 执行安装： npm install eslint-config-standard eslint-plugin-standard eslint-plugin-promise -g 目前来看，公认的最好的标准是 Airbnb 标准。建议全局安装这些标准，然后在你的 .eslintrc 配置文件中直接使用： { \"extends\": \"google\" //\"extends\": \"airbnb\" //\"extends\": \"standard\" } ","date":"2017-10-03","objectID":"/posts/2017-10-13-eslint-introduction/:5:3","tags":null,"title":"ESlint 入门","uri":"/posts/2017-10-13-eslint-introduction/"},{"categories":["Linux"],"content":"在 CentOS 7 上通过 yum 安装 docker。 ","date":"2017-09-27","objectID":"/posts/2017-09-27-yum-install-docker/:0:0","tags":null,"title":"CentOs 安装 Docker","uri":"/posts/2017-09-27-yum-install-docker/"},{"categories":["Linux"],"content":"配置 yum 代理 因为我安装 docker 的服务器在公司内网，所以要配置代理，如果不是请忽略。 export http_proxy=\u003chttp proxy endpoint\u003e export https_proxy=$http_proxy export HTTP_PROXY=$http_proxy export HTTPS_PROXY=$http_proxy export no_proxy=127.0.0.1,localhost export NO_PROXY=$no_proxy vim /etc/yum.conf # 添加行 proxy=http://web-proxy.com:8080 ","date":"2017-09-27","objectID":"/posts/2017-09-27-yum-install-docker/:1:0","tags":null,"title":"CentOs 安装 Docker","uri":"/posts/2017-09-27-yum-install-docker/"},{"categories":["Linux"],"content":"卸载旧版本 旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本： $ sudo yum remove docker \\ docker-common \\ docker-selinux \\ docker-engine ","date":"2017-09-27","objectID":"/posts/2017-09-27-yum-install-docker/:2:0","tags":null,"title":"CentOs 安装 Docker","uri":"/posts/2017-09-27-yum-install-docker/"},{"categories":["Linux"],"content":"安装依赖包 $ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 ","date":"2017-09-27","objectID":"/posts/2017-09-27-yum-install-docker/:3:0","tags":null,"title":"CentOs 安装 Docker","uri":"/posts/2017-09-27-yum-install-docker/"},{"categories":["Linux"],"content":"添加 yum 软件源 这里使用官方源： $ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 如果使用国内网络，建议使用国内源： $ sudo yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 如果需要最新版本的 Docker CE 使用以下命令: sudo yum-config-manager --enable docker-ce-edge sudo yum-config-manager --enable docker-ce-test ","date":"2017-09-27","objectID":"/posts/2017-09-27-yum-install-docker/:4:0","tags":null,"title":"CentOs 安装 Docker","uri":"/posts/2017-09-27-yum-install-docker/"},{"categories":["Linux"],"content":"安装 Docker CE # 更新 yum 软件源缓存 $ sudo yum makecache fast # 安装 docker-ce $ sudo yum install docker-ce ","date":"2017-09-27","objectID":"/posts/2017-09-27-yum-install-docker/:5:0","tags":null,"title":"CentOs 安装 Docker","uri":"/posts/2017-09-27-yum-install-docker/"},{"categories":["Linux"],"content":"启动 Docker CE sudo systemctl enable docker sudo systemctl start docker ","date":"2017-09-27","objectID":"/posts/2017-09-27-yum-install-docker/:6:0","tags":null,"title":"CentOs 安装 Docker","uri":"/posts/2017-09-27-yum-install-docker/"},{"categories":["Linux"],"content":"添加 docker 代理 为 docker 配置代理： mkdir /etc/systemd/system/docker.service.d vim /etc/systemd/system/docker.service.d/http-proxy.conf # 添加下面的内容 [Service] Environment=\"HTTP_PROXY={http proxy endpoint}\" \"NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com\" # 重新载入 systemd，扫描新的或有变动的单元 systemctl daemon-reload # 查看环境变量属性 systemctl show --property=Environment docker # 重启 docker 服务 systemctl restart docker 官方代配置文档： Configure and troubleshoot the Docker daemon Control Docker with systemd 如果没有代理，由于国内网络的问题，拉取 Docker 镜像会十分缓慢，建议配置国内镜像加速，然后在 /etc/docker/daemon.json （如果文件不存在请新 建该文件）中配置： { \"registry-mirrors\": [ \"https://********.mirror.aliyuncs.com\", ] } 之后重新启动服务。 sudo systemctl daemon-reload sudo systemctl restart docker ","date":"2017-09-27","objectID":"/posts/2017-09-27-yum-install-docker/:7:0","tags":null,"title":"CentOs 安装 Docker","uri":"/posts/2017-09-27-yum-install-docker/"},{"categories":["Linux"],"content":"错误：docker-runc did not terminate sucessfully unknown 系统版本不支持。 https://github.com/moby/moby/issues/35906 Docker 官方 CentOS 安装文档 ","date":"2017-09-27","objectID":"/posts/2017-09-27-yum-install-docker/:8:0","tags":null,"title":"CentOs 安装 Docker","uri":"/posts/2017-09-27-yum-install-docker/"},{"categories":["Node.js"],"content":"Yarn 是 Facebook 最新的包管理器。Yarn 的使用方式跟 npm 类似，但命令上还是有所区别。 Yarn 官网：https://yarnpkg.com/zh-Hans/ ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:0:0","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"安装 参考 Yarn 官方安装文档 。 ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:1:0","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"源码安装 下载源码 。 wget https://github.com/yarnpkg/yarn/releases/download/v1.9.4/yarn-v1.9.4.tar.gz mkdir /usr/local/yarn/ mv ./yarn-v1.9.4.tar.gz /usr/local/yarn/ 解压源码 tar -xvf yarn-v1.9.4.tar.gz 配置环境变量 vim /etc/profile # yarn export YARN_HOME=/usr/local/node/yarn-v1.9.4 export PATH=$YARN_HOME/bin:$PATH # 使配置生效 source /etc/profile 验证 yarn --version ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:1:1","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"简单使用 ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:2:0","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"开始新项目 yarn init ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:2:1","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"添加依赖包 yarn add [package] yarn add [package]@[version] yarn add [package]@[tag] Adding a dependency to different categories of dependencies 分别添加到 devDependencies、peerDependencies 和 optionalDependencies： yarn add [package] --dev yarn add [package] --peer yarn add [package] --optional ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:2:2","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"升级依赖包 yarn upgrade [package] yarn upgrade [package]@[version] yarn upgrade [package]@[tag] ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:2:3","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"移除依赖包 yarn remove [package] ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:2:4","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"安装项目的全部依赖 yarn # 或者 yarn install ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:2:5","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"全局 yarn global [add|bin|ls|remove|upgrade] [flags] # 相当于 npm -g 更多命令详情 Yarn CLI ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:2:6","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"配置淘宝源 ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:3:0","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"全局使用 yarn config set registry http://registry.npm.taobao.org 切换会原来的源 yarn config set registry https://registry.npmjs.org/ ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:3:1","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"避免与 npm 混用 yarn 的全局 node_modules 位置和 npm 的不同。npm 的 bin 目录在 C:/Users/xxx/AppData/Roaming/npm，yarn 会 把 C:/Users/xxx/AppData/Roaming/npm/node_modules 目录的结构改掉，并把之前用 npm 安装的一些模块删除掉，包括 npm 本身依赖的模块， 最终导致npm不可用。 ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:4:0","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Node.js"],"content":"global add 的命令报错 command not found yarn global bin 先使用上面的命令查看 yarn 全局安装的二进制文件的位置，找到后把这个目录配置到环境变量。 ","date":"2017-09-05","objectID":"/posts/2017-09-05-yarn/:5:0","tags":null,"title":"使用 Yarn 代替 NPM","uri":"/posts/2017-09-05-yarn/"},{"categories":["Others"],"content":"Markdown 是一种轻量级的标记语言，它用简洁的语法代替排版。Markdown 的语法非常简单，它的语法由一些符号所组成，这些一目了然符号让我们更专注于 文字的内容而不是排版和样式。 ","date":"2017-08-25","objectID":"/posts/2017-08-25-markdown/:0:0","tags":null,"title":"Markdown 入门","uri":"/posts/2017-08-25-markdown/"},{"categories":["Others"],"content":"标题 在行首插入 1 到6个 #，对应到标题 1 到 6 阶，例如： # 一级标题\r## 二级标题\r### 三级标题 ","date":"2017-08-25","objectID":"/posts/2017-08-25-markdown/:1:0","tags":null,"title":"Markdown 入门","uri":"/posts/2017-08-25-markdown/"},{"categories":["Others"],"content":"列表 Markdown 支持有序列表和无序列表。在文字前加上 - 或 * 或 + 即可变为无序列表，有序列表则使用数字接着一个英文句点，要和文字之间加上 一个字符的空格。 * Red\r* Green\r* Blue\r1. Red\r2. Green\r3. Blue ","date":"2017-08-25","objectID":"/posts/2017-08-25-markdown/:2:0","tags":null,"title":"Markdown 入门","uri":"/posts/2017-08-25-markdown/"},{"categories":["Others"],"content":"区块引用 Markdown 标记区块引用是用 \u003e 的引用方式。 \u003e This is a blockquote. ","date":"2017-08-25","objectID":"/posts/2017-08-25-markdown/:3:0","tags":null,"title":"Markdown 入门","uri":"/posts/2017-08-25-markdown/"},{"categories":["Others"],"content":"链接 插入链接与插入图片链接： // 图片\r![myimagename](/images/2/img2.jpg)\r\u003cimg src=\"/images/2/img2.jpg\" width=\"80%\" height=\"\"\u003e\r// 链接\r[这是百度](https://www.baidu.com) ","date":"2017-08-25","objectID":"/posts/2017-08-25-markdown/:4:0","tags":null,"title":"Markdown 入门","uri":"/posts/2017-08-25-markdown/"},{"categories":["Others"],"content":"粗体与斜体 Markdown 的粗体和斜体也非常简单，用两个 ** 包含一段文本就是粗体的语法，用一个 * 包含一段文本就是斜体的语法。 **粗体**\r*斜体* ","date":"2017-08-25","objectID":"/posts/2017-08-25-markdown/:5:0","tags":null,"title":"Markdown 入门","uri":"/posts/2017-08-25-markdown/"},{"categories":["Others"],"content":"分隔线 Markdown 可以在一行中用三个以上的 *、-、— 来建立一个分隔线，行内不能有其他东西。 * * *\r***\r*****\r- - -\r------------- ","date":"2017-08-25","objectID":"/posts/2017-08-25-markdown/:6:0","tags":null,"title":"Markdown 入门","uri":"/posts/2017-08-25-markdown/"},{"categories":["Others"],"content":"代码区块 标记一小段行内代码，你可以用反引号把它包起来。 this is my `code`. ","date":"2017-08-25","objectID":"/posts/2017-08-25-markdown/:7:0","tags":null,"title":"Markdown 入门","uri":"/posts/2017-08-25-markdown/"},{"categories":["Others"],"content":"表格 Markdown 表格比较麻烦： | 水果 | 价格 | 数量 |\r| -------- | -----: | :----: |\r| 香蕉 | $1 | 5 |\r| 苹果 | $1 | 6 |\r| 草莓 | $1 | 7 | 说明： 第一行为表头，第二行分隔表头和主体部分，第三行开始每一行代表一个表格行。 列与列之间用 | 隔开，表格每一行的两边也要有 |。 第二行指定不同列单元格内容的对齐方式，默认为左对齐，在 - 右边加上 : 为右对齐，在 - 两侧同时加上 : 为居中对齐。 ","date":"2017-08-25","objectID":"/posts/2017-08-25-markdown/:8:0","tags":null,"title":"Markdown 入门","uri":"/posts/2017-08-25-markdown/"},{"categories":["Node.js"],"content":"npm 脚本功能是最常用的功能之一。运行 npm run \u003cscript_name\u003e 会执行当前项目的 package.json 中 scripts 属性下对应 script_name 的 脚本。 ","date":"2017-07-23","objectID":"/posts/2017-07-23-npm-scripts/:0:0","tags":null,"title":"NPM scripts 使用","uri":"/posts/2017-07-23-npm-scripts/"},{"categories":["Node.js"],"content":"简单使用 使用 scripts 字段定义脚本命令。 \"scripts\": { \"build\": \"node build.js\" } 使用 npm run 命令，就可以执行这段脚本: npm run build ","date":"2017-07-23","objectID":"/posts/2017-07-23-npm-scripts/:1:0","tags":null,"title":"NPM scripts 使用","uri":"/posts/2017-07-23-npm-scripts/"},{"categories":["Node.js"],"content":"原理 npm run 会创建一个 Shell，执行指定的命令，并临时将 node_modules/.bin 加入 PATH 变量，执行结束后，再将 PATH 变量恢复原样。 也就说 node_modules/.bin 子目录里面的脚本，都可以直接用脚本名调用。比如，当前项目的依赖里面有 Mocha，只要直接写 mocha test 就可以了。 \"test\": \"mocha test\" // 而不用写成下面这样。 \"test\": \"./node_modules/.bin/mocha test\" npm 脚本的退出码，也遵守 Shell 脚本规则。如果退出码不是 0，npm 就认为这个脚本执行失败。 ","date":"2017-07-23","objectID":"/posts/2017-07-23-npm-scripts/:2:0","tags":null,"title":"NPM scripts 使用","uri":"/posts/2017-07-23-npm-scripts/"},{"categories":["Node.js"],"content":"传参 向 npm 脚本传入参数，要使用 -- 隔开，-- 后面的内容都会原封不动地传给运行的命令。 \"test\": \"mocha test\" 向上面的 npm test 命令传入参数，必须写成下面这样。 npm test -- --reporter spec 也可以封装在 package.json 里面。 \"test\": \"mocha --reporter spec\" ","date":"2017-07-23","objectID":"/posts/2017-07-23-npm-scripts/:3:0","tags":null,"title":"NPM scripts 使用","uri":"/posts/2017-07-23-npm-scripts/"},{"categories":["Node.js"],"content":"钩子 在 npm script 中有两个钩子 pre 和 post。例如上面的 test 脚本： \"scripts\":{ \"pretest\": \"echo run before the test script\" \"test\": \"mocha --reporter spec\", \"posttest\": \"echo run after the test script\" } 执行 npm test 的时候，会自动按照下面的顺序执行。 npm run pretest \u0026\u0026 npm run test \u0026\u0026 npm run posttest ","date":"2017-07-23","objectID":"/posts/2017-07-23-npm-scripts/:4:0","tags":null,"title":"NPM scripts 使用","uri":"/posts/2017-07-23-npm-scripts/"},{"categories":["Node.js"],"content":"简写形式 四个常用的 npm 脚本有简写形式。 npm start 是 npm run start npm stop 是 npm run stop 的简写 npm test 是 npm run test 的简写 npm restart npm restart 是一个复合命令，它不单单执行 prerestart, restart, postrestart 具体的执行顺序如下： prerestart prestop stop poststop restart prestart start poststart postrestart ","date":"2017-07-23","objectID":"/posts/2017-07-23-npm-scripts/:5:0","tags":null,"title":"NPM scripts 使用","uri":"/posts/2017-07-23-npm-scripts/"},{"categories":["Node.js"],"content":"环境变量 npm 脚本可以访问 package.json 中的变量。 通过 process.env.npm_package_xxx 可以获得，比如，下面是一个 package.json。 { \"name\": \"foo\", \"version\": \"1.2.5\", \"scripts\": { \"view\": \"node view.js\" } } process.env.npm_package_name // foo process.env.npm_package_version // 1.2.5 process.env.npm_package_scripts_view //node view.js npm 脚本可以访问 npm 的配置变量。 通过 process.env.npm_config_xxx 可以获得，即 npm config get xxx 命令返回的值。 例如 process.env.npm_config_user_email 可以拿到 user.email 的值。 ","date":"2017-07-23","objectID":"/posts/2017-07-23-npm-scripts/:6:0","tags":null,"title":"NPM scripts 使用","uri":"/posts/2017-07-23-npm-scripts/"},{"categories":["Node.js"],"content":"npm 是 Node 的模块管理器，功能强大，使用简单。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:0:0","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm 常用命令 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:0","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm init 运行构建新项目的向导，初始化一个 package.json 文件，使用 npm init --yes 命令使用默认的配置来创建 package.json 文件。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:1","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm install 读取 package.json 文件来安装模块。package.json 文件中的 dependencies 和 devDependencies，分别对应生产环境需要的安装包和 开发环境需要的安装包。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:2","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm install \u003cpackage_name\u003e 在项目中安装模块。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:3","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm install \u003cpackage_name\u003e@ 安装指定版本的模块，版本号用 @ 符号连接。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:4","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm install -g \u003cpackage_name\u003e 全局安装模块。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:5","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm install \u003cpackage_name\u003e –save 在项目中安装模块，并添加到项目配置文件 package.json 中，作为项目依赖。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:6","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm install \u003cpackage_name\u003e –save-dev 在项目中安装模块，并添加到项目配置文件 package.json 中，作为项目开发依赖（devDependency）。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:7","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm update \u003cpackage_name\u003e 更新指定的已安装模块。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:8","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm update -g \u003cpackage_name\u003e 更新指定的全局安装模块。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:9","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm uninstall \u003cpackage_name\u003e 从项目中移除已安装的模块。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:10","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm uninstall –save \u003cpackage_name\u003e 卸载模块的同时，也将他从 package.json 文件中移除。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:11","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm list 列出项目中已安装的所有模块 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:12","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm list -g 列出系统中全局安装的所有模块 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:13","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm -v 显示 npm 包管理器的当前版本 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:14","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm adduser username 在 npmjs.org 创建一个账户 npm adduser Username: YOUR_USER_NAME Password: YOUR_PASSWORD Email: YOUR_EMAIL@domain.com ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:15","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm whoami 显示 npmjs.org 上的账户详细信息 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:16","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm publish 发布自己开发的模块到 npmjs.org，要发布模块必须先有账户 更新时发布的模块要先修改模块的 version 否则会 error。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:17","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm search \u003cpackage_name\u003e 搜索模块。可以用来检验某个包名是否已存在。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:18","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm root 查看当前包的安装路径。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:19","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm root -g 查看全局的包的安装路径。 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:20","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm config 管理 npm 的配置路径。 npm config set \u003ckey\u003e \u003cvalue\u003e [-g|--global] npm config get \u003ckey\u003e npm config delete \u003ckey\u003e npm config list npm config edit ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:21","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"npm login 登录 npmjs.org。 如果 npm login 输入正确的用户名和密码时仍出现 Incorrect username or password 的错误， 先通过 npm config ls 查看是否使用了非 npmjs.org 官网的 registry。如下： npm config ls ; cli configs user-agent = \"npm/2.14.2 node/v4.0.0 darwin x64\" ; userconfig /Users/xxx/.npmrc email = \"xxx@xx.com\" registry = \"https://registry.npm.taobao.org/\" 切换回 npm 官方库地址: npm config set registry https://registry.npmjs.org/ ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:1:22","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"Node.js 模块的版本号 npm 使用语义版本号来管理代码，语义版本号分为 X.Y.Z 三位，分别代表主版本号、次版本号和补丁版本号。当代码变更时，版本号按以下原则更新。 主要版本 Major：X.0.0 // 有大变动，向下不兼容 次要版本 Minor：0.Y.0 // 新增了功能，但是向下兼容 补丁版本 Patch：0.0.Z // 只是修复bug ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:2:0","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"配置 npm 源 ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:3:0","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"临时使用 npm install express --registry https://registry.npm.taobao.org ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:3:1","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"全局使用 npm config set registry https://registry.npm.taobao.org # 验证是否成功 npm config get registry npm info express 切换会原来的源 npm config set registry https://registry.npmjs.org/ ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:3:2","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"使用 cnpm npm install -g cnpm --registry=https://registry.npm.taobao.org cnpm install express ","date":"2017-07-19","objectID":"/posts/2017-07-19-npm-use/:3:3","tags":null,"title":"npm 使用入门","uri":"/posts/2017-07-19-npm-use/"},{"categories":["Node.js"],"content":"使用 npm init 命令初始化一个 package.json 文件，描述这个 NPM 包的所有相关信息，包括作者、简介、包依赖、构建等信息，格式是严格的 JSON 格式。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:0:0","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"属性 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:0","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"name name 和 version 是最重要的两个属性，也是发布到 NPM 平台上的唯一标识，如果没有正确设置这两个字段，包就不能发布和被下载。 模块更新，那么 version 也应该一起更新。 命名规则: name 必须小于等于 214 个字节，包括前缀名称在内（如 xxx/xxxmodule）。 name 不能以 _ 或 . 开头 不能含有大写字母 name 会成为 url 的一部分，不能含有 url 非法字符 name 中不要含有 “js” 和 “node”。 It’s assumed that it’s js, since you’re writing a package.json file, and you can specify the engine using the “engines” field. (See below.) name 属性可以有一些前缀如 e.g. @myorg/mypackage. ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:1","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"version 模块的版本号。如 “1.0.0”。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:2","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"description 模块的描述信息。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:3","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"keywords 模块的关键词信息，是一个字符串数组。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:4","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"homepage 模块的主页 url。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:5","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"bugs 模块的 bug 提交地址或者一个邮箱。例如： { \"url\" : \"https://github.com/owner/project/issues\", \"email\" : \"project@hostname.com\" } ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:6","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"license 模块的开源协议名称。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:7","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"author，contributors, maintainers author：模块的作者。 contributors、maintainers：模块的贡献者、维护者，是一个数组。 { \"name\" : \"Xiao Ming\", \"email\" : \"xiaoming@163.com\", \"url\" : \"http://www.xiaoming.com/\" } email 和 url 属性是可以省略的。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:8","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"files 一个数组，模块所包含的所有文件，可以取值为文件夹。通常是用 .npmignore 来去除不想包含到包里的文件，与 .gitignore 类似。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:9","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"main 模块的入口文件。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:10","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"bin 如果你的模块里包含可执行文件，通过设置这个字段可以将它们包含到系统的 PATH 中，这样直接就可以运行，很方便。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:11","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"man 为系统的 man 命令提供帮助文档。帮助文件的文件名必须以数字结尾，如果是压缩的，需要以 .gz 结尾。 \"man\": [\"./man/foo.1\", \"./man/bar.1\", \"./man/foo.2\" ] ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:12","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"directories CommonJS 模块所要求的目录结构信息，展示项目的目录结构信息。字段可以是：lib, bin, man, doc, example。值都是字符串。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:13","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"repository 模块的仓库地址。 \"repository\": { \"type\": \"git\", \"url\": \"git+https://github.com/rainnaZR/es6-react.git\" } ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:14","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"config 添加设置，供 scripts 读取用，同时这里的值也会被添加到系统的环境变量中。通常用来设置一些项目不怎么变化的配置，例如 port： \"config\": { \"port\": \"8080\" } // 用户调用 http.createServer(...).listen(process.env.npm_package_config_port) 可以通过 npm config set foo:port 8080 来修改 config: { \"name\" : \"foo\", \"config\" : { \"port\" : \"8080\" } } npm start 的时候会读取到 npm_package_config_port 环境变量。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:15","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"dependencies 指定依赖的其它包，这些依赖是指包发布后正常执行时所需要的，也就是线上需要的包。使用下面的命令来安装： npm install --save \u003cpackage_name\u003e 用法： version 精确匹配版本 \u003eversion 必须大于某个版本 \u003e=version 大于等于 \u003cversion 小于 \u003c=versionversion小于 ~version “约等于”，具体规则详见 semver 文档 ^version “兼容版本\"具体规则详见 semver 文档 1.2.x 仅一点二点几的版本 http://... url作为 denpendencies \"\" 空字符，和 * 相同，任何版本 version1 - version2 相当于 \u003e=version1 \u003c=version2. range1 || range2 范围 1 和范围 2 满足任意一个都行 git... git url 作为 denpendencies user/repo See 见下面 GitHub 仓库的说明 tag 发布的一个特殊的标签，见 npm-tag 的文档 path/path/path 本地模块 { \"dependencies\" : { \"foo\" : \"1.0.0 - 2.9999.9999\", \"bar\" : \"\u003e=1.0.2 \u003c2.1.2\", \"baz\" : \"\u003e1.0.2 \u003c=2.3.4\", \"boo\" : \"2.0.1\", \"qux\" : \"\u003c1.0.0 || \u003e=2.3.1 \u003c2.4.5 || \u003e=2.5.2 \u003c3.0.0\", \"asd\" : \"http://asdf.com/asdf.tar.gz\", \"til\" : \"~1.2\", \"elf\" : \"~1.2.3\", \"two\" : \"2.x\", \"thr\" : \"3.3.x\", \"lat\" : \"latest\", \"dyl\" : \"file:../dyl\" } } URLs as Dependencies 在版本范围的地方可以写一个 url 指向一个压缩包，模块安装的时候会把这个压缩包下载下来安装到模块本地。 Git URLs as Dependencies Git url 可以像下面一样: git://github.com/user/project.git#commit-ish git+ssh://user@hostname:project.git#commit-ish git+ssh://user@hostname/project.git#commit-ish git+http://user@hostname/project/blah.git#commit-ish git+https://user@hostname/project/blah.git#commit-ish commit-ish 可以是任意标签，哈希值，或者可以检出的分支，默认是 master 分支。 GitHub URLs 支持 github 的 username/modulename 的写法，# 后边可以加后缀写明分支 hash 或标签： { \"name\": \"foo\", \"version\": \"0.0.0\", \"dependencies\": { \"express\": \"visionmedia/express\", \"mocha\": \"visionmedia/mocha#4727d357ea\" } } ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:16","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"devDependencies 这些依赖只有在开发时候才需要。使用下面的命令来安装： npm install --save-dev \u003cpackage_name\u003e ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:17","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"peerDependencies 相关的依赖，如果你的包是插件，而用户在使用你的包时候，通常也会需要这些依赖（插件），那么可以将依赖列到这里。 如 karma, 它的 package.json 中有设置，依赖下面这些插件： \"peerDependencies\": { \"karma-jasmine\": \"~0.1.0\", \"karma-requirejs\": \"~0.2.0\", \"karma-coffee-preprocessor\": \"~0.1.0\", \"karma-html2js-preprocessor\": \"~0.1.0\", \"karma-chrome-launcher\": \"~0.1.0\", \"karma-firefox-launcher\": \"~0.1.0\", \"karma-phantomjs-launcher\": \"~0.1.0\", \"karma-script-launcher\": \"~0.1.0\" } ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:18","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"bundledDependencies 绑定的依赖包，发布的时候这些绑定包也会被一同发布。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:19","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"engines 指定模块运行的环境。 \"engines\": { \"node\": \"\u003e=0.10.3 \u003c 0.12\", \"npm\": \"~1.0.20\" } ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:20","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"os 一个数组，指定模块支持的系统平台。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:21","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"cpu 指定模块运行的 cpu 架构。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:22","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"private 设为 true 这个模块将不会发布到 NPM 平台下。 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:23","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Node.js"],"content":"scripts 使用 scripts 字段定义脚本命令。 \"scripts\": { \"build\": \"node build.js\" } 使用 npm run 命令，就可以执行这段脚本: npm run build 更多参考 官方文档 ","date":"2017-07-10","objectID":"/posts/2017-07-10-npm-package/:1:24","tags":null,"title":"NPM package.json 详解","uri":"/posts/2017-07-10-npm-package/"},{"categories":["Linux"],"content":"Linux 下环境变量设置，可以在通过 export 命令在控制台中设置，也可修改 profile 文件或者 bashrc 文件。 ","date":"2017-06-22","objectID":"/posts/2017-06-22-linux-profile/:0:0","tags":null,"title":"Linux 环境变量设置","uri":"/posts/2017-06-22-linux-profile/"},{"categories":["Linux"],"content":"export命令 控制台中用户利用 export 命令，在当前终端下声明环境变量，只对当前的 Shell 终端起作用，关闭 Shell 终端失效。如: export NODE_ENV=\"production\" ","date":"2017-06-22","objectID":"/posts/2017-06-22-linux-profile/:1:0","tags":null,"title":"Linux 环境变量设置","uri":"/posts/2017-06-22-linux-profile/"},{"categories":["Linux"],"content":"修改 profile 文件 用户登录时，文件会被执行。修改 profile 文件，环境变量对该系统中所有用户都永久有效。因为所有用户的 Shell 终端都有权使用这个环境变量，可能会 给系统带来安全性问题。添加环境变量时，可以在行尾使用 ; 号，也可以不使用。一个变量名可以对应多个变量值，多个变量值使用 : 分隔。 PATH=$PATH:\u003cPATH 1\u003e:\u003cPATH 2\u003e:\u003cPATH 3\u003e:....:\u003cPATH N\u003e Example: vim /etc/profile # 添加 export NODE_ENV=\"production\" # node export NODE_HOME=/usr/local/node/v8.11.4 export PATH=$NODE_HOME/bin:$PATH # yarn YARN_INSTALL_DIR=/usr/local/yarn/v1.9.4 PATH=$PATH:$YARN_INSTALL_DIR/bin # proxy export http_proxy=http://web-proxy.net:8080 export https_proxy=$http_proxy export HTTP_PROXY=$http_proxy export HTTPS_PROXY=$http_proxys export no_proxy=127.0.0.1,localhost export NO_PROXY=$no_proxy # 使配置生效 source /etc/profile # 查看是否生效 $ echo $NODE_ENV ","date":"2017-06-22","objectID":"/posts/2017-06-22-linux-profile/:2:0","tags":null,"title":"Linux 环境变量设置","uri":"/posts/2017-06-22-linux-profile/"},{"categories":["Linux"],"content":"修改 bashrc 文件 bashrc 文件有两种:/etc/bashrc 和 ~/.bashrc。bashrc 只会被 bash shell 调用。 /etc/bashrc 对该系统中所有用户都永久有效，当用户打开 Shell 终端时，该文件被读取，修改后无需重启，重新开一个 Shell 终端即可生效，也可以使 用 source 命令强制立即生效。 ~/.bashrc 只对某个用户永久有效，当登录或打开新的 Shell 终端时，文件被读取，修改后无需重启，重新开一个 Shell 终端即可生效，也可以使用 source 命令强制立即生效。修改用户主目录下的 ~/.bashrc 文件，对某个用户永久有效。这种方法相对安全。 vim ~/.bashrc # 添加 export NODE_ENV=\"production\" # 使配置生效 source ~/.bashrc ","date":"2017-06-22","objectID":"/posts/2017-06-22-linux-profile/:3:0","tags":null,"title":"Linux 环境变量设置","uri":"/posts/2017-06-22-linux-profile/"},{"categories":["Linux"],"content":"修改 bash_profile 文件 用户登录时，文件会被执行。~/.bash_profile 文件只对某个用户永久有效，和 profile 文件作用类似。 vim ~/.bash_profile # 添加 export NODE_ENV=\"production\" # 使配置生效 source ~/.bash_profile ","date":"2017-06-22","objectID":"/posts/2017-06-22-linux-profile/:4:0","tags":null,"title":"Linux 环境变量设置","uri":"/posts/2017-06-22-linux-profile/"},{"categories":["Linux"],"content":"常见环境变量 $PATH：决定了shell将到哪些目录中寻找命令或程序 $HOME：当前用户主目录。 $SHELL：指当前用户用的是哪种 Shell。 $LOGNAME：指当前用户的登录名。 $HOSTNAME：指主机的名称。 $HISTSIZE：指保存历史命令记录的条数。 $LANG/LANGUGE：和语言相关的环境变量，使用多种语言的用户可以修改此环境变量。 $MAIL：指当前用户的邮件存放目录。 $PS1：是基本提示符，对于 root 用户是 #，对于普通用户是 $，也可以使用一些更复杂的值。 $PS2：是附属提示符，默认是 \u003e。可以通过修改此环境变量来修改当前的命令符。 $IFS：输入域分隔符。当 Shell 读取输入时，用来分隔单词的一组字符，它们通常是空格、制表符和换行符。 $0：shell 脚本的名字。 $#：传递给脚本的参数个数。 # 在 shell 中 echo $0 # 输出 /usr/bin/bash echo $# # 输出 0 ","date":"2017-06-22","objectID":"/posts/2017-06-22-linux-profile/:5:0","tags":null,"title":"Linux 环境变量设置","uri":"/posts/2017-06-22-linux-profile/"},{"categories":["Linux"],"content":"环境变量相关的命令 export 设置一个新的环境变量 export NODE_ENV=\"production\" (可以无引号) echo 显示某个环境变量值 echo $NODE_ENV env 显示所有环境变量 set 显示本地定义的 shell 变量 unset 清除环境变量 unset NODE_ENV readonly 设置只读环境变量 readonly HELLO set # 输出 BASH=/bin/bash ... export NODE_ENV=\"production\" readonly NODE_ENV # 将环境变量 NODE_ENV 设为只读 unset NODE_ENV # 输出 发现此变量不能被删除 -bash: unset: NODE_ENV: cannot unset: readonly variable ","date":"2017-06-22","objectID":"/posts/2017-06-22-linux-profile/:6:0","tags":null,"title":"Linux 环境变量设置","uri":"/posts/2017-06-22-linux-profile/"},{"categories":["Linux"],"content":"在 CentOS 上用源码安装 Node.js。 官网下载 node 。 wget https://nodejs.org/dist/v6.11.4/node-v6.11.4-linux-x64.tar.xz # /usr/local/node/ mkdir /usr/local/node/ mv ./node-v6.11.4-linux-x64 /usr/local/node/ 解压源码 tar -xvf node-v6.11.4-linux-x64.tar.xz Node 环境配置 vim /etc/profile # 在 export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL 一行的上面添加 # nodejs export NODE_HOME=/usr/local/node/6.11.4 export PATH=$NODE_HOME/bin:$PATH # 编译/etc/profile 使配置生效 source /etc/profile 验证 node -v npm -v ","date":"2017-06-12","objectID":"/posts/2017-06-12-node-install/:0:0","tags":null,"title":"CentOS 安装 Node.js","uri":"/posts/2017-06-12-node-install/"},{"categories":["Javascript"],"content":"每一个 Javascript 对象(null 除外)都和另一个对象相关联，即原型，每一个对象都从原型继承属性。 ","date":"2017-06-09","objectID":"/posts/2017-06-09-js-prototype-chain/:0:0","tags":null,"title":"Javascript 原型链","uri":"/posts/2017-06-09-js-prototype-chain/"},{"categories":["Javascript"],"content":"原型链 function Test(value) { this.a = value; } Test.prototype.getValue = function() { console.log(this.a); }; var test = new Test(1); test.getValue(); // 输出1 Javascript 在创建对象的时候，都有一个叫做 __proto__ 的内置属性，用于指向创建它的函数对象的原型对象 prototype。上面的代码中： console.log(test.__proto__ === Test.prototype) //true 同样，Test.prototype 对象也有 __proto__ 属性，它指向创建它的函数对象（Object）的 prototype console.log(Test.prototype.__proto__ === Object.prototype) // true 继续，Object.prototype 对象也有 __proto__ 属性，但它比较特殊，为 null console.log(Object.prototype.__proto__) //null 这个由 __proto__ 串起来的直到 Object.prototype.__proto__ 为 null 的链叫做原型链。 ","date":"2017-06-09","objectID":"/posts/2017-06-09-js-prototype-chain/:1:0","tags":null,"title":"Javascript 原型链","uri":"/posts/2017-06-09-js-prototype-chain/"},{"categories":["Javascript"],"content":"prototype 和 proto prototype 是函数的一个属性（每个函数都有一个 prototype 属性），这个属性是一个指针，指向一个对象。 prototype 包含了 2 个属性， constructor，值为函数本身 __proto__，值为父函数的 prototype 属性值。 可以通过 hasOwnProperty 方法验证。 prototype 是函数的内置属性，__proto__ 是对象的内置属性。 ","date":"2017-06-09","objectID":"/posts/2017-06-09-js-prototype-chain/:2:0","tags":null,"title":"Javascript 原型链","uri":"/posts/2017-06-09-js-prototype-chain/"},{"categories":["Javascript"],"content":"new 的过程 function Test() {} var t = new Test(); new 的过程拆分成以下三步： var t = {}; 初始化一个对象 t t.__proto__ = Test.prototype; Test.call(t); ","date":"2017-06-09","objectID":"/posts/2017-06-09-js-prototype-chain/:3:0","tags":null,"title":"Javascript 原型链","uri":"/posts/2017-06-09-js-prototype-chain/"},{"categories":["Javascript"],"content":"Javascript 实现继承的 5 种方式。 例如实现 Student 对 Man 的继承： function Man(){ this.sex = \"男\"; } function Student(name,age){ this.name = name; this.age = age; } ","date":"2017-05-29","objectID":"/posts/2017-05-29-js-extend/:0:0","tags":null,"title":"Javascript 继承","uri":"/posts/2017-05-29-js-extend/"},{"categories":["Javascript"],"content":"使用 call 或 apply 方法 function Student(name,age){ Man.apply(this, arguments);// 或者 Man.call(this) this.name = name; this.age = age; } var s = new Student(\"xiaoming\", 18); console.log(s.sex); // 男 ","date":"2017-05-29","objectID":"/posts/2017-05-29-js-extend/:1:0","tags":null,"title":"Javascript 继承","uri":"/posts/2017-05-29-js-extend/"},{"categories":["Javascript"],"content":"原型链方式 Student.prototype = new Man(); Student.prototype.constructor = Student; // 因为上一行代码使 Student.prototype.constructor 指向了 Man 的构造函数， // 但是 prototype 的 constructor 属性都应该指向它的构造函数， // 所以这里手动让 Student.prototype.constructor 指向 Student var s = new Student(\"xiaoming\", 18); console.log(s.sex); // 男 ","date":"2017-05-29","objectID":"/posts/2017-05-29-js-extend/:2:0","tags":null,"title":"Javascript 继承","uri":"/posts/2017-05-29-js-extend/"},{"categories":["Javascript"],"content":"直接继承 prototype 对原型链方式的改进。与原型链方式相比，这种方式省去了 new 一个 Man 实例的步骤，节省内存。但是 Student.prototype 和 Man.prototype 指向 了同一个对象，那么对 Student.prototype 的修改，也会反映到 Man.prototype，这不是我们想看到的。 Student.prototype = Man.prototype; Student.prototype.constructor = Student; var s = new Student(\"xiaoming\", 18); console.log(s.sex); // 男 ","date":"2017-05-29","objectID":"/posts/2017-05-29-js-extend/:3:0","tags":null,"title":"Javascript 继承","uri":"/posts/2017-05-29-js-extend/"},{"categories":["Javascript"],"content":"利用空对象实现继承 var F = function(){}; F.prototype = Man.prototype; Student.prototype = new F(); Student.prototype.constructor = Student; F是空对象，几乎不占内存。而且修改 Student.prototype，不会影响到 Man.prototype。 ","date":"2017-05-29","objectID":"/posts/2017-05-29-js-extend/:4:0","tags":null,"title":"Javascript 继承","uri":"/posts/2017-05-29-js-extend/"},{"categories":["Javascript"],"content":"拷贝继承 function extend(Child, Parent) { var p = Parent.prototype; var c = Child.prototype; for (var i in p) { c[i] = p[i]; } } extend(Student, Man); var s = new Student(\"xiaoming\", 18); console.log(s.sex); // 男 效率较低，内存占用高（因为要拷贝父类的属性），而且无法获取父类不可枚举的方法（不可枚举方法，不能使用 for in 访问到） ","date":"2017-05-29","objectID":"/posts/2017-05-29-js-extend/:5:0","tags":null,"title":"Javascript 继承","uri":"/posts/2017-05-29-js-extend/"},{"categories":["Javascript"],"content":"多重继承 function Class1() { this.showSub = function(a,b) { console.log(a-b); } } function Class2() { this.showAdd = function(a,b) { console.log(a+b); } } function Class3() { Class1.call(this); Class2.call(this); } ","date":"2017-05-29","objectID":"/posts/2017-05-29-js-extend/:6:0","tags":null,"title":"Javascript 继承","uri":"/posts/2017-05-29-js-extend/"},{"categories":["Javascript"],"content":"Node.js 常用的实现继承的方法 var util = require('util'); function Man(){ this.sex = \"男\"; } function Student(name,age){ Man.call(this); // 继承属性 this.name = name; this.age = age; } util.inherits(Student, Man);// 继承方法 ","date":"2017-05-29","objectID":"/posts/2017-05-29-js-extend/:7:0","tags":null,"title":"Javascript 继承","uri":"/posts/2017-05-29-js-extend/"},{"categories":["Linux"],"content":"Linux 实现无密码登录 ","date":"2017-05-21","objectID":"/posts/2017-05-21-ssh-imp-login/:0:0","tags":null,"title":"Linux 实现无密码登录","uri":"/posts/2017-05-21-ssh-imp-login/"},{"categories":["Linux"],"content":"本地机配置 如果本机已经有 ssh key, 请忽略这一步, 如果还没有需要同过下面的命令生成： ssh-keygen \\\\ 或者 ssh-keygen -t rsa 这里一路回车。生成 ssh 密钥后，可以到 ~/.ssh 目录下查看, 该目录下有两个文件 id_rsa (私钥)和 id_rsa.pub (公钥), -t rsa 是设置生成密钥的算法, 如果使用 -t dsa,生成的文件名分别是：id_dsa, id_rsa.pub。还可以通过 -C 参数添加密钥的注释例如： ssh-keygen -t rsa -C \"\u003c注释\u003e\" ","date":"2017-05-21","objectID":"/posts/2017-05-21-ssh-imp-login/:1:0","tags":null,"title":"Linux 实现无密码登录","uri":"/posts/2017-05-21-ssh-imp-login/"},{"categories":["Linux"],"content":"远端服务器 查看是否存在 ~/.ssh 目录，查看是否已经有 ssh key。如果没有执行上一步操作的命令。 创建好SSH 密钥后，创建 authorized_keys，该文件是授权文件。编辑该文件： vim authorized_keys 将本地机器的 id_rsa.pub 文件内容粘贴到 authorized_keys 文件。 ","date":"2017-05-21","objectID":"/posts/2017-05-21-ssh-imp-login/:2:0","tags":null,"title":"Linux 实现无密码登录","uri":"/posts/2017-05-21-ssh-imp-login/"},{"categories":["Linux"],"content":"配置无密码登录 切换到 root 账户。编辑以下配置文件： vim /etc/ssh/sshd_config 去掉如下三行注释#： #RSAAuthentication yes #PubkeyAuthentication yes #AuthorizedKeysFile .ssh/authorized_keys ","date":"2017-05-21","objectID":"/posts/2017-05-21-ssh-imp-login/:3:0","tags":null,"title":"Linux 实现无密码登录","uri":"/posts/2017-05-21-ssh-imp-login/"},{"categories":["Linux"],"content":"重启 sshd 服务 service sshd restart \\\\CentOS systemctl restart sshd.service ","date":"2017-05-21","objectID":"/posts/2017-05-21-ssh-imp-login/:4:0","tags":null,"title":"Linux 实现无密码登录","uri":"/posts/2017-05-21-ssh-imp-login/"},{"categories":["Linux"],"content":"登录 ssh -l bot 192.168.0.1 这个时候应该可以直接登录了。 ","date":"2017-05-21","objectID":"/posts/2017-05-21-ssh-imp-login/:5:0","tags":null,"title":"Linux 实现无密码登录","uri":"/posts/2017-05-21-ssh-imp-login/"},{"categories":["Javascript"],"content":"JavaScript 中的 apply、call、bind 方法都可以改变函数的 this 的作用域。 ","date":"2017-05-20","objectID":"/posts/2017-05-20-js-apply-call-bind/:0:0","tags":null,"title":"JavaScript 中的 apply、call、bind 方法","uri":"/posts/2017-05-20-js-apply-call-bind/"},{"categories":["Javascript"],"content":"apply apply 方法有两个参数，第一个参数为 this 所要指向的那个对象，第二个参数是一个数组，绑定对象的参数数组。apply()的参数为空时，默认是指向 全局对象。 function add (x, y) { console.log(x + y); } function multiply (x, y){ add.apply(this, [x, y]); // 绑定参数组 } function sub (x, y){ add.apply(this, arguments); // 绑定 arguments 对象 } multiply(2, 3); // 5 sub(2, 3); // 5 绑定 arguments 对象和绑定参数组在使用上没有区别。 ","date":"2017-05-20","objectID":"/posts/2017-05-20-js-apply-call-bind/:1:0","tags":null,"title":"JavaScript 中的 apply、call、bind 方法","uri":"/posts/2017-05-20-js-apply-call-bind/"},{"categories":["Javascript"],"content":"call call 方法与 apply 方法作用相同，在参接上有所区别。第一个参数同样是 this 所要指向的那个对象，但是其余参数都是直接传递给函数。 function add (x, y, z) { console.log(x + y + z); } function multiply (x, y, z){ add.call(this, x, y, z); // 绑定参数列表 } multiply(2, 3, 4); // 9 ","date":"2017-05-20","objectID":"/posts/2017-05-20-js-apply-call-bind/:2:0","tags":null,"title":"JavaScript 中的 apply、call、bind 方法","uri":"/posts/2017-05-20-js-apply-call-bind/"},{"categories":["Javascript"],"content":"bind bind 方法会创建一个函数实例，参数传递形式与 call 方法相同。如果 bind 方法的第一个参数是 null 或 undefined，等于将 this 绑定到全局 对象，函数运行时 this 指向全局对象。 window.color = 'green'; var obj = {color:'red'}; function showColor (){ console.log(this.color); } showColor.call(window); // green var objShowColor = showColor.bind(obj); objShowColor(); // red objShowColor 方法是通过 bind 方法创建的 showColor 函数的实例方法，其 this 作用域为 obj 对象，因此，实列调用后输出值是 “red”。 bind 方法有一些使用注意点。 每一次返回一个新函数 bind 方法每运行一次，就返回一个新函数，这会产生一些问题。比如，监听事件的时候，不能写成下面这样。 element.addEventListener('click', o.m.bind(o)); 上面代码中，click 事件绑定了 bind 方法生成的一个匿名函数。这样会导致无法取消绑定，所以，下面的代码是无效的。 element.addEventListener('click', o.m.bind(o)); // o.m.bind(o) bind 方法生成的一个匿名函数 element.removeEventListener('click', o.m.bind(o)); // 这里的 o.m.bind(o) 是 bind 方法生成另一个新的匿名函数，所以 removeEventListener 不能取消绑定。 正确的方法是写成下面这样： var listener = o.m.bind(o); element.addEventListener('click', listener); // ... element.removeEventListener('click', listener); 结合回调函数使用 回调函数是 JavaScript 最常用的模式之一，但是一个常见的错误是，将包含 this 的方法直接当作回调函数，如下面的例子： var counter = { count: 0, inc: function () { 'use strict'; this.count ++; } }; function callIt(callback) { callback(); } callIt(counter.inc.bind(counter)); console.log(counter.count) // 1 上面代码中，callIt 方法会调用回调函数。这时如果直接把 counter.inc 传入，调用时 counter.inc 内部的 this 就会指向全局对象。 使用 bind 方法将 counter.inc 绑定 counter 以后，就不会有这个问题，this 指向了 counter。 ","date":"2017-05-20","objectID":"/posts/2017-05-20-js-apply-call-bind/:3:0","tags":null,"title":"JavaScript 中的 apply、call、bind 方法","uri":"/posts/2017-05-20-js-apply-call-bind/"},{"categories":["Javascript"],"content":"比较 call 和 apply 两个方法在作用上没有任何区别，不同的只是二者的参数的传递方式。至于使用哪一个方法，取决于你的需要，如果打算直接 传入 argumnets 对象或应用的函数接收到的也是数组，那么使用 apply 方法比较方便，其它情况使用 call 则相对方便一些。 bind 方法会在指定对象的作用上创建一个函数实例，而 call 和 apply 方法是在指定对象的作用上运行函数。 bind 方法会创建函数实例，所以需要运行实例后才会发生调用。而 call 和 apply 则会指定作用域上直接调用函数，不需要再次运行。 ","date":"2017-05-20","objectID":"/posts/2017-05-20-js-apply-call-bind/:3:1","tags":null,"title":"JavaScript 中的 apply、call、bind 方法","uri":"/posts/2017-05-20-js-apply-call-bind/"},{"categories":["Database"],"content":"安装参考官网 Yum 安装 MySQL 文档。 ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:0:0","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Database"],"content":"安装步骤 ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:1:0","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Database"],"content":"添加 MySQL Yum Repository 在 这里 下载。 选择你要下载的版本下载。我的系统是 CentOs7： wget https://repo.mysql.com//mysql80-community-release-el7-2.noarch.rpm 下载好之后，使用下面的命令安装 RPM 包 yum localinstall mysql80-community-release-el7-2.noarch.rpm 这个安装命令会把 MySQL 的 Yum 源添加到系统的源列表中，并且下载 GnuPG key 校验软件包的完整性。使用下面的命令验证 MySQL 的 Yum 源是否添加成功： yum repolist enabled | grep \"mysql.*-community.*\" ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:1:1","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Database"],"content":"选择一个版本系列 使用 MySQL Yum Repository，默认会选择最新的 GA（Generally Available）系列（当前是MySQL 8.0）安装。如果这是你想要安装的版本，可以跳过这 一步。MySQL 的不同版本系列托管在不同的子仓库中。默认情况下启用了最新 GA 系列(当前 MySQL 8.0)的子仓库，并且其他版本的子仓库默认是禁用的。 使用下面的命令查看所有仓库的状态： yum repolist all | grep mysql 安装指定的版本要先禁用最新的 GA 子仓库，并启用指定版本的子仓库。如果系统支持 yum-config-manager，可以使用 yum-config-manager，比如， 禁用 5.7 的子仓库并启用 8.0: yum-config-manager --disable mysql57-community yum-config-manager --enable mysql80-community 对于启用了 dnf 的系统，使用： dnf config-manager --disable mysql57-community dnf config-manager --enable mysql80-community 除了上面的方式，还可以手动修改 /etc/yum.repos.d/mysql-community.repo 文件： [mysql57-community]\rname=MySQL 5.7 Community Server\rbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/6/$basearch/\renabled=1\rgpgcheck=1\rgpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql\r# Enable to use MySQL 8.0\r[mysql80-community]\rname=MySQL 8.0 Community Server\rbaseurl=http://repo.mysql.com/yum/mysql-8.0-community/el/6/$basearch/\renabled=1\rgpgcheck=1\rgpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 通过修改 enabled 的值来禁用和启用对应的版本仓库。enabled=0 表示禁用。使用 yum repolist enabled | grep mysql 检查状态。 注意，只能启用一个版本。 ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:1:2","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Database"],"content":"安装 MySQL 执行下面的命令安装 MySQL： yum install mysql-community-server 这个命令安装 MySQL server(mysql-community-server)和运行 MySQL server 必要的组件，包括MySQL 客户端(mysql-community-client)等。 ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:1:3","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Database"],"content":"启动 MySQL 启动 MySQL： systemctl start mysqld # 检查 systemctl status mysqld 初次启动 MySQL server，要注意： SSL 证书和密钥文件在数据目录中生成。 validate_password 被安装并启用。 会创建一个名为 root 的超级用户。密码可以使用 grep 'temporary password' /var/log/mysqld.log 来查看。使用生成的临时密码登录， 尽快更改 root 密码，并为超级用户帐户设置自定义密码: mysql -uroot -p # 修改密码 ALTER USER 'root'@'localhost' IDENTIFIED BY 'Admin@111'; 报错：Your password does not satisfy the current policy requirements 说明密码太简单了。 ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:1:4","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Database"],"content":"配置 安装后，配置文件为 /etc/my.cnf。具体配置参数参考 官网。 ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:2:0","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Database"],"content":"MySQL 主从复制 环境说明和注意点： 假设有两台服务器，一台做主，一台做从 MySQL 主信息： IP：10.5.4.247 端口：3306 MySQL 从信息： IP：10.5.4.248 端口：3306 注意点 主 DB server 和从 DB server 数据库的版本一致 主 DB server 和从 DB server 数据库数据一致 主 DB server 开启二进制日志，主 DB server 和从 DB server 的 server-id 都必须唯一 优先操作： 把主库的数据库复制到从库并导入 ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:2:1","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Database"],"content":"主库机子操作 主库操作步骤 创建一个目录：mkdir -p /usr/local/mysql/data/mysql-bin 主 DB 开启二进制日志功能：vim /etc/my.cnf， 添加一行：log-bin = /usr/local/mysql/data/mysql-bin 指定同步的数据库，如果不指定则同步全部数据库，其中 ssm 是我的数据库名：binlog-do-db=ssm 主库关掉慢查询记录，用 SQL 语句查看当前是否开启：SHOW VARIABLES LIKE '%slow_query_log%';，如果显示 OFF 则表示关闭，ON 表示开启 重启主库 MySQL 服务 进入 MySQL 命令行状态，执行 SQL 语句查询状态：SHOW MASTER STATUS; 在显示的结果中，我们需要记录下 File 和 Position 值，等下从库配置有用。 设置授权用户 slave01 使用 123456 密码登录主库，这里 @ 后的 IP 为从库机子的 IP 地址，如果从库的机子有多个，我们需要多个这个 SQL 语句。 grant replication slave on *.* to 'slave01'@'192.168.1.135' identified by '123456'; flush privileges; ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:2:2","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Database"],"content":"从库机子操作 从库操作步骤 从库开启慢查询记录，用 SQL 语句查看当前是否开启：SHOW VARIABLES LIKE '%slow_query_log%';，如果显示 OFF 则表示关闭，ON 表示开启。 测试从库机子是否能连上主库机子：mysql -h 192.168.1.105 -u slave01 -p，必须要连上下面的操作才有意义。 由于不能排除是不是系统防火墙的问题，所以建议连不上临时关掉防火墙：service iptables stop 或是添加防火墙规则： 添加规则：iptables -I INPUT -p tcp -m tcp --dport 3306 -j ACCEPT 保存规则：service iptables save 重启 iptables：service iptables restart 修改配置文件：vim /etc/my.cnf，把 server-id 改为跟主库不一样 在进入 MySQL 的命令行状态下，输入下面 SQL： CHANGE MASTER TO master_host='192.168.1.113', master_user='slave01', master_password='123456', master_port=3306, master_log_file='mysql3306-bin.000006',\u003e\u003e\u003e这个值复制刚刚让你记录的值 master_log_pos=1120;\u003e\u003e\u003e这个值复制刚刚让你记录的值 执行该 SQL 语句，启动 slave 同步：START SLAVE; 执行该 SQL 语句，查看从库机子同步状态：SHOW SLAVE STATUS; 在查看结果中必须下面两个值都是 Yes 才表示配置成功： Slave_IO_Running:Yes 如果不是 Yes 也不是 No，而是 Connecting，那就表示从机连不上主库，需要你进一步排查连接问题。 Slave_SQL_Running:Yes 如果你的 Slave_IO_Running 是 No，一般如果你是在虚拟机上测试的话，从库的虚拟机是从主库的虚拟机上复制过来的，那一般都会这样的，因为两台 的 MySQL 的 UUID 值一样。你可以检 ","date":"2017-04-27","objectID":"/posts/2017-04-27-mysql-yum-install/:2:3","tags":null,"title":"CentOs 安装配置 MySQL","uri":"/posts/2017-04-27-mysql-yum-install/"},{"categories":["Javascript"],"content":"javascript 中的类方法、构造方法、原型方法的对比 ","date":"2017-03-29","objectID":"/posts/2017-03-29-js-methods/:0:0","tags":null,"title":"Javascript 中的类方法、构造方法、原型方法","uri":"/posts/2017-03-29-js-methods/"},{"categories":["Javascript"],"content":"定义 function Class(){ //声明一个类 this.constructMethod = function(){}; // 添加构造构造方法 } Class.classMethod = function(){}; // 添加类方法，静态方法 Class.prototype.protoMethod=function(){};// 添加原型方法 ","date":"2017-03-29","objectID":"/posts/2017-03-29-js-methods/:1:0","tags":null,"title":"Javascript 中的类方法、构造方法、原型方法","uri":"/posts/2017-03-29-js-methods/"},{"categories":["Javascript"],"content":"用法 Class.classMethod(); // 类方法可以直接调用 var instance = new Class(); instance.constructMethod();// 构造方法只有实例才能调用 instance.protoMethod(); // 原型方法只有实例才能调用 ","date":"2017-03-29","objectID":"/posts/2017-03-29-js-methods/:2:0","tags":null,"title":"Javascript 中的类方法、构造方法、原型方法","uri":"/posts/2017-03-29-js-methods/"},{"categories":["Javascript"],"content":"性能 类方法在内存中只会有一份，因为它只属于类本身。 构造方法和原型方法都是实例的，但是构造方法会在每一次 new Class() 时，都在内存中产生一个新的副本。通常这种方法我们用在实例间的不同之处。每 个实例的构造方法互不影响。但是显然，它又占据内存了。原型方法就正好相反，它不会随着 new Class() 时产生新的副本，它在内存中也只有一份。可以实 现实例间的共享。同时也节约了内存。 综上：你在开发时，一般不会用到类方法，将有共性的方法做成原型方法，将有个性的方法做成构造方法。 ","date":"2017-03-29","objectID":"/posts/2017-03-29-js-methods/:3:0","tags":null,"title":"Javascript 中的类方法、构造方法、原型方法","uri":"/posts/2017-03-29-js-methods/"},{"categories":["Javascript"],"content":"JavaScript 的闭包有两个用途： 访问函数内部的变量。 让变量的值在作用域内保持不变。 JavaScript 没有块作用域（比如 for 循环，if 的 {} 中的代码块），函数是 JavaScript 中唯一有作用域的对象。 ","date":"2017-03-19","objectID":"/posts/2017-03-19-js-closure/:0:0","tags":null,"title":"JavaScript 的闭包","uri":"/posts/2017-03-19-js-closure/"},{"categories":["Javascript"],"content":"JavaScript 中使用闭包的陷阱 如果在循环中创建函数，并引用循环变量，原意是打印出 0，1，2，但结果却是一样的: var tasks = []; for (var i = 0; i \u003c 3; i ++) { tasks.push(function() { console.log('\u003e\u003e\u003e ' + i); }); } console.log('end for.'); for (var j = 0; j \u003c tasks.length; j ++) { tasks[j](); } // end for. // \u003e\u003e\u003e 3\u003e\u003e\u003e 3\u003e\u003e\u003e 3 问题的原因在于，函数创建时并未执行，所以先打印 end for，然后才执行函数。 由于函数引用了循环变量 i，在函数执行时，由于 i 的值已经变成了 3，所以，打印出的结果不对。 注意到 i 为什么不是 2，因为 i++ 多加一次。 解决方法可以使用闭包 ","date":"2017-03-19","objectID":"/posts/2017-03-19-js-closure/:1:0","tags":null,"title":"JavaScript 的闭包","uri":"/posts/2017-03-19-js-closure/"},{"categories":["Javascript"],"content":"闭包的使用 ","date":"2017-03-19","objectID":"/posts/2017-03-19-js-closure/:2:0","tags":null,"title":"JavaScript 的闭包","uri":"/posts/2017-03-19-js-closure/"},{"categories":["Javascript"],"content":"保持变量的作用域 ES6中可以使用 let 定义块级变量 for(var i = 0; i \u003c 10; i++) { (function(e) { setTimeout(function() { console.log(e); }, 1000); })(i); } function() 匿名函数立即被执行，因此，闭包拿到的参数 i 就是当前循环变量的值的副本。为变量构建一个作用域。 ","date":"2017-03-19","objectID":"/posts/2017-03-19-js-closure/:2:1","tags":null,"title":"JavaScript 的闭包","uri":"/posts/2017-03-19-js-closure/"},{"categories":["Javascript"],"content":"访问函数内部的变量 在 JavaScript 中，函数可以访问其外部定义的变量，外部不能访问函数内部定义的变量。而通过调用闭包函数达到访问函数内部变量的目的。 在下面示例中，count 相当于一个“私有变量”，在 Counter 函数外部不能访问这个变量。在 Counter 中，还定义了 increment 和 get 两 个“闭包函数”，这两个函数都保持着对 Counter 作用域的引用，因此可以访问到 Counter 作用域内定义的变量 count。 function Counter() { var count = 2; return { increment: function() { count++; }, get: function() { return count; } } } var foo = new Counter(); foo.increment(); foo.get(); // -\u003e 3 ","date":"2017-03-19","objectID":"/posts/2017-03-19-js-closure/:2:2","tags":null,"title":"JavaScript 的闭包","uri":"/posts/2017-03-19-js-closure/"},{"categories":["Javascript"],"content":"闭包的注意点 由于闭包会使得函数中的变量都被保存在内存中，所以不能滥用闭包，否则可能导致内存泄露。解决方法是，在退出函数之前，将不使用的局部变量全部删除。一 旦数据不再有用，最好通过将其值设置为 null 来释放其引用——这个做法叫做解除引用（dereferencing）。 闭包会在父函数外部，改变父函数内部变量的值。所以，如果你把父函数当作对象使用，把闭包当作它的公用方法，把内部变量当作它的私有属性，这时一定要小 心，不要随便改变父函数内部变量的值。 在闭包中使用 this 对象也可能会导致一些问题。this 对象是在运行时基于函数的执行环境绑定的： 在全局函数中，this 等于 window，而当函数被作为某个对象的方法调用时，this 等于那个对象。不过，匿名函数的执行环境具有全局性，因此 其 this 对象通常指向 window，不过，把外部作用域中的 this 对象保存在一个闭包能够访问到的变量里，就可以让闭包访问该对象了。 ","date":"2017-03-19","objectID":"/posts/2017-03-19-js-closure/:2:3","tags":null,"title":"JavaScript 的闭包","uri":"/posts/2017-03-19-js-closure/"},{"categories":["Node.js"],"content":"使用 Node.js 实现命令行。 ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:0:0","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"命令行参数处理 ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:1:0","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"yargs 简单模式 只需要引入 yargs，就能读取命令行参数，不需要写任何的配置 #!/usr/bin/env node var argv = require('yargs').argv; console.log('hello ', argv.name); $ hello --name=tom hello tom $ hello --name tom hello tom 简单模式还能读取短变量如 -x 4 相当于 argv.x = 4 简单模式还能读取布尔类型 -s 相当于 argv.s = true 简单模式还能读取非 - 开始的变量，这种类型的变量保存在 argv._ 数组里面 count 统计变量出现的次数 var argv = require('yargs') .count('num') .alias('n', 'num') .argv; 统计 num 参数出现的次数，缩写 -n 也会统计进去 node count.js -n node count.js -nn node count.js -n --num demand default describe var argv = require('yargs') .demand(['n']) //是否必选 .default({n: 'tom'}) //默认值 .describe({n: 'your name'}) //提示 .argv; n 参数不可省略，默认值为 tom，并给出一行提示 options 将所有配置写进一个对象 var argv = require('yargs') .option('n', { alias : 'name', demand: true, default: 'tom', describe: 'your name', type: 'string' }) .argv; boolean 方法指定参数返回布尔值 var argv = require('yargs') .boolean(['l']) .argv; 帮助信息 usage：用法格式 example：提供例子 help：显示帮助信息 epilog：出现在帮助信息的结尾 var argv = require('yargs') .option('f', { alias : 'name', demand: true, default: 'tom', describe: 'your name', type: 'string' }) .usage('Usage: hello [options]') .example('hello -n tom', 'say hello to Tom') .help('h') .alias('h', 'help') .epilog('epilog 2017') .argv; 结果 $ hello -h Usage: hello [options] Options: -f, --name your name [string] [required] [default: \"tom\"] -h, --help Show help [boolean] Examples: hello -n tom say hello to Tom epilog 2017 设置子命令 command() .command(cmd, desc, [builder], [handler]) .command(module) .command(cmd, desc, [module]) //.command(cmd, desc, [builder], [handler]) yargs .command( 'get', 'get incident', function (yargs) { return yargs.option('u', { alias: 'url', describe: 'the url get incident' }) }, function (argv) { console.log(argv.url) } ) .help() .argv //.command(module) test.js exports.command = 'get' exports.describe = 'get incident' exports.builder = { name: { default: 'tom' } } exports.handler = function (argv) { //console.log(argv) } yargs.command(require('drafts/test')) .help() .argv commandDir 如果有大量的命令都使用上面的 command(module) 来开发的话，这些模块都有相同的结构，yargs 提供了 commandDir 接口,简化这些命令的引入过 程，把这个过程自动化. require('yargs') .commandDir('commands') .demand(1) .help() .locale('en') .showHelpOnFail(true, 'Specify --help for available options') .argv commandDir 默认加载目录下第一级的文件，递归加载: commandDir('pit', {recurse: true}) ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:1:1","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"commander commander 是从 Ruby 下同名项目移植过来的，官方文档 。 commander 特性 自记录代码 自动生成 help 合并短参数（“ABC”==“-A-B-C”） 默认选项 强制选项​​ 命令解析 提示符 example \\\\example test.js file: var commander = require('commander'); commander .version('1.0.0') .usage('[options] [value ...]') .option('-l, --langu', 'langueage') .parse(process.argv); if (commander.langu == 'zh-cn') { console.log('Chinese website!'); }else if(commander.langu == 'en') { console.log('English website!'); } 启动 test.js 时,接受一个 -l 的参数 $node test.js -l en commander API Option(): 初始化自定义参数对象，设置“关键字”和“描述” Command(): 初始化命令行参数对象，直接获得命令行输入 Command#command(): 定义一个命令名字 Command#action(): 注册一个 callback 函数 Command#option(): 定义参数，需要设置“关键字”和“描述”，关键字包括“简写”和“全写”两部分，以,，|，空格 做分隔。 Command#parse(): 解析命令行参数 argv Command#description(): 设置 description 值 Command#usage(): 设置 usage 值 Command#version(): 指定当前应用程序的一个版本号 参数解析 1.使用 option() 方法自定义参数； 2.使用 parse() 方法解析用户从命令行输入的参数。 上面的例子中： parse() 方法对 option() 方法定义的参数进行赋值，然后将剩下的参数（未定义的参数）赋值给 commander 对象的 args 属性 (program.args)，program.args是一个数组。 command()、description() 和 action() command()方法有点复杂，最常用的方法是和 action() 联合起来用： var program = require('commander'); program .version('0.0.1') .option('-C, --chdir \u003cpath\u003e', 'change the working directory') .option('-c, --config \u003cpath\u003e', 'set config path. defaults to ./deploy.conf') .option('-T, --no-tests', 'ignore test hook') program .command('setup') // 定义命令 .description('run remote setup commands') // 对命令参数的描述信息 .action(function() { // setup命令触发时调用 console.log('setup'); }); program .command('exec \u003ccmd\u003e') // 定义命令，参数可以用 \u003c\u003e 或 [] 修饰 .description('run the given remote command') // exec 触发时调用，参数和定义的参数顺序一致 .action(function(cmd) { console.log('exec \"%s\"', cmd); }); program .command('init') // 定义命令，参数可以用 \u003c\u003e 或 [] 修饰 .description('run the given remote command') .option('-y, --yes', 'without prompt') // options 是 init 命令的参数对象、是 action 回调方法的最后一个参数 .action(function(options) { console.log('init param \"%s\"',options.yes ); }); program.parse(process.argv); 可变参数 一个命令的最后一个参数可以是可变参数, 并且只能是最后一个参数。可变参数需要在参数名后面追加 ...： var program = require('commander'); program .version('0.0.1') .command('rmdir \u003cdir\u003e [otherDirs...]') .action(function(dir, otherDirs) { console.log('rmdir %s', dir); if (otherDirs) { //otherDirs是一个数组 otherDirs.forEach(function(oDir) { console.log('rmdir %s', oDir); }); } }); program.parse(process.argv); commander 帮助信息 默认情况下，commander 会根据 option() 方法的参数为你帮你实现 --help 参数，当用户在命令行使用 -h 或 --help 参数时，将自动打印 出帮助信息。也支持自定义帮助信息： commander.on('help', function() { // 自定义帮助信息 console.log(' # website langueage ') console.log(' $ ./app.js -l \\\"a string zh-cn or en \\\" ') console.log('') }); # or commander.on('--help', function(){ // 自定义帮助信息 console.log(' Examples:'); console.log(''); console.log(' $ custom-help --help'); console.log(' $ custom-help -h'); console.log(''); }); 主动打印帮助信息 两种情况： 打印帮助信息，然后等待用户继续输入信息，不结束当前进程—— program.outputHelp() 打印帮助信息，并立即结束当前进程—— program.help() .outputHelp() 方法和 .help() 方法都可以带一个参数——一个回调方法，打印信息在显示到命令行之前会先传入这个方法，你可以在方法里面做必要 的信息处理，比如改变文本颜色。 ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:1:2","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"argparse \\\\example test.js file: import {ArgumentParser} from 'argparse'; const parser = new ArgumentParser({ version: require(\"../package.json\").version, addHelp: true, description: \"Storage Server\" }); parser.addArgument([\"-rpc\",\"--rpcPort\"], { required: false, help: \"rpc port\", dest: \"rpcPort\" }); parser.addArgument(\"--isLocal\", { dest: \"isLocal\", help: \"is publish from office network\", defaultValue: false, action: \"storeTrue\" }); const argument = parser.parseArgs(); console.log(argument.rpcPort) console.dir(args); $ ./test.js -h usage: example.js [-h] [-rpc] [--isLocal] Storage Server Optional arguments: -h, --help Show this help message and exit. -v, --version Show program's version number and exit. -rpc, --rpcPort rpc port --isLocal is publish from office network ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:1:3","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"shell.js shelljs 模块重新包装了 child_process,调用系统命令更加简单。官方文档 。 ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:2:0","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"安装 npm install shelljs --save ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:2:1","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"使用 shelljs 绝大部分命令都是对文件和文件夹的操作。看个例子： var shell = require('shelljs'); // 判定 git 命令是否可用 if (!shell.which('git')) { // 向命令行打印git命令不可用的提示信息 shell.echo('Sorry, this script requires git'); // 退出当前进程 shell.exit(1); } // 先删除 'out/Release' 目录 shell.rm('-rf', 'out/Release'); // 拷贝文件到 'out/Release' 目录 shell.cp('-R', 'stuff/', 'out/Release'); // 切换当前工作目录到 'lib' shell.cd('lib'); // shell.ls('*.js') 返回值是一个包含所有 js 文件路径的数组 shell.ls('*.js').forEach(function(file) {//遍历数组 // sed 命令用于文件内容的替换，这里是对每个文件都执行如下 3 步操作，更改版本信息 shell.sed('-i', 'BUILD_VERSION', 'v0.1.2', file); shell.sed('-i', /^.*REMOVE_THIS_LINE.*$/, '', file); shell.sed('-i', /.*REPLACE_LINE_WITH_MACRO.*\\n/, shell.cat('macro.js'), file); }); // 切换当前工作目录到上一层 shell.cd('..'); // 同步执行 git 命令提交代码 if (shell.exec('git commit -am \"Auto-commit\"').code !== 0) { shell.echo('Error: Git commit failed'); shell.exit(1); } 上面的例子展示了一个可发布版本提交到 git 仓库的过程。 ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:2:2","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"exec exec(command [, options] [, callback]) command \u003cString\u003e: 要在命令行执行的完整命令 options \u003cObject\u003e: 可选参数，JSON 对象 async: 异步执行.如果你提供了回调方法，这个值就一定为 true，无论你怎么设置 silent: 打印信息不输出到命令控制台 Node.js 的 child_process.exec() 方法的其他参数都可以用 callback:\u003cFunction\u003e: 当进程终止时调用，并带上输出。 error \u003cError\u003e stdout \u003cString\u003e | \u003cBuffer\u003e stderr \u003cString\u003e | \u003cBuffer\u003e 返回值：同步模式下，将返回一个 ShellString（shelljs v0.6.xf 返回一个形如 { code:..., stdout:... , stderr:... } 的对象； 异步模式下，将返回一个 child_process 的对象 exec()同步方法的实现会占用大量 CPU，所以建议使用异步模式。 例： var version = exec('node --version', {silent:true}).stdout; var child = exec('some_long_running_process', {async:true}); child.stdout.on('data', function(data) { /* ... do something with data ... */ }); exec('some_long_running_process', function(code, stdout, stderr) { console.log('Exit code:', code); console.log('Program output:', stdout); console.log('Program stderr:', stderr); }); ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:2:3","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"命令行交互 命令行交互可以使用 prompt 实现。 const prompt = require('prompt'); var schema = { properties: { name: { pattern: /^[a-zA-Z\\s\\-]+$/, message: 'Name must be only letters, spaces, or dashes', required: true }, password: { hidden: true } } }; // // Start the prompt // prompt.start(); // // Get two properties from the user: email, password // prompt.get(schema, function (err, result) { // // Log the results. // console.log('Command-line input received:'); console.log(' name: ' + result.name); console.log(' password: ' + result.password); }); ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:3:0","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"},{"categories":["Node.js"],"content":"隐式调用 node 程序 在执行 node 程序的时候都是使用 node filePath(比如，node run.js)的形式。如何像 npm，git 一样直接调用？ 在你要运行的脚本文件头添加 #!/usr/bin/env node，例如： #!/usr/bin/env node console.log('Hello,world!'); 它的作用是指定脚本文件的执行程序 node。做完上面的修改，可以直接 ./\u003cfile\u003e 了。 如果想要一个全局的命令，在 package.json 中加入一个字段 bin，注意： \"bin\":{ \"myCmd\":\"\u003cfile path\u003e\" }, myCmd 就是你命令的名字，如果是准备发布的模块，一般是会使用模块名称。 在当前工作目录下执行 npm link，把模块链接的本地 npm 仓库，然后就可以全局调用 myCmd 了。 ","date":"2017-02-18","objectID":"/posts/2017-02-18-nodejs-command/:4:0","tags":null,"title":"Node.js 命令行实现","uri":"/posts/2017-02-18-nodejs-command/"}]